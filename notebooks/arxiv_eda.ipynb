{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "enormous-paraguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c0e05453974c28b38ba6ed471170f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/866 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca990b7b4f1486e8a17757de9b3f68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-af0e913e4e56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLongformerTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allenai/longformer-large-4096-finetuned-triviaqa\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLongformerForQuestionAnswering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allenai/longformer-large-4096-finetuned-triviaqa\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m                     \u001b[0mresume_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m                     \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 )\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m         )\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found in cache or force_download set to True, downloading to %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m             \u001b[0mhttp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storing %s in cache at %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/site-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m     )\n\u001b[0;32m-> 1167\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m                 if (\n\u001b[1;32m    521\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nce/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from transformers import LongformerTokenizer, LongformerForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-large-4096-finetuned-triviaqa\", use_fast=False)\n",
    "model = LongformerForQuestionAnswering.from_pretrained(\"allenai/longformer-large-4096-finetuned-triviaqa\", return_dict=False)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "bi_encoder = SentenceTransformer('nq-distilbert-base-v1')\n",
    "\n",
    "from inspect import getsourcefile\n",
    "import os.path as path, sys\n",
    "current_dir = path.dirname(path.abspath(getsourcefile(lambda:0)))\n",
    "sys.path.insert(0, current_dir[:current_dir.rfind(path.sep)])\n",
    "import src.clean_dataset as clean\n",
    "\n",
    "import time\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "banner-front",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Taking Ethics, Fairness, and Bias Seriously in...</td>\n",
       "      <td>This paper highlights an important, if under-e...</td>\n",
       "      <td>['Robert Soden', 'Dennis Wagenaar', 'Dave Luo'...</td>\n",
       "      <td>http://arxiv.org/abs/1912.05538v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A Survey on the Role of Wireless Sensor Networ...</td>\n",
       "      <td>Extreme events and disasters resulting from cl...</td>\n",
       "      <td>['Ahsan Adeel', 'Mandar Gogate', 'Saadullah Fa...</td>\n",
       "      <td>http://arxiv.org/abs/1909.10353v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A Natural Disasters Index</td>\n",
       "      <td>Natural disasters, such as tornadoes, floods, ...</td>\n",
       "      <td>['Thilini V. Mahanama', 'Abootaleb Shirvani']</td>\n",
       "      <td>http://arxiv.org/abs/2008.03672v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sistem Pengambilan Keputusan Penanganan Bencan...</td>\n",
       "      <td>After Aceh's quake many earthquakes have struc...</td>\n",
       "      <td>['H. L. H Spits Warnars']</td>\n",
       "      <td>http://arxiv.org/abs/1006.1704v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CNN-Based Semantic Change Detection in Satelli...</td>\n",
       "      <td>Timely disaster risk management requires accur...</td>\n",
       "      <td>['Ananya Gupta', 'Elisabeth Welburn', 'Simon W...</td>\n",
       "      <td>http://arxiv.org/abs/2006.05589v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>14995</td>\n",
       "      <td>Reduce The Wastage of Data During Movement in ...</td>\n",
       "      <td>In this research paper so as to handle Data in...</td>\n",
       "      <td>['Ahmed Mateen', 'Lareab Chaudhary']</td>\n",
       "      <td>http://arxiv.org/abs/1612.08702v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>14996</td>\n",
       "      <td>Paving the Way to Smart Micro Energy Internet:...</td>\n",
       "      <td>The energy internet is one of the most promisi...</td>\n",
       "      <td>['Shengwei Mei', 'Rui Li', 'Xiaodai Xue', 'Yin...</td>\n",
       "      <td>http://arxiv.org/abs/1612.09500v3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>14997</td>\n",
       "      <td>A Non-Cooperative Game Theoretical Approach Fo...</td>\n",
       "      <td>Power management is one of the vital issue in ...</td>\n",
       "      <td>['R. Valli', 'P. Dananjayan']</td>\n",
       "      <td>http://arxiv.org/abs/1007.5168v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>14998</td>\n",
       "      <td>Secured Data Consistency and Storage Way in Un...</td>\n",
       "      <td>It is very challenging part to keep safely all...</td>\n",
       "      <td>['C. Dinesh']</td>\n",
       "      <td>http://arxiv.org/abs/1111.2412v1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>14999</td>\n",
       "      <td>The Management and Use of Social Network Sites...</td>\n",
       "      <td>In this paper we report findings from a study ...</td>\n",
       "      <td>['John Rooksby', 'Ian Sommerville']</td>\n",
       "      <td>http://arxiv.org/abs/1111.5454v1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title  \\\n",
       "0               0  Taking Ethics, Fairness, and Bias Seriously in...   \n",
       "1               1  A Survey on the Role of Wireless Sensor Networ...   \n",
       "2               2                          A Natural Disasters Index   \n",
       "3               3  Sistem Pengambilan Keputusan Penanganan Bencan...   \n",
       "4               4  CNN-Based Semantic Change Detection in Satelli...   \n",
       "...           ...                                                ...   \n",
       "14995       14995  Reduce The Wastage of Data During Movement in ...   \n",
       "14996       14996  Paving the Way to Smart Micro Energy Internet:...   \n",
       "14997       14997  A Non-Cooperative Game Theoretical Approach Fo...   \n",
       "14998       14998  Secured Data Consistency and Storage Way in Un...   \n",
       "14999       14999  The Management and Use of Social Network Sites...   \n",
       "\n",
       "                                                 summary  \\\n",
       "0      This paper highlights an important, if under-e...   \n",
       "1      Extreme events and disasters resulting from cl...   \n",
       "2      Natural disasters, such as tornadoes, floods, ...   \n",
       "3      After Aceh's quake many earthquakes have struc...   \n",
       "4      Timely disaster risk management requires accur...   \n",
       "...                                                  ...   \n",
       "14995  In this research paper so as to handle Data in...   \n",
       "14996  The energy internet is one of the most promisi...   \n",
       "14997  Power management is one of the vital issue in ...   \n",
       "14998  It is very challenging part to keep safely all...   \n",
       "14999  In this paper we report findings from a study ...   \n",
       "\n",
       "                                                 authors  \\\n",
       "0      ['Robert Soden', 'Dennis Wagenaar', 'Dave Luo'...   \n",
       "1      ['Ahsan Adeel', 'Mandar Gogate', 'Saadullah Fa...   \n",
       "2          ['Thilini V. Mahanama', 'Abootaleb Shirvani']   \n",
       "3                              ['H. L. H Spits Warnars']   \n",
       "4      ['Ananya Gupta', 'Elisabeth Welburn', 'Simon W...   \n",
       "...                                                  ...   \n",
       "14995               ['Ahmed Mateen', 'Lareab Chaudhary']   \n",
       "14996  ['Shengwei Mei', 'Rui Li', 'Xiaodai Xue', 'Yin...   \n",
       "14997                      ['R. Valli', 'P. Dananjayan']   \n",
       "14998                                      ['C. Dinesh']   \n",
       "14999                ['John Rooksby', 'Ian Sommerville']   \n",
       "\n",
       "                                     url  \n",
       "0      http://arxiv.org/abs/1912.05538v2  \n",
       "1      http://arxiv.org/abs/1909.10353v1  \n",
       "2      http://arxiv.org/abs/2008.03672v1  \n",
       "3       http://arxiv.org/abs/1006.1704v2  \n",
       "4      http://arxiv.org/abs/2006.05589v1  \n",
       "...                                  ...  \n",
       "14995  http://arxiv.org/abs/1612.08702v1  \n",
       "14996  http://arxiv.org/abs/1612.09500v3  \n",
       "14997   http://arxiv.org/abs/1007.5168v1  \n",
       "14998   http://arxiv.org/abs/1111.2412v1  \n",
       "14999   http://arxiv.org/abs/1111.5454v1  \n",
       "\n",
       "[15000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data:\n",
    "df = pd.read_csv('../data/raw/arxiv_results.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surprising-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary_clean'] = df['summary'].astype(str).apply(clean.basic)\n",
    "wrapped, splitted = clean.split_at_length(df, 'summary_clean', 512, PIMS_ID = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "considerable-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = pd.concat([pd.Series(row['title'], row['wrapped'].split(\"; \"), )              \n",
    "                            for _, row in wrapped.iterrows()]).reset_index()\n",
    "splitted = splitted.rename(columns={\"index\": \"text\", 0: \"title\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "drawn-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = splitted.text.tolist()\n",
    "passage_id = splitted.title.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "measured-wright",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this paper highlights an important if underexamined set of questions about the deployment of machine learning technologies in the field of disaster risk management drm while emerging tools show promising capacity to support scientific efforts to better understand and mitigate the threats posed by disasters and climate change our field must undertake a much more careful assessment of the potential negative impacts that machine learning technologies may create we also argue that attention to these issues in',\n",
       " 'the context of machine learning affords the opportunity to have discussions about potential ethics bias and fairness concerns within disaster data more broadly in what follows we first describe some of the uses and potential benefits of machinelearning technology in disaster risk management we then draw on research from other fields to speculate about potential negative impacts finally we outline a research agenda for how our disaster risk management can begin to take these issues seriously and ensure that',\n",
       " 'deployments of machinelearning tools are conducted in a responsible and beneficial manner',\n",
       " 'extreme events and disasters resulting from climate change or other ecological factors are difficult to predict and manage current limitations of stateoftheart approaches to disaster prediction and management could be addressed by adopting new unorthodox risk assessment and management strategies the next generation internet of things iot wireless sensor networks wsns g wireless communication and big data analytics technologies are the key enablers for future effective disaster management infrastructures in',\n",
       " 'this chapter we commissioned a survey on emerging wireless communication technologies with potential for enhancing disaster prediction monitoring and management systems challenges opportunities and future research trends are highlighted to provide some insight on the potential future work for researchers in this field',\n",
       " 'natural disasters such as tornadoes floods and wildfire pose risks to life and property requiring the intervention of insurance corporations one of the most visible consequences of changing climate is an increase in the intensity and frequency of extreme weather events the relative strengths of these disasters are far beyond the habitual seasonal maxima often resulting in subsequent increases in property losses thus insurance policies should be modified to endure increasingly volatile catastrophic weather',\n",
       " 'events we propose a natural disasters index ndi for the property losses caused by natural disasters in the united states based on the storm data published by the national oceanic and atmospheric administration the proposed ndi is an attempt to construct a financial instrument for hedging the intrinsic risk the ndi is intended to forecast the degree of future risk that could forewarn the insurers and corporations allowing them to transfer insurance risk to capital market investors this index could also be',\n",
       " 'modified to other regions and countries',\n",
       " 'after acehs quake many earthquakes have struck indonesia alternately and even other disasters have been a threat for every citizen in this country actually an everyday occurrence on earth and more than million earthquakes occur every year about a day or one every seconds in indonesia there are to quakes prediction everyday governments responsibility to protect the citizen has been done by making national body of disaster management preparing saving and distribution logistic become national body of disaster',\n",
       " 'managements responsibility to build information management many laws products have been produced as a governments responsibility to give secure life for the citizen we can not prevent them totally we have to learn to live with them and need to be prepared all the time need to learn how to mitigate risk of losses in such events by managing crisis and emergencies correctly after disaster happens respond must be rapidly and at an optimal level to save lives and help to victims dss is information technology',\n",
       " 'environment which can be used to help human in order to learn from past earthquake record it learn and plan for future mitigation and hope will reduce the disaster risk in the future using web technology for dss will give value added where not only make a strategic decision for the decision maker but for others who need national earthquake information like citizen scholars researches and people around the world',\n",
       " 'timely disaster risk management requires accurate road maps and prompt damage assessment currently this is done by volunteers manually marking satellite imagery of affected areas but this process is slow and often errorprone segmentation algorithms can be applied to satellite images to detect road networks however existing methods are unsuitable for disasterstruck areas as they make assumptions about the road network topology which may no longer be valid in these scenarios herein we propose a cnnbased',\n",
       " 'framework for identifying accessible roads in postdisaster imagery by detecting changes from predisaster imagery graph theory is combined with the cnn output for detecting semantic changes in road networks with openstreetmap data our results are validated with data of a tsunamiaffected region in palu indonesia acquired from digitalglobe',\n",
       " 'social media are more than just a oneway communication channel data can be collected analyzed and contextualized to support disaster risk management however disaster management agencies typically use such addedvalue information to support only their own decisions a feedback loop between contextualized information and data suppliers would result in various advantages first it could facilitate the near realtime communication of early warnings derived from social media linked to other sources of information',\n",
       " 'second it could support the staff of aid organizations during response operations based on the example of hurricanes harvey and irma we show how filtered geolocated tweets can be used for rapid damage assessment we claim that the next generation of big data analyses will have to generate actionable information resulting from the application of advanced analytical techniques these applications could include the provision of social mediabased training data for algorithms designed to forecast actual cyclone',\n",
       " 'impacts or new socioeconomic validation metrics for seasonal climate forecasts',\n",
       " 'satellite images are an extremely valuable resource in the aftermath of natural disasters such as hurricanes and tsunamis where they can be used for risk assessment and disaster management in order to provide timely and actionable information for disaster response in this paper a framework utilising segmentation neural networks is proposed to identify impacted areas and accessible roads in postdisaster scenarios the effectiveness of pretraining with imagenet on the task of aerial image segmentation has been',\n",
       " 'analysed and performances of popular segmentation models compared experimental results show that pretraining on imagenet usually improves the segmentation performance for a number of models open data available from openstreetmap osm is used for training forgoing the need for timeconsuming manual annotation the method also makes use of graph theory to update road network data available from osm and to detect the changes caused by a natural disaster extensive experiments on data from the tsunami that struck',\n",
       " 'palu indonesia show the effectiveness of the proposed framework enetseparable with fewer parameters compared to enet achieved comparable segmentation results to that of the stateoftheart networks',\n",
       " 'the increasingly sophisticated sensors supported by modern smartphones open up novel research opportunities such as mobile phone sensing one of the most challenging of these research areas is contextaware and activity recognition the smartrescue project takes advantage of smartphone sensing processing and communication capabilities to monitor hazards and track people in a disaster the goal is to help crisis managers and members of the public in early hazard detection prediction and in devising',\n",
       " 'riskminimizing evacuation plans when disaster strikes in this paper we suggest a novel smartphonebased communication framework it uses specific machine learning techniques that intelligently process sensor readings into useful information for the crisis responders core to the framework is a contentbased publishsubscribe mechanism that allows flexible sharing of sensor data and computation results we also evaluate a preliminary implementation of the platform involving a smartphone app that reads and shares',\n",
       " 'mobile phone sensor data for activity recognition',\n",
       " 'recent financial disasters emphasised the need to investigate the consequence associated with the tail comovements among institutions episodes of contagion are frequently observed and increase the probability of large losses affecting market participants risk capital commonly used risk management tools fail to account for potential spillover effects among institutions because they provide individual risk assessment we contribute to analyse the interdependence effects of extreme events providing an',\n",
       " 'estimation tool for evaluating the conditional valueatrisk covar defined as the valueatrisk of an institution conditioned on another institution being under distress in particular our approach relies on bayesian quantile regression framework we propose a markov chain monte carlo algorithm exploiting the asymmetric laplace distribution and its representation as a locationscale mixture of normals moreover since risk measures are usually evaluated on time series data and returns typically change over time we',\n",
       " 'extend the covar model to account for the dynamics of the tail behaviour application on us companies belonging to different sectors of the standard and poors composite index sp is considered to evaluate the marginal contribution to the overall systemic risk of each individual institution',\n",
       " 'in classical markov decision processes mdps action costs and transition probabilities are assumed to be known although an accurate estimation of these parameters is often not possible in practice this study addresses mdps under cost and transition probability uncertainty and aims to provide a mathematical framework to obtain policies minimizing the risk of high longterm losses due to not knowing the true system parameters to this end we utilize the risk measure valueatrisk associated with the expected',\n",
       " 'performance of an mdp model with respect to parameter uncertainty we provide mixedinteger linear and nonlinear programming formulations and heuristic algorithms for such riskaverse models of mdps under a finite distribution of the uncertain parameters our proposed models and solution methods are illustrated on an inventory management problem for humanitarian relief operations during a slowonset disaster the results demonstrate the potential of our riskaverse modeling approach for reducing the risk of highly',\n",
       " 'undesirable outcomes in uncertainrisky environments',\n",
       " 'natural hazards can considerably impact the overall society of a country as some degree of public sector involvement is always necessary to deal with the consequences of natural disasters central governments have increasingly invested in proactive risk management planning in order to empower and involve the whole society some countries have established publicprivate partnerships mainly with the insurance industry with satisfactorily outcomes although they have proven necessary and most often effective the',\n",
       " 'publicprivate initiatives have often incurred high debts or have failed to achieved the desired risk reduction objectives we review the role of these partnerships in the management of natural risks with particular attention to the insurance sector among other countryspecific issues poor risk knowledge and weak governance have widely challenged the initiatives during the recent years while the future is threatened by the uncertainty of climate change and unsustainable development in order to strengthen the',\n",
       " 'countrys resilience a greater involvement of all segments of the community especially the weakest layers is needed and the management of natural risks should be included in a sustainable development plan',\n",
       " 'insurance industry is one of the most vulnerable sectors to climate change assessment of future number of claims and incurred losses is critical for disaster preparedness and risk management in this project we study the effect of precipitation on a joint dynamics of weatherinduced home insurance claims and losses we discuss utility and limitations of such machine learning procedures as support vector machines and artificial neural networks in forecasting future claim dynamics and evaluating associated',\n",
       " 'uncertainties we illustrate our approach by application to attribution analysis and forecasting of weatherinduced home insurance claims in a middlesized city in the canadian prairies',\n",
       " 'the need for information security within small to midsize companies is increasing the risks of information security breach data loss and disaster are growing the impact of it outages and issues on the company are unacceptable to any size business and their clients there are many ways to address the security for it departments the need to address risks of attacks as well as disasters is important to the it security policies and procedures the it departments of small to medium companies have to address these',\n",
       " 'security concerns within their budgets and other limited resourcessecurity planning design and employee training that is needed requires input and agreement from all levels of the company and management this paper will discuss security needs and methods to implement them into a corporate infrastructure',\n",
       " 'this paper investigates whether security markets price the effect of social distancing on firms operations we document that firms that are more resilient to social distancing significantly outperformed those with lower resilience during the covid outbreak even after controlling for the standard risk factors similar crosssectional return differentials already emerged before the covid crisis the cumulative return differential between more and less resilient firms is of similar size as during the outbreak',\n",
       " 'suggesting growing awareness of pandemic risk well in advance of its materialization finally we use stock option prices to infer the markets return expectations after the onset of the pandemic even at a twoyear horizon stocks of more pandemicresilient firms are expected to yield significantly lower returns than less resilient ones reflecting their lower exposure to disaster risk hence going forward markets appear to price exposure to a new risk factor namely pandemic risk',\n",
       " 'social media has become an essential channel for posting disasterrelated information which provide governments and relief agencies realtime data for better disaster management however research in this field has not received sufficient attention and extracting useful information is still challenging this paper aims to improve disaster relief efficiency via mining and analyzing social media data like public attitudes towards disaster response and public demands for targeted relief supplies during different',\n",
       " 'types of disasters we focus on different natural disasters based on properties such as types durations and damages which contains a total of tweets in this paper public perception is assessed qualitatively by manually classified tweets which contain information like the demand for targeted relief supplies satisfactions of disaster response and public fear public attitudes to natural disasters are studied via a quantitative analysis using eight machine learning models to better provide decisionmakers with',\n",
       " 'the appropriate model the comparison of machine learning models based on computational time and prediction accuracy is conducted the change of public opinion during different natural disasters and the evolution of peoples behavior of using social media for disaster relief in the face of the identical type of natural disasters as twitter continues to evolve are studied the results in this paper demonstrate the feasibility and validation of the proposed research approach and provide relief agencies with',\n",
       " 'insights into better disaster management',\n",
       " 'recently the world has witnessed the increasing occurrence of disasters some of natural origin and others caused by man the intensity of the phenomenon that cause such disasters the frequency in which they occur the number of people affected and the material damage caused by them have been growing substantially disasters are defined as natural technological and humaninitiated events that disrupt the normal functioning of the economy and society on a large scale areas where disasters have occurred bring many',\n",
       " 'dangers to rescue teams and the communication network infrastructure is usually destroyed to manage these hazards different wireless technologies can be launched in the area of disaster this paper discusses the innovative wireless technologies for disaster management specifically issues related to the design of hierarchical hybrid communication network arising in the communication network for disaster relief are discussed',\n",
       " 'virtualization is a very popular solution to many problems in datacenter management it offers increased utilization of existing system resources through effective consolidation negating the need for more servers and additional rack space furthermore it offers essential capabilities in terms of disaster recovery and potential savings on energy and maintenance costs however these benefits may be tempered by the increased complexities of securing virtual infrastructure do the benefits of virtualization',\n",
       " 'outweigh the risks in this study the authors evaluated the functionalities of the basic components of virtual datacenters identified the major risks to the data infrastructure and present here several solutions for overcoming potential threats to virtual infrastructure',\n",
       " 'modern societies can be understood as the intersection of four interdependent systems the natural environment of geography climate and weather the built environment of cities engineered systems and physical infrastructure the social environment of human populations communities and socioeconomic activities and an information ecosystem that overlays the other three domains and provides the means for understanding interacting with and managing the relationships between the natural built and human environments',\n",
       " 'as the nation and its communities become more connected networked and technologically sophisticated new challenges and opportunities arise that demand a rethinking of current approaches to public safety and emergency management addressing the current and future challenges requires an equally sophisticated program of research technology development and strategic planning the design and integration of intelligent infrastructureincluding embedded sensors the internet of things iot advanced wireless information',\n",
       " 'technologies realtime data capture and analysis and machinelearningbased decision supportholds the potential to greatly enhance public safety emergency management disaster recovery and overall community resilience while addressing new and emerging threats to public safety and security ultimately the objective of this program of research and development is to save lives reduce risk and disaster impacts permit efficient use of material and social resources and protect quality of life and economic stability',\n",
       " 'across entire regions',\n",
       " 'in this work a disaster management scheme based on cognitive radio ad hoc network crahn has been presented disaster management has been a big problem for mankind for years however still not much research work has been presented on this problem technology has been employed in past few years to address this problem cognitive radio ad hoc network presents a viable solution for disaster management it can be deployed rapidly without infrastructure and it solves the spectrum scarcity and congestion issues that',\n",
       " 'arise during disaster this paper presents a novel solution for disaster management it provides a multilayer perceptron mlp based disaster detection scheme based on wsn to solve the spectrum scarcity problem a mlp based spectrum management scheme has been proposed in order to ensure collaboration among rescue workers during disaster a novel service discovery scheme has been proposed to ensure interoperability during communication xml format has been recommended a realtime gui has been proposed to provide',\n",
       " 'shared situation awareness to rescue workers and enabling better decision making the proposed approach has been implemented in ns simulator the results show accurate disaster detection efficient spectrum usage and interoperability and collaboration among nodes with reduced latency',\n",
       " 'this paper presents an approach towards disaster management based on cognitive radio ad hoc network despite the growing interests on cognitive radio ad hoc networks not much work has been reported on using them for disaster management this paper discusses opportunities for disaster management based on cognitive radio ad hoc networks in this direction the paper presents a novel technique for disaster detection based on artificial neural network ann the ann is trained using backward propagation algorithm an',\n",
       " 'annbased spectrum sensing scheme is also presented finally a service discovery scheme is presented for coordination during the time of disaster the simulation of proposed approach has been performed in ns simulator the proposed approach shows very low false negative alarm rate using the proposed disaster detection system the spectrum switching time of spectrum sensing scheme is also analyzed along with an analysis of latency of proposed service discovery scheme',\n",
       " 'large wildfires pose a major environmental concern and precise maps of fire risk can improve disaster relief planning fosberg fire weather index ffwi is often used to measure wildfire risk ffwi exhibits nongaussian marginal distributions as well as strong spatiotemporal extremal dependence and thus modeling ffwi using geostatistical models like gaussian processes is questionable extreme value theory evtdriven models like maxstable processes are theoretically appealing but are computationally demanding and',\n",
       " 'applicable only for threshold exceedances or block maxima disaster management policies often consider moderatetoextreme quantiles of climate parameters and hence joint modeling of the bulk and the tail of the data is required in this paper we consider a dirichlet process mixture of spatial skewt processes that can flexibly model the bulk as well as the tail the proposed model has nonstationary mean and covariance structure and also nonzero spatiotemporal extremal dependence a simulation study demonstrates',\n",
       " 'that the proposed model has better spatial prediction performance compared to some competing models we develop spatial maps of ffwi medians and extremes and discuss the wildfire risk throughout the santa ana region of california',\n",
       " 'demands on the disaster response capacity of the european union are likely to increase as the impacts of disasters continue to grow both in size and frequency this has resulted in intensive research on issues concerning spatiallyexplicit information and modelling and their multiple sources of uncertainty geospatial support is one of the forms of assistance frequently required by emergency response centres along with hazard forecast and event management assessment robust modelling of natural hazards requires',\n",
       " 'dynamic simulations under an array of multiple inputs from different sources uncertainty is associated with meteorological forecast and calibration of the model parameters software uncertainty also derives from the data transformation models dtm needed for predicting hazard behaviour and its consequences on the other hand social contributions have recently been recognized as valuable in rawdata collection and mapping efforts traditionally dominated by professional organizations here an architecture overview',\n",
       " 'is proposed for adaptive and robust modelling of natural hazards following the semantic array programming paradigm to also include the distributed array of social contributors called citizen sensor in a semanticallyenhanced strategy for dtm modelling the modelling architecture proposes a multicriteria approach for assessing the array of potential impacts with qualitative rapid assessment methods based on a partial open loop feedback control polfc schema and complementing more traditional and accurate',\n",
       " 'aposteriori assessment we discuss the computational aspect of environmental risk modelling using arraybased parallel paradigms on high performance computing hpc platforms in order for the implications of urgency to be introduced into the systems urgenthpc',\n",
       " 'in order to account for large variance and fat tail of damage by natural disaster we study a simple model by combining distributions of disaster and populationproperty with their spatial correlation we assume fattailed or powerlaw distributions for disaster and populationproperty exposed to the disaster and a constant vulnerability for exposed populationproperty our model suggests that the fat tail property of damage can be determined either by that of disaster or by those of populationproperty depending on',\n",
       " 'which tail is fatter it is also found that the spatial correlations of populationproperty can enhance or reduce the variance of damage depending on how fat the tails of populationproperty are in case of tornadoes in the united states we show that the damage does have fat tail property our results support that the standard costbenefit analysis would not be reliable for social investment in vulnerability reduction and disaster prevention',\n",
       " 'natural disasters are a large threat for people especially in developing countries such as laos ictbased disaster management systems aim at supporting disaster warning and response efforts however the ability to directly communicate in both directions between local and administrative level is often not supported and a tight integration into administrative workflows is missing in this paper we present the smartphonebased disaster and reporting system mobile d it allows for bidirectional communication while',\n",
       " 'being fully involved in administrative processes we present the system setup and discuss integration into administrative structures in lao pdr',\n",
       " 'recent financial disasters have emphasised the need to accurately predict extreme financial losses and their consequences for the institutions belonging to a given financial market the ability of econometric models to predict extreme events strongly relies on their flexibility to account for the highly nonlinear and asymmetric dependence observed in financial returns we develop a new class of flexible copula models where the evolution of the dependence parameters follow a markovswitching generalised',\n",
       " 'autoregressive score sgasc dynamics maximum likelihood estimation is consistently performed using the inference functions for margins ifm approach and a version of the expectationmaximisation em algorithm specifically tailored to this class of models the sgasc models are then used to estimate the conditional valueatrisk covar which is defined as the var of a given asset conditional on another asset or portfolio being in financial distress and the conditional expected shortfall coes our empirical',\n",
       " 'investigation shows that the proposed sgasc models are able to explain and predict the systemic risk contribution of several european countries moreover we also find that the sgasc models outperform competitors using several covar backtesting procedures',\n",
       " 'social attachment theory states that individuals seek the proximity of attachment figures eg family members friends colleagues familiar places or objects when faced with threat during disasters this means that family members may seek each other before evacuating gather personal property before heading to familiar exits and places or follow groupscrowds etc this hardwired human tendency should be considered in the assessment of risk and the creation of disaster management plans doing so may result in more',\n",
       " 'realistic evacuation procedures and may minimise the number of casualties and injuries in this context a dynamic spatiotemporal analysis of seismic risk is presented using solace a multiagent model of pedestrian behaviour based on social attachment theory implemented using the beliefdesireintention approach the model focuses on the influence of human social physical and temporal factors on successful evacuation human factors considered include perception and mobility defined by age social factors are',\n",
       " 'defined by attachment bonds social groups population distribution and cultural norms physical factors refer to the location of the epicentre of the earthquake spatial distributionlayout and attributes of environmental objects such as buildings roads barriers cars placement of safe areas evacuation routes and the resulting debrisdamage from the earthquake experiments tested the influence of time of the day presence of disabled persons and earthquake intensity initial results show that factors that influence',\n",
       " 'arrivals in safe areas include a human factors age disability speed b preevacuation behaviours c perception distance social attachment time of day d social interaction during evacuation and e physical and spatial aspects such as limitations imposed by debris damage and the distance to safe areas to validate the results scenarios will be designed with stakeholders who will also take part in the definition of a serious game the recommendation of this research is that both social and physical aspects should be',\n",
       " 'considered when defining vulnerability in the analysis of risk',\n",
       " 'monitoring of disasters is crucial for mitigating their effects on the environment and human population and can be facilitated by the use of unmanned aerial vehicles uav equipped with camera sensors that produce aerial photos of the areas of interest a modern technique for recognition of events based on aerial photos is deep learning in this paper we present the state of the art work related to the use of deep learning techniques for disaster identification we demonstrate the potential of this technique in',\n",
       " 'identifying disasters with high accuracy by means of a relatively simple deep learning model based on a dataset of images containing disaster images such as fires earthquakes collapsed buildings tsunami and flooding as well as nondisaster scenes our results show an accuracy of achieved indicating that deep learning combined with uav equipped with camera sensors have the potential to predict disasters with high accuracy',\n",
       " 'power consumption is a critical consideration in high performance computing systems and it is becoming the limiting factor to build and operate petascale and exascale systems when studying the power consumption of existing systems running hpc workloads we find that power energy and performance are closely related which leads to the possibility to optimize energy consumption without sacrificing much or at all the performance in this paper we propose a hpc system running with a gnulinux os and a real time',\n",
       " 'resource manager rtrm that is aware and monitors the healthy of the platform on the system an application for disaster management runs the application can run with different qos depending on the situation we defined two main situations normal execution when there is no risk of a disaster even though we still have to run the system to look ahead in the near future if the situation changes suddenly in the second scenario the possibilities for a disaster are very high then the allocation of more resources for',\n",
       " 'improving the precision and the human decision has to be taken into account the paper shows that at design time it is possible to describe different optimal points that are going to be used at runtime by the rtos with the application this environment helps to the system that must run in saving energy with the tradeoff of losing precision the paper shows a model execution which can improve the precision of results by in average by increasing the number of iterations from e to e this also produces one order',\n",
       " 'of magnitude longer execution time which leads to the need to use a multinode solution the optimal tradeoff between precision vs execution time is computed by the rtos with the time overhead less than against a native execution',\n",
       " 'fires earthquakes floods hurricanes overcrowding or and even pandemic viruses endanger human lives hence designing infrastructures to handle possible emergencies has become an everincreasing need the safe evacuation of occupants from the building takes precedence when dealing with the necessary mitigation and disaster risk management this thesis deals with designing an iot system to provide safe and quick evacuation suggestions the iotbased evacuation system provides optimal evacuation paths that can be',\n",
       " 'continuously updated based on runtime sensory data so evacuation guidelines can be adjusted according to visitors occupants that evolve over time this thesis makes the following main contributions i addressing an up to date state of the art class for iot architectural styles and patterns ii proposing a set of selfadaptive iot patterns and assessing their specific quality attributes faulttolerance energy consumption and performance iii designing an iot infrastructure and testing its performance in both',\n",
       " 'realtime and designtime applications iv developing a network flow algorithm that facilitates minimizing the time necessary to evacuate people from a scene of a disaster v modeling various social agents and their interactions during an emergency to improve the iot system accordingly vi evaluating the system by using empirical and real case studies',\n",
       " 'people increasingly use microblogging platforms such as twitter during natural disasters and emergencies research studies have revealed the usefulness of the data available on twitter for several disaster response tasks however making sense of social media data is a challenging task due to several reasons such as limitations of available tools to analyze highvolume and highvelocity data streams this work presents an extensive multidimensional analysis of textual and multimedia content from millions of',\n",
       " 'tweets shared on twitter during the three disaster events specifically we employ various artificial intelligence techniques from natural language processing and computer vision fields which exploit different machine learning algorithms to process the data generated during the disaster events our study reveals the distributions of various types of useful information that can inform crisis managers and responders as well as facilitate the development of future automated systems for disaster management',\n",
       " 'although a lot of research has been done on utilising online social media during disasters there exists no system for a specific task that is critical in a postdisaster scenario identifying resourceneeds and resourceavailabilities in the disasteraffected region coupled with their subsequent matching to this end we present narmada a semiautomated platform which leverages the crowdsourced information from social media posts for assisting postdisaster relief coordination efforts the system employs natural',\n",
       " 'language processing and information retrieval techniques for identifying resourceneeds and resourceavailabilities from microblogs extracting resources from the posts and also matching the needs to suitable availabilities the system is thus capable of facilitating the judicious management of resources during postdisaster relief operations',\n",
       " 'traffic evacuation plays a critical role in saving lives in devastating disasters such as hurricanes wildfires floods earthquakes etc an ability to evaluate evacuation plans in advance for these rare events including identifying traffic flow bottlenecks improving traffic management policies and understanding the robustness of the traffic management policy are critical for emergency management given the rareness of such events and the corresponding lack of real data traffic simulation provides a flexible and',\n",
       " 'versatile approach for such scenarios and furthermore allows dynamic interaction with the simulated evacuation in this paper we build a traffic simulation pipeline to explore the above problems covering many aspects of evacuation including map creation demand generation vehicle behavior bottleneck identification traffic management policy improvement and results analysis we apply the pipeline to two case studies in california the first is paradise which was destroyed by a large wildfire in and experienced',\n",
       " 'catastrophic traffic jams during the evacuation the second is mill valley which has high risk of wildfire and potential traffic issues since the city is situated in a narrow valley',\n",
       " 'microgrids are resources that can be used to restore critical loads after a natural disaster enhancing resilience of a distribution network to deal with the stochastic nature of intermittent energy resources such as wind turbines wts and photovoltaics pvs many methods rely on forecast information however some microgrids may not be equipped with power forecasting tools to fill this gap a risklimiting strategy based on measurements is proposed gaussian mixture model gmm is used to represent a prior joint',\n",
       " 'probability density function pdf of power outputs of wts and pvs over multiple periods as time rolls forward the distribution of wtpv generation is updated based the latest measurement data in a recursive manner the updated distribution is used as an input for the risklimiting load restoration problem enabling an equivalent transformation of the original chance constrained problem into a mixed integer linear programming milp simulation cases on a distribution system with three microgrids demonstrate the',\n",
       " 'effectiveness of the proposed method results also indicate that networked microgrids have better uncertainty management capabilities than standalone microgrids',\n",
       " 'nowadays event extraction systems mainly deal with a relatively small amount of information about temporal and modal qualifications of situations primarily processing assertive sentences in the past tense however systems with a wider coverage of tense aspect and mood can provide better analyses and can be used in a wider range of text analysis applications this thesis develops such a system for turkish language this is accomplished by extending open source information mining and analysis optima research',\n",
       " 'groups event extraction software by implementing appropriate extensions in the semantic representation format by adding a partial grammar which improves the tam tense aspect and mood marker adverb analysis and matching functions of express and by constructing an appropriate lexicon in the standard of corleone these extensions are based on iv the theory of anchoring relations temurcu which is a crosslinguistically applicable semantic framework for analyzing tense aspect and mood related categories the result',\n",
       " 'is a system which can in addition to extracting basic event structures classify sentences given in news reports according to their temporal modal and volitionalillocutionary values although the focus is on news reports of natural disasters disease outbreaks and manmade disasters in turkish language the approach can be adapted to other languages domains and genres this event extraction and classification system with further developments can provide a basis for automated browsing systems for preventing',\n",
       " 'environmental and humanitarian risk',\n",
       " 'natural disasters affect hundreds of millions of people worldwide every year early warning humanitarian response and recovery mechanisms can be improved by using big data sources measuring the different dimensions of the impact of natural disasters is critical for designing policies and building up resilience detailed quantification of the movement and behaviours of affected populations requires the use of high granularity data that entails privacy risks leveraging all this data is costly and has to be done',\n",
       " 'ensuring privacy and security of large amounts of data proxies based on social media and data aggregates would streamline this process by providing evidences and narrowing requirements we propose a framework that integrates environmental data social media remote sensing digital topography and mobile phone data to understand different types of floods and how data can provide insights useful for managing humanitarian action and recovery plans thus data is dynamically requested upon databased indicators',\n",
       " 'forming a multigranularity and multiaccess data pipeline we present a composed study of three cases to show potential variability in the natures of floodingsas well as the impact and applicability of data sources critical heterogeneity of the available data in the different cases has to be addressed in order to design systematic approaches based on data the proposed framework establishes the foundation to relate the physical and socioeconomical impacts of floods',\n",
       " 'complex systems can fail through different routes often progressing through a series of ratelimiting steps and modified by environmental exposures the onset of disease cancer in particular is no different multistage models provide a simple but very general mathematical framework for studying the failure of complex systems or equivalently the onset of disease they include the armitage doll multistage cancer model as a particular case and have potential to provide new insights into how failures and disease',\n",
       " 'arise and progress a method described by et jaynes is developed to provide an analytical solution for a large class of these models and highlights connections between the convolution of laplace transforms sums of random variables and schwingerfeynman parameterisations examples include exact solutions to the armitagedoll model the sum of gammadistributed variables with integervalued shape parameters a clonalgrowth cancer model and a model for cascading disasters applications and limitations of the approach',\n",
       " 'are discussed in the context of recent cancer research the model is sufficiently general to be used in many contexts such as engineering project management disease progression and disaster risk for example allowing the estimation of failure rates in complex systems and projects the intended result is a mathematical toolkit for applying multistage models to the study of failure rates in complex systems and to the onset of disease cancer in particular',\n",
       " 'decisions related to electric power systems planning and operations rely on assumptions and insights informed by historic weather data and records of past performance evolving climate trends are however changing the energy use patterns and operating conditions of grid assets thus altering the nature and severity of risks the system faces because grid assets remain in operation for decades planning for evolving risks will require incorporating climate projections into grid infrastructure planning processes',\n",
       " 'the current work traces a pathway for climateaware decisionmaking in the electricity sector we evaluate the suitability of using existing climate models and data for electricity planning and discuss their limitations we review the interactions between grid infrastructure and climate by synthesizing what is known about how changing environmental operating conditions would impact infrastructure utilization constraints and performance we contextualize our findings by presenting a case study of california',\n",
       " 'examining if and where climate data can be integrated into infrastructure planning processes the core contribution of the work is a series of nine recommendations detailing advancements in climate projections grid modeling architecture and disaster preparedness that would be needed to ensure that infrastructure planning decisions are robust to uncertainty and risks associated with evolving climate conditions',\n",
       " 'natural hazards are becoming increasingly expensive as climate change and development are exposing communities to greater risks preparation and recovery are critical for climate change resilience and social media are being used more and more to communicate before during and after disasters while there is a growing body of research aimed at understanding how people use social media surrounding disaster events most existing work has focused on a single disaster case study in the present study we analyze five',\n",
       " 'of the costliest disasters in the last decade in the united states hurricanes irene and sandy two sets of tornado outbreaks and flooding in louisiana through the lens of twitter in particular we explore the frequency of both generic and specific foodsecurity related terms and quantify the relationship between network size and twitter activity during disasters we find differences in tweet volume for keywords depending on disaster type with people using twitter more frequently in preparation for hurricanes',\n",
       " 'and for realtime or recovery information for tornado and flooding events further we find that people share a host of general disaster and specific preparation and recovery terms during these events finally we find that among all account types individuals with average sized networks are most likely to share information during these disasters and in most cases do so more frequently than normal this suggests that around disasters an ideal form of social contagion is being engaged in which average people rather',\n",
       " 'than outsized influentials are key to communication these results provide important context for the type of disaster information and target audiences that may be most useful for disaster communication during varying extreme events',\n",
       " 'postdisaster inspections are critical to emergency management after earthquakes the availability of data on the condition of civil infrastructure immediately after an earthquake is of great importance for emergency management stakeholders require this information to take effective actions and to better recover from the disaster the datadriven shm has shown great promises to achieve this goal in near realtime there have been several proposals to automate the inspection process from different sources of input',\n",
       " 'using deep learning the existing models in the literature only provide a final prediction output while the risks of utilizing such models for safetycritical assessments should not be ignored this paper is dedicated to developing deep bayesian unets where the uncertainty of predictions is a second output of the model which is made possible through monte carlo dropout sampling in test time based on a gridlike data structure the concept of semantic damage segmentation sds is revisited compared to image',\n",
       " 'segmentation it is shown that a much higher level of precision is necessary for damage diagnosis to validate and test the proposed framework a benchmark dataset nonlinear response history analyses on a story bay d reinforced concrete moment frame is utilized compared to the benchmark sds model bayesian models exhibit superior robustness with enhanced global and mean class accuracies finally the models uncertainty output is studied by monitoring the softmax class variance of different predictions it is shown',\n",
       " 'that class variance correlates well with locations where the model makes mistakes this output can be used in combination with the prediction results to increase the reliability of this datadriven framework in structural inspections',\n",
       " 'the impact of extreme events across the globe is extraordinary which continues to handicap the advancement of the struggling developing societies and threatens most of the industrialized countries in the globe various fields of information and communication technology have widely been used for efficient disaster management but only to a limited extent though there is a tremendous potential for increasing efficiency and effectiveness in coping with disasters with the utilization of emerging wireless network',\n",
       " 'technologies early warning response to the particular situation and proper recovery are among the main focuses of an efficient disaster management system today considering these aspects in this paper we propose a framework for developing an efficient disaster management communications and information system dmcis which is basically benefited by the exploitation of the emerging wireless network technologies combined with other networking and data processing technologies',\n",
       " 'study of recurrences in earthquakes climate financial timeseries etc is crucial to better forecast disasters and limit their consequences however almost all the previous phenomenological studies involved only a longranged autocorrelation function or disregarded the multiscaling properties induced by potential higher order dependencies consequently they missed the facts that nonlinear dependences do impact both the statistics and dynamics of recurrence times and that scaling arguments for the unconditional',\n",
       " 'distribution may not be applicable we argue that copulas is the correct modelfree framework to study nonlinear dependencies in time series and related concepts like recurrences fitting andor simulating the intertemporal distribution of recurrence intervals is very much system specific and cannot actually benefit from universal features in contrast to the previous claims this has important implications in epilepsy prognosis and financial risk management applications',\n",
       " 'the globalization of trade and the organization of work are currently causing a large migratory flow towards the cities this growth of cities requires new urban planning where digital tools take a preponderant place to capture data and understand and decide in face of changes these tools however hardly resist to natural disasters terrorism accidents etc based on the expertise of the citi laboratory of insa lyon and sc of the industrial university of santander we propose to create the alert project',\n",
       " 'autonomous liable emergency service in real time with decentralized reliable and efficient services physically close to the citizens taking decisions locally in a relevant manner without risk of disconnection with a central authority these information gathering and decisionmaking will involve the population with participatory and social approaches',\n",
       " 'it is very easy to run applications in docker docker offers an ecosystem that offers a platform for application packaging distributing and managing within containers however docker platform is yet not matured presently docker is less secured as compare to virtual machines vm and most of the other cloud technologies the key of reason of docker inadequate security protocols is containers sharing of linux kernel which can lead to risk of privileged escalations this research is going to outline some major',\n",
       " 'security vulnerabilities at docker and counter solutions to neutralize such attacks there are variety of security attacks like insider and outsider this research will outline both types of attacks and their mitigations strategies taking some precautionary measures can save from huge disasters this research will also present docker secure deployment guidelines these guidelines will suggest different configurations to deploy docker containers in a more secure way',\n",
       " 'during and after disasters highways provide vital routes for emergency services relief efforts and evacuation activities thus a timely and reliable assessment of disaster impacts on highways is critical for decisionmakers to quickly and effectively perform relief and recovery efforts recently social media has increasingly been used in disaster management for obtaining a rapid publiccentric assessment of disaster impacts due to its near realtime social and informational characteristics although promising the',\n",
       " 'employment of social media for assessing disaster impacts on highways is still limited due to the inability of extracting accurate highwayrelated data from social media to overcome this limitation a systematic approach is proposed to identify highwayrelated data from social media for assessing disaster impacts on highways and a case study of hurricane harvey in houston tx is employed for the demonstration the approach is constructed through three steps building data sources for social media and highways of',\n",
       " 'interest in houston respectively adapting the social media data to each highway through a developed mapping algorithm assessing disaster impacts through analyzing social media activities in terms of their intensity geographic and topic distributions results show that the proposed approach is capable of capturing the temporal patterns of disaster impacts on highways official news and reports are employed to validate the assessed impacts',\n",
       " 'earth observation technologies such as optical imaging and synthetic aperture radar sar provide excellent means to monitor evergrowing urban environments continuously notably in the case of largescale disasters eg tsunamis and earthquakes in which a response is highly timecritical images from both data modalities can complement each other to accurately convey the full damage condition in the disasters aftermath however due to several factors such as weather and satellite coverage it is often uncertain which',\n",
       " 'data modality will be the first available for rapid disaster response efforts hence novel methodologies that can utilize all accessible eo datasets are essential for disaster management in this study we have developed a global multisensor and multitemporal dataset for building damage mapping we included building damage characteristics from three disaster types namely earthquakes tsunamis and typhoons and considered three building damage categories the global dataset contains highresolution optical imagery',\n",
       " 'and hightomoderateresolution multiband sar data acquired before and after each disaster using this comprehensive dataset we analyzed five data modality scenarios for damage mapping singlemode optical and sar datasets crossmodal predisaster optical and postdisaster sar datasets and mode fusion scenarios we defined a damage mapping framework for the semantic segmentation of damaged buildings based on a deep convolutional neural network algorithm we compare our approach to another stateoftheart baseline model',\n",
       " 'for damage mapping the results indicated that our dataset together with a deep learning network enabled acceptable predictions for all the data modality scenarios',\n",
       " 'communication networks such as core optical networks heavily depend on their physical infrastructure and hence they are vulnerable to manmade disasters such as electromagnetic pulse emp or weapons of mass destruction wmd attacks as well as to natural disasters largescale disasters may cause huge data loss and connectivity disruption in these networks as our dependence on network services increases the need for novel survivability methods to mitigate the effects of disasters on communication networks becomes',\n",
       " 'a major concern softwaredefined networking sdn by centralizing control logic and separating it from physical equipment facilitates network programmability and opens up new ways to design disasterresilient networks on the other hand to fully exploit the potential of sdn along with dataplane survivability we also need to design the control plane to be resilient enough to survive network failures caused by disasters several distributed sdn controller architectures have been proposed to mitigate the risks of',\n",
       " 'overload and failure but they are optimized for limited faults without addressing the extent of largescale disaster failures for disaster resiliency of the control plane we propose to design it as a virtual network which can be solved using virtual network mapping techniques we select appropriate mapping of the controllers over the physical network such that the connectivity among the controllers controllertocontroller and between the switches to the controllers switchtocontrollers is not compromised by',\n",
       " 'physical infrastructure failures caused by disasters we formally model this disasteraware controlplane design and mapping problem and demonstrate a significant reduction in the disruption of controllertocontroller and switchtocontroller communication channels using our approach',\n",
       " 'thousands of human lives are lost every year around the globe apart from significant damage on property animal life etc due to natural disasters eg earthquake flood tsunami hurricane and other storms landslides cloudburst heat wave forest fire in this paper we focus on reviewing the application of data mining and analytical techniques designed so far for i prediction ii detection and iii development of appropriate disaster management strategy based on the collected data from disasters a detailed description',\n",
       " 'of availability of data from geological observatories seismological hydrological satellites remote sensing and newer sources like social networking sites as twitter is presented an extensive and indepth literature study on current techniques for disaster prediction detection and management has been done and the results are summarized according to various types of disasters finally a framework for building a disaster management database for india hosted on open source big data platform like hadoop in a',\n",
       " 'phased manner has been proposed the study has special focus on india which ranks among top five counties in terms of absolute number of the loss of human life',\n",
       " 'peatland fires and haze events are disasters with national regional and international implications the phenomena lead to direct damage to local assets as well as broader economic and environmental losses satellite imagery is still the main and often the only available source of information for disaster management in this article we test the potential of social media to assist disaster management to this end we compare insights from two datasets fire hotspots detected via nasa satellite imagery and almost',\n",
       " 'all gpsstamped tweets from sumatra island indonesia posted during sumatra island is chosen as it regularly experiences a significant number of haze events which affect citizens in indonesia as well as in nearby countries including malaysia and singapore we analyse temporal correlations between the datasets and their geospatial interdependence furthermore we show how twitter data reveals changes in users behavior during severe haze events overall we demonstrate that social media is a valuable source of',\n",
       " 'complementary and supplementary information for haze disaster management based on our methodology and findings an analytics tool to improve peatland fire and haze disaster management by the indonesian authorities is under development',\n",
       " 'when major disaster occurs the questions are raised how to estimate the damage in time to support the decision making process and relief efforts by local authorities or humanitarian teams in this paper we consider the use of machine learning and computer vision on remote sensing imagery to improve time efficiency of assessment of damaged buildings in disaster affected area we propose a general workflow that can be useful in various disaster management applications and demonstrate the use of the proposed',\n",
       " 'workflow for the assessment of the damage caused by the wildfires in california in',\n",
       " 'modern financial networks are characterized by complex structures of mutual obligations such interconnections may propagate and amplificate individual defaults leading in some cases to financial disaster for this reason mathematical models for the study and control of systemic risk the risk of severe instabilities on the system as a whole due to default of single entities have attracted considerable research attention in recent years one important line of research is concerned with mechanisms of clearing',\n",
       " 'that is the mechanism by which mutual debts are repaid in the regular regime or in a default regime one of the first models of a clearing mechanism was proposed by eisenberg and noe and is based on the three rules limited liability the priority of debt claims over the shareholders interests and the equal priority of debts prorata rule these three principles naturally lead to the concept of clearing vector the vector of the entities total payments in this paper we propose a necessary and sufficient condition',\n",
       " 'for the uniqueness of clearing vector applicable to an arbitrary topology of the financial network further we show that the overall system loss can be reduced if one relaxes the prorata rule and replaces the clearing vector by a matrix of clearing payments this approach shifts the focus from the individual interest to the system or social interest in order to control and contain the adverse effects of cascaded failures',\n",
       " 'the lack of a comprehensive decisionmaking approach at the community level is an important problem that warrants immediate attention networklevel decisionmaking algorithms need to solve largescale optimization problems that pose computational challenges the complexity of the optimization problems increases when various sources of uncertainty are considered this research introduces a sequential discrete optimization approach as a decisionmaking framework at the community level for recovery management the',\n",
       " 'proposed mathematical approach leverages approximate dynamic programming along with heuristics for the determination of recovery actions our methodology overcomes the curse of dimensionality and manages multistate largescale infrastructure systems following disasters we also provide computational results showing that our methodology not only incorporates recovery policies of responsible public and private entities within the community but also substantially enhances the performance of their underlying',\n",
       " 'strategies with limited resources the methodology can be implemented efficiently to identify nearoptimal recovery decisions following a severe earthquake based on multiple objectives for an electrical power network of a testbed community coarsely modeled after gilroy california united states the proposed optimization method supports riskinformed community decision makers within chaotic posthazard circumstances',\n",
       " 'risk is part of the fabric of every business surprisingly there is little work on establishing best practices for systematic repeatable risk identification arguably the first step of any risk management process in this paper we present a proposal that constitutes a more holistic risk management approach a methodology for computersupported risk identification is proposed that may lead to more consistent objective repeatable risk analysis',\n",
       " 'without sufficient preparation and onsite management the mass scale unexpected huge human crowd is a serious threat to public safety a recent impressive tragedy is the shanghai stampede where people were killed and were injured in celebration of the new years eve on december th in the shanghai bund due to the innately stochastic and complicated individual movement it is not easy to predict collective gatherings which potentially leads to crowd events in this paper with leveraging the big data generated on',\n",
       " 'baidu map we propose a novel approach to early warning such potential crowd disasters which has profound public benefits an insightful observation is that with the prevalence and convenience of mobile map service users usually search on the baidu map to plan a routine therefore aggregating users query data on baidu map can obtain priori and indication information for estimating future human population in a specific area ahead of time our careful analysis and deep investigation on the baidu map data on',\n",
       " 'various events also demonstrates a strong correlation pattern between the number of map query and the number of positioning users in an area based on such observation we propose a decision method utilizing query data on baidu map to invoke warnings for potential crowd events about hours in advance then we also construct a machine learning model with heterogeneous data such as query data and mobile positioning data to quantitatively measure the risk of the potential crowd disasters we evaluate the',\n",
       " 'effectiveness of our methods on the data of baidu map',\n",
       " 'due to their often unexpected nature natural and manmade disasters are difficult to monitor and detect for journalists and disaster management response teams journalists are increasingly relying on signals from social media to detect such stories in their early stage of development twitter which features a vast network of local news outlets is a major source of early signal for disaster detection journalists who work for global desks often follow these sources via twitters lists but have to comb through',\n",
       " 'thousands of smallscale or lowimpact stories to find events that may be globally relevant these are events that have a large scope high impact or potential geopolitical relevance we propose a model for automatically identifying events from local news sources that may break on a global scale within the next hours the results are promising and can be used in a predictive setting to help journalists manage their sources more effectively or in a descriptive manner to analyze media coverage of disasters through',\n",
       " 'the feature evaluation process we also address the question what makes a disaster event newsworthy on a global scale as part of our data collection process we have created a list of local sources of disasteraccident news on twitter which we have made publicly available',\n",
       " 'data backup in data center networks dcns is critical to minimize the data loss under disaster this paper considers the costefficient data backup for dcns against a disaster with varepsilon early warning time given geodistributed dcns and such a varepsilontime early warning disaster we investigate the issue of how to back up the data in dcn nodes under risk to other safe dcn nodes within the varepsilon early warning time constraint which is significant because it is an emergency data protection scheme',\n",
       " 'against a predictable disaster and also help dcn operators to build a complete backup scheme ie regular backup and emergency backup specifically an integer linear program ilpbased theoretical framework is proposed to identify the optimal selections of backup dcn nodes and data transmission paths such that the overall data backup cost is minimized extensive numerical results are also provided to illustrate the proposed framework for dcn data backup',\n",
       " 'the objective of this study is to examine spatial patterns of impacts and recovery of communities based on variances in credit card transactions such variances could capture the collective effects of household impacts disrupted accesses and business closures and thus provide an integrative measure for examining disaster impacts and community recovery in disasters existing studies depend mainly on survey and sociodemographic data for disaster impacts and recovery effort evaluations although such data has',\n",
       " 'limitations including large data collection efforts and delayed timeliness results in addition there are very few studies have concentrated on spatial patterns and disparities of disaster impacts and shortterm recovery of communities although such investigation can enhance situational awareness during disasters and support the identification of disparate spatial patterns of disaster impacts and recovery in the impacted regions this study examines credit card transaction data harris county texas usa during',\n",
       " 'hurricane harvey in to explore spatial patterns of disaster impacts and recovery during from the perspective of community residents and businesses at zip code and county scales respectively and to further investigate their spatial disparities across zip codes the results indicate that individuals in zip codes with populations of higher income experienced more severe disaster impact and recovered more quickly than those located in lowerincome zip codes for most business sectors our findings not only enhance',\n",
       " 'the understanding of spatial patterns and disparities in disaster impacts and recovery for better community resilience assessment but also could benefit emergency managers city planners and public officials in harnessing population activity data using credit card transactions as a proxy for activity to improve situational awareness and resource allocation',\n",
       " 'in an increasingly complex mobile and interconnected world we face growing threats of disasters whether by chance or deliberately disruption of coordinated response and recovery efforts due to organizational technical procedural random or deliberate attack could result in the risk of massive loss of life this requires urgent action to explore the development of optimal informationsharing environments for promoting collective disaster response and preparedness using multijurisdictional hierarchical networks',\n",
       " 'innovative approaches to information flow modeling and analysis for dealing with challenges of coordinating across multi layered agency structures as well as development of early warnings through social systems using social media analytics may be pivotal to timely responses to dealing with large scale disasters where response strategies need to be viewed as a shared responsibility how do facilitate the development of collective disaster response in a multijurisdictional setting how do we develop and test',\n",
       " 'the level and effectiveness of shared multijurisdictional hierarchical networks for improved preparedness and response what is the role of multi layered training and exercises in building the shared learning space for collective disaster preparedness and response the aim of this is therefore to determine factors that may be responsible for affecting disaster response',\n",
       " 'this research presented a novel resiliencebased framework to support resilience planning regarding predisaster mitigation and postdisaster recovery first the author proposes a new performance metric for transportation network weighted number of independent pathways wipw integrating the network topology redundancy level traffic patterns structural reliability of network components and functionality of the network during communitys postdisaster recovery in a systematical way to the best of our knowledge wipw',\n",
       " 'is the only performance metric that permits risk mitigation alternatives for improving transportation network resilience to be compared on a common basis based on the wipw a decision methodology of prioritizing transportation network retrofit projects is developed second our studies extend from predisaster mitigation to posthazard recovery in which this research presents two metrics to evaluate the restoration over the horizon after disasters that is total recovery time and the skew of the recovery',\n",
       " 'trajectory both metrics are involved in the multiobjective stochastic optimization problem of restoration scheduling the metrics provided a new dimension to evaluate the relative efficiency of alternative network recovery strategies the author then develops a restoration scheduling methodology for network postdisaster recovery that minimizes the overall network recovery time and optimizes the recovery trajectory which ultimately will reduce economic losses due to network service disruption',\n",
       " 'the maintenance of system flow is critical for effective network operation any type of disruption to network facilities arcsnodes potentially risks loss of service leaving users without access to important resources it is therefore an important goal of planners to assess infrastructures for vulnerabilities identifying those vital nodesarcs whose debilitation would compromise the most sourcesink st interaction or system flow due to the budgetary limitations of disaster management agencies',\n",
       " 'protectionfortification and planning for the recovery of these vital infrastructure facilities is a logical and efficient proactive approach to reducing worstcase risk of service disruption given damage to a network evaluating the potential for flow between st pairs requires assessing the availability of an operational st path recent models proposed for identifying infrastructure vital to system flow have relied on enumeration of all st paths to support this task this paper proposes an alternative model',\n",
       " 'constraint structure that does not require complete enumeration of st paths providing computational benefits over existing models to illustrate the model an application to a practical infrastructure planning problem is presented',\n",
       " 'mitigating the risk arising from extreme events is a fundamental goal with many applications such as the modelling of natural disasters financial crashes epidemics and many others to manage this risk a vital step is to be able to understand or generate a wide range of extreme scenarios existing approaches based on generative adversarial networks gans excel at generating realistic samples but seek to generate typical samples rather than extreme samples hence in this work we propose exgan a ganbased approach',\n",
       " 'to generate realistic and extreme samples to model the extremes of the training distribution in a principled way our work draws from extreme value theory evt a probabilistic approach for modelling the extreme tails of distributions for practical utility our framework allows the user to specify both the desired extremeness measure as well as the desired extremeness probability they wish to sample at experiments on real us precipitation data show that our method generates realistic samples based on visual',\n",
       " 'inspection and quantitative measures in an efficient manner moreover generating increasingly extreme examples using exgan can be done in constant time with respect to the extremeness probability tau as opposed to the mathcalofrac tau time required by the baseline approach',\n",
       " 'this paper describes the current taxonomy of model risk ways for its mitigation and management and the importance of the model validation function in collaboration with other departments to design and implement them',\n",
       " 'droughts are a recurring hazard in subsaharan africa that can wreak huge socioeconomic costsacting early based on alerts provided by early warning systems ews can potentially provide substantial mitigation reducing the financial and human cost however existing ews tend only to monitor current rather than forecast future environmental and socioeconomic indicators of drought and hence are not always sufficiently timely to be effective in practice here we present a novel method for forecasting satellitebased',\n",
       " 'indicators of vegetation condition specifically we focused on the month vegetation condition index vci m over pastoral livelihood zones in kenya which is the indicator used by the kenyan national drought management authorityndma using data from modis and landsat we apply linear autoregression and gaussian process modeling methods and demonstrate high forecasting skill several weeks ahead as a benchmark we predicted the drought alert marker used by ndma vci m both of our models were able to predict this',\n",
       " 'alert marker four weeks ahead with a hit rate of around and a false alarm rate of around or and respectively six weeks ahead the methods developed here can thus identify a deteriorating vegetation condition well and sufficiently in advance to help disaster risk managers act early to support vulnerable communities and limit the impact of a drought hazard',\n",
       " 'in recent years we have been faced with a series of natural disasters causing a tremendous amount of financial environmental and human losses the unpredictable nature of natural disasters behavior makes it hard to have a comprehensive situational awareness sa to support disaster management using opinion surveys is a traditional approach to analyze public concerns during natural disasters however this approach is limited expensive and timeconsuming luckily the advent of social media has provided scholars',\n",
       " 'with an alternative means of analyzing public concerns social media enable users people to freely communicate their opinions and disperse information regarding current events including natural disasters this research emphasizes the value of social media analysis and proposes an analytical framework twitter situational awareness twisa this framework uses text mining methods including sentiment analysis and topic modeling to create a better sa for disaster preparedness response and recovery twisa has also',\n",
       " 'effectively deployed on a large number of tweets and tracks the negative concerns of people during the south carolina flood',\n",
       " 'disaster management demands a near realtime information dissemination so that the emergency services can be provided to the right people at the right time recent advances in information and communication technologies enable collection of realtime information from various sources for example sensors deployed in the fields collect data about the environment similarly social networks like twitter and facebook can help to collect data from people in the disaster zone on one hand inadequate situation awareness',\n",
       " 'in disasters has been identified as one of the primary factors in human errors with grave consequences such as loss of lives and destruction of critical infrastructure on the other hand the growing ubiquity of social media and mobile devices and pervasive nature of the internetofthings means that there are more sources of outbound traffic which ultimately results in the creation of a data deluge beginning shortly after the onset of disaster events leading to the problem of information tsunami in addition',\n",
       " 'security and privacy has crucial role to overcome the misuse of the system for either intrusions into data or overcome the misuse of the information that was meant for a specified purpose in this chapter we provide such a situation aware application to support disaster management data lifecycle ie from data ingestion and processing to alert dissemination we utilize cloud computing internet of things and social computing technologies to achieve a scalable efficient and usable situationaware application',\n",
       " 'called cloud bigdata',\n",
       " 'data management has always been a multidomain problem even in the simplest cases it involves quality of service security resource management cost management incident identification disaster avoidance andor recovery as well as many other concerns in our case this situation gets ever more complicated because of the divergent nature of a cloud federation like basmati in this federation the basmati unified data management framework budamaf tries to create an automated uniform way of managing all the data',\n",
       " 'transactions as well as the data stores themselves in a polyglot multicloud consisting of a plethora of different machines and data store systems',\n",
       " 'efficient communications are crucial for disaster response and recovery however most current public safety land mobile radio lmr networks only provide narrowband voice service with limited support of lowspeed data services in this paper we study to enhance the interoperability of lmr with commercial wireless cellular networks by which a wide variety of benefits can be offered to disaster responders including new multimedia services increased data rates and low cost devices our approach is based on session',\n",
       " 'initial protocol sip and a joint radio resource management framework in addition an optimal radio resource management scheme is proposed to maximize the overall radio resource utilization and at the same time guarantee service availability and continuity quality of service qos for disaster responders the effectiveness of the proposed approach is illustrated by numerical examples',\n",
       " 'in this paper we look at the efficacy of different risk measures on energy markets and across several different stock market indices we use both the value at risk and the tail conditional expectation on each of these data sets we also consider several different durations and levels for historical risk measures through our results we make some recommendations for a robust risk management strategy that involves historical risk measures',\n",
       " 'in many scheduling applications minimizing delays is of high importance one adverse effect of such delays is that the reward for completion of a job may decay over time indeed in healthcare settings delays in access to care can result in worse outcomes such as an increase in mortality risk motivated by managing hospital operations in disaster scenarios as well as other applications in perishable inventory control and information services we consider nonpreemptive scheduling of jobs whose internal value',\n",
       " 'decays over time because solving for the optimal scheduling policy is computationally intractable we focus our attention on the performance of three intuitive heuristics a policy which maximizes the expected immediate reward a policy which maximizes the expected immediate reward rate and a policy which prioritizes jobs with imminent deadlines we provide performance guarantees for all three policies and show that many of these performance bounds are tight in addition we provide numerical experiments and',\n",
       " 'simulations to compare how the policies perform in a variety of scenarios our theoretical and numerical results allow us to establish rulesofthumb for applying these heuristics in a variety of situations including patient scheduling scenarios',\n",
       " 'wildfires are natural disasters capable of damaging economies and communities when wildfires become uncontrollable incident manager teams imts dispatch response vehicles to key assets to undertake protective tasks and so mitigate the risk to these assets in developing a deployment plan under severe time pressure imts need to consider the special requirements of each asset the resources vehicles and their teams as well as uncertainties associated with the wildfire a common situation that arises in southern',\n",
       " 'australian wildfires is a wind change there is a reliable forecast of a wind change but some uncertainty around the timing of that change to assist imts to deal with this situation we develop a twostage stochastic model to integrate such an uncertainty with the complexities of asset protection operations this is the first time a mathematical model is proposed which considers uncertainty in the timing of a scenario change the model is implemented for a case study that uses the context of the black saturday',\n",
       " 'bushfires in victoria a new set of benchmark instances is generated using realistic wildfire attributes to test the computational tractability of our model and the results compared to a dynamic rerouting approach the computations reveal that compared with dynamic rerouting the new model can generate better deployment plans the model can achieve solutions in operational time for realisticsized problems although for larger problems the suboptimal rerouting algorithm would still need to be deployed',\n",
       " 'wildfires are one of the costliest and deadliest natural disasters in the us causing damage to millions of hectares of forest resources and threatening the lives of people and animals of particular importance are risks to firefighters and operational forces which highlights the need for leveraging technology to minimize danger to people and property flame fire luminosity airbornebased machine learning evaluation offers a dataset of aerial images of fires along with methods for fire detection and',\n",
       " 'segmentation which can help firefighters and researchers to develop optimal fire management strategies this paper provides a fire image dataset collected by drones during a prescribed burning piled detritus in an arizona pine forest the dataset includes video recordings and thermal heatmaps captured by infrared cameras the captured videos and images are annotated and labeled framewise to help researchers easily apply their fire detection and modeling algorithms the paper also highlights solutions to two',\n",
       " 'machine learning problems binary classification of video frames based on the presence and absence of fire flames an artificial neural network ann method is developed that achieved a classification accuracy fire detection using segmentation methods to precisely determine fire borders a deep learning method is designed based on the unet upsampling and downsampling approach to extract a fire mask from the video frames our flame method approached a precision of and a recall of future research will expand the',\n",
       " 'technique for free burning broadcast fire using thermal images',\n",
       " 'this paper presents a case for the adoption of an informationcentric architecture for a global disaster management system drawing from a case study of the queensland floods we describe the challenges in providing every participant with relevant and actionable information we use various examples to argue for a more flexible information dissemination framework which is designed from the ground up to minimise the effort needed to fix the unexpected and unavoidable information acquisition quality and',\n",
       " 'dissemination challenges posed by any real disaster',\n",
       " 'this report reviews the edinburgh tram projects risk management projects frequently overrun their cost and timelines and fall short on intended benefits cost schedule and benefit risk of projects need to be carefully considered to avoid this the report describes and evaluates risk assessment and management for the edinburgh tram the report was produced as part of the edinburgh tram inquiry keywords risk assessment risk management infrastructure megaprojects optimism bias strategic misrepresentation planning',\n",
       " 'fallacy behavioral science',\n",
       " 'datacenter networks and services are at risk in the face of disasters existing faulttolerant storage services cannot even achieve a nil recovery point objective rpo as clientgenerated data may get lost before the termination of their migration across georeplicated datacenters sdn has proved instrumental in exploiting applicationlevel information to optimise the routing of information in this paper we propose software defined edge sde or the implementation of sdn at the network edge to achieve nil rpo we',\n",
       " 'illustrate our proposal with a faulttolerant keyvalue store that experimentally recovers from disaster within s although sde is inherently faulttolerant and scalable its deployment raises new challenges on the partnership between isps and cdn providers we conclude that failure detection information at the sdnlevel can effectively benefit applications to recover from disaster',\n",
       " 'spectral risk measures are attractive risk measures as they allow the user to obtain risk measures that reflect their riskaversion functions to date there has been very little guidance on the choice of riskaversion functions underlying spectral risk measures this paper addresses this issue by examining two popular risk aversion functions based on exponential and power utility functions respectively we find that the former yields spectral risk measures with nice intuitive properties but the latter yields',\n",
       " 'spectral risk measures that can have perverse properties more work therefore needs to be done before we can be sure that arbitrary but respectable utility functions will always yield wellbehaved spectral risk measures',\n",
       " 'attribution of responsibility and blame are important topics in political science especially as individuals tend to think of political issues in terms of questions of responsibility and as blame carries far more weight in voting behavior than that of credit however surprisingly there is a paucity of studies on the attribution of responsibility and blame in the field of disaster research the flint water crisis is a story of government failure at all levels by studying microblog posts about it we understand',\n",
       " 'how citizens assign responsibility and blame regarding such a manmade disaster online we form hypotheses based on social scientific theories in disaster research and then operationalize them on unobtrusive observational social media data in particular we investigate the following phenomena the source for blame the partisan predisposition the concerned geographies and the contagion of complaining this paper adds to the sociology of disasters research by exploiting a new rarely used data source the social web',\n",
       " 'and by employing new computational methods such as sentiment analysis and retrospective cohort study design on this new form of data in this regard this work should be seen as the first step toward drawing more challenging inferences on the sociology of disasters from big social data',\n",
       " 'the usage of nonauthoritative data for disaster management presents the opportunity of accessing timely information that might not be available through other means as well as the challenge of dealing with several layers of biases wikipedia a collaborativelyproduced encyclopedia includes indepth information about many natural and humanmade disasters and its editors are particularly good at adding information in realtime as a crisis unfolds in this study we focus on the english version of wikipedia that is by',\n",
       " 'far the most comprehensive version of this encyclopedia wikipedia tends to have good coverage of disasters particularly those having a large number of fatalities however we also show that a tendency to cover events in wealthy countries and not cover events in poorer ones permeates wikipedia as a source for disasterrelated information by performing careful automatic content analysis at a large scale we show how the coverage of floods in wikipedia is skewed towards rich englishspeaking countries in particular',\n",
       " 'the us and canada we also note how coverage of floods in countries with the lowest income as well as countries in south america is substantially lower than the coverage of floods in middleincome countries these results have implications for systems using wikipedia or similar collaborative media platforms as an information source for detecting emergencies or for gathering valuable information for disaster response',\n",
       " 'in this paper the fractional trading ansatz of money management is reconsidered with special attention to chance and risk parts in the goal function of the related optimization problem by changing the goal function with due regards to other risk measures like current drawdowns the optimal fraction solutions reflect the needs of risk averse investors better than the original optimal f solution of ralph vince keywords fractional trading optimal f current drawdown terminal wealth relative risk aversion',\n",
       " 'risk analytics is important to quantify manage and analyse risks from the manufacturing to the financial setting in this paper the data challenges in the three stages of the highperformance risk analytics pipeline namely risk modelling portfolio risk management and dynamic financial analysis is presented',\n",
       " 'digital currencies and cryptocurrencies have hesitantly started to penetrate the investors and the next step will be the regulatory risk management framework we examine the valueatrisk and expected shortfall properties for the major digital currencies bitcoin ethereum litecoin and ripple the methodology used is garch modelling followed by filtered historical simulation we find that digital currencies are subject to a higher risk therefore to higher sufficient buffer and risk capital to cover potential',\n",
       " 'losses',\n",
       " 'risk diversification is one of the dominant concerns for portfolio managers various portfolio constructions have been proposed to minimize the risk of the portfolio under some constrains including expected returns we propose a portfolio construction method that incorporates the complex valued principal component analysis into the risk diversification portfolio construction the proposed method is verified to outperform the conventional risk parity and risk diversification portfolio constructions',\n",
       " 'locationbased augmented reality games have entered the mainstream with the nearly overnight success of niantics pokemon go unlike traditional video games the fact that players of such games carry out actions in the external physical world to accomplish ingame objectives means that the largescale adoption of such games motivate people en masse to do things and go places they would not have otherwise done in unprecedented ways the social implications of such massmobilisation of individual players are in',\n",
       " 'general difficult to anticipate or characterise even for the shortterm in this work we focus on disaster relief and the short and longterm implications that a proliferation of ar games like pokemon go may have in disasterprone regions of the world we take a distributed cognition approach and focus on one natural disasterprone region of new zealand the city of wellington',\n",
       " 'during natural or manmade disasters humanitarian response organizations look for useful information to support their decisionmaking processes social media platforms such as twitter have been considered as a vital source of useful information for disaster response and management despite advances in natural language processing techniques processing short and informal twitter messages is a challenging task in this paper we propose to use deep neural network dnn to address two types of information needs of',\n",
       " 'response organizations identifying informative tweets and classifying them into topical classes dnns use distributed representation of words and learn the representation as well as higher level features automatically for the classification task we propose a new online algorithm based on stochastic gradient descent to train dnns in an online fashion during disaster situations we test our models using a crisisrelated realworld twitter dataset',\n",
       " 'physical media like surveillance cameras and social media like instagram and twitter may both be useful in attaining ontheground information during an emergency or disaster situation however the intersection and reliability of both surveillance cameras and social media during a natural disaster are not fully understood to address this gap we tested whether social media is of utility when physical surveillance cameras went offline during hurricane irma in specifically we collected and compared geotagged',\n",
       " 'instagram and twitter posts in the state of florida during times and in areas where public surveillance cameras went offline we report social media content and frequency and content to determine the utility for emergency managers or first responders during a natural disaster',\n",
       " 'risk including economic risk is increasingly a concern for public policy and management the possibility of dealing effectively with risk is hampered however by lack of a sound empirical basis for risk assessment and management the paper demonstrates the general point for cost and demand risks in urban rail projects the paper presents empirical evidence that allow valid economic risk assessment and management of urban rail projects including benchmarking of individual or groups of projects benchmarking of',\n",
       " 'the copenhagen metro is presented as a case in point the approach developed is proposed as a model for other types of policies and projects in order to improve economic and financial risk assessment and management in policy and planning',\n",
       " 'this paper presents a methodology for freight traffic assignment in a largescale roadrail intermodal network under uncertainty network uncertainties caused by natural disasters have dramatically increased in recent years several of these disasters eg hurricane sandy mississippi river flooding hurricane harvey severely disrupted the us freight transport network and consequently the supply chain to account for these network uncertainties a stochastic freight traffic assignment model is formulated an',\n",
       " 'algorithmic framework involving the sample average approximation and gradient projection algorithm is proposed to solve this challenging problem the developed methodology is tested on the us intermodal network with freight flow data from the freight analysis framework the experiments consider four types of natural disasters that have different risks and impacts on the transportation network earthquake hurricane tornado and flood the results demonstrate the feasibility of the model and algorithmic framework',\n",
       " 'to obtain freight flows for a realisticsized network in reasonable time between and minutes it is found that for all disaster scenarios the freight tonmiles are higher compared to the base case without uncertainty the increase in freight tonmiles is the highest under the flooding scenario this is due to the fact that there are more states in the floodrisk areas and they are scattered throughout the us',\n",
       " 'we present a cognitive model of opinion dynamics which studies the behavior of a population of interacting individuals in the context of risk of natural disaster in particular we investigate the response of the individuals to the information received by institutional sources about the correct behaviors for prevention and harm reduction the results of our study show that alarmist opinions are more likely to be adopted by populations since worried people',\n",
       " 'disaster management dm is a complex set of interrelated activities the activities are often knowledge intensive and time sensitive sharing the required knowledge timely is critical for dm in developed countries for recurring disasters eg floods there are dedicated document repositories of disaster management plans dmp that can be accessed as needs arise however accessing the appropriate plan in a timely manner and sharing activities between plans often requires domain knowledge and intimate knowledge of the',\n",
       " 'plans in the first place in this paper we introduce an agentbased knowledge analysis method to convert dmps into a collection of knowledge units that can be stored into a unified repository the repository of dm actions then enables the mixing and matching knowledge between different plans the repository is structured as a layered abstraction according to meta object facility mof we use the flood management plans used by ses in nsw to illustrate and give a preliminary validation of the approach it is',\n",
       " 'illustrated using dmps along the flood prone murrumbidgee river in central nsw',\n",
       " 'in this paper we present a versatile method for the investigation of interaction networks and show how to use it to assess effects of indirect interactions and feedback loops the method allows to evaluate the impact of optimization measures or failures on the system here we will apply it to the investigation of catastrophes in particular to the temporal development of disasters catastrophe dynamics the mathematical methods are related to the master equation which allows the application of wellknown solution',\n",
       " 'methods we will also indicate connections of disaster management with excitable media and supply networks this facilitates to study the effects of measures taken by the emergency management or the local operation units with a fictious but more or less realistic example of a spreading epidemic disease or a wave of influenza we illustrate how this method can in principle provide decision support to the emergency management during such a disaster similar considerations may help to assess measures to fight the',\n",
       " 'sars epidemics although immunization is presently not possible',\n",
       " 'we generalize quasilinear means by restricting to the tail of the risk distribution and show that this can be a useful quantity in risk management since it comprises in its general form the value at risk the tail value at risk and the entropic risk measure in a unified way we then investigate the fundamental properties of the proposed measure and show its unique features and implications in the risk measurement process furthermore we derive formulas for truncated elliptical models of losses and provide',\n",
       " 'formulas for selected members of such models',\n",
       " 'there is a lack of formal risk management techniques in agile software development methods scrum the need to manage risks in agile project management is also identified by various authors authors of this paper conducted a survey to find out the current practices in agile project management furthermore authors discuss the new integrated framework of scrum and prince with focus on risk management enrichment of scrum with selected practices from the heavyweight project management framework prince promises',\n",
       " 'better results in delivering software products especially in global development projects',\n",
       " 'approximate incremental valueatrisk formulae provide an easytouse preliminary guideline for risk allocation both the cases of risk adding and risk pooling are examined and betabased formulae achieved results highlight how much the conditions for adding new risky positions are stronger than those required for risk pooling key words incremental valueatrisk ivar risk pooling risk adding',\n",
       " 'higher educational institutions continuously look for ways to improve the quality of their elearning services and adapt learning solutions to suit the needs of the institution during the fall semester a university located in the southern part of united states decided to transition from the blackboard learning management system lms to the moodle learning management system typically such a transition presents a huge challenge for the university staff faculty and students additionally on august what cnn',\n",
       " 'themedthe worst natural disaster to strike the united states since hurricane sandy occurred in louisiana during the transition this led to massive disruptions in activities throughout the state this paper examines the perceptions of both faculty and student on the transition from one lms to another and also what impact if any the natural disaster had on the process faculty and students were surveyed to gain understanding of how they perceived the transitioning process their perception of both systems their',\n",
       " 'preferences and why furthermore we identified issues peculiar to transitioning during a natural disaster the results of this study can be used to anticipate issues that may be associated with transitioning from one lms to the other and issues peculiar to transitioning amidst a natural disaster it can also be used to identify areas for improvement',\n",
       " 'this paper was presented and written for two seminars a national uk university risk conference and a risk management industry workshop the target audience is therefore a cross section of academics and industry professionals the current ongoing global credit crunch has highlighted the importance of risk measurement in finance to companies and regulators alike despite risk measurements central importance to risk management few papers exist reviewing them or following their evolution from its foremost',\n",
       " 'beginnings up to the present day risk measures this paper reviews the most important portfolio risk measures in financial mathematics from bernoulli to markowitzs portfolio theory to the presently preferred risk measures such as cvar conditional value at risk we provide a chronological review of the risk measures and survey less commonly known risk measures eg treynor ratio',\n",
       " 'several behavioral social and public health interventions such as suicidehiv prevention or community preparedness against natural disasters leverage social network information to maximize outreach algorithmic influence maximization techniques have been proposed to aid with the choice of peer leaders or influencers in such interventions yet traditional algorithms for influence maximization have not been designed with these interventions in mind as a result they may disproportionately exclude minority',\n",
       " 'communities from the benefits of the intervention this has motivated research on fair influence maximization existing techniques come with two major drawbacks first they require committing to a single fairness measure second these measures are typically imposed as strict constraints leading to undesirable properties such as wastage of resources to address these shortcomings we provide a principled characterization of the properties that a fair influence maximization algorithm should satisfy in particular we',\n",
       " 'propose a framework based on social welfare theory wherein the cardinal utilities derived by each community are aggregated using the isoelastic social welfare functions under this framework the tradeoff between fairness and efficiency can be controlled by a single inequality aversion design parameter we then show under what circumstances our proposed principles can be satisfied by a welfare function the resulting optimization problem is monotone and submodular and can be solved efficiently with optimality',\n",
       " 'guarantees our framework encompasses as special cases leximin and proportional fairness extensive experiments on synthetic and real world datasets including a case study on landslide risk management demonstrate the efficacy of the proposed framework',\n",
       " 'in this paper we propose a new efficient linear programming based approach for multiresource allocation and location problems in disaster management such problems require an integer solution and therefore in most cases the computations rely on integer and mixedinteger linear programming solvers in general these solvers can not handle large scaled problem in this paper we demonstrate that there exists a large class of disaster management problems whose exact solutions can be obtained by applying the simplex',\n",
       " 'method linear programming the results of numerical experiments are provided another important contribution of this paper is related to general cluster analysis and allocation namely we demonstrate that the classical kmedoid clustering method can be implemented using linear programming techniques simplex method without relying on integer solvers',\n",
       " 'regulation and risk management in banks depend on underlying risk measures in general this is the only purpose that is seen for risk measures in this paper we suggest that the reporting of risk measures can be used to determine the loss distribution function for a financial entity we demonstrate that a lack of sufficient information can lead to ambiguous risk situations we give examples showing the need for the reporting of multiple risk measures in order to determine a banks loss distribution we conclude',\n",
       " 'by suggesting a regulatory requirement of multiple risk measures being reported by banks giving specific recommendations',\n",
       " 'risk measures such as expected shortfall es and valueatrisk var have been prominent in banking regulation and financial risk management motivated by practical considerations in the assessment and management of risks including tractability scenario relevance and robustness we consider theoretical properties of scenariobased risk evaluation we propose several novel scenariobased risk measures including various versions of maxes and maxvar and study their properties we establish axiomatic characterizations of',\n",
       " 'scenariobased risk measures that are comonotonicadditive or coherent and an esbased representation result is obtained these results provide a theoretical foundation for the recent basel iii iv market risk calculation formulas we illustrate the theory with financial data examples',\n",
       " 'complex risk is a critical factor for both intelligent systems and risk management in this paper we consider a special class of risk statistics named complex risk statistics our result provides a new approach for addressing complex risk especially in deep neural networks by further developing the properties related to complex risk statistics we are able to derive dual representation for such risk',\n",
       " 'we derive simple return models for several classes of bond portfolios with only one or two risk factors our models are able to explain most of the return variations in portfolios of fixed rate government bonds inflation linked government bonds and investment grade corporate bonds the underlying risk factors have natural interpretations which make the models well suited for risk management and portfolio design',\n",
       " 'we characterize when a convex risk measure associated to a lawinvariant acceptance set in linfty can be extended to lp leq pinfty preserving finiteness and continuity this problem is strongly connected to the statistical robustness of the corresponding risk measures special attention is paid to concrete examples including risk measures based on expected utility maxcorrelation risk measures and distortion risk measures',\n",
       " 'due to the increase in natural disasters in the past years disaster response organizations dros are faced with the challenge of coping with more and larger operations currently appointed information and communications technology ict used for coordination and communication is sometimes outdated and does not scale while novel technologies have the potential to greatly improve disaster response efficiency to allow adoption of these novel technologies ict system designers have to take into account the',\n",
       " 'particular needs of dros and characteristics of international disaster response idr this work attempts to bring the humanitarian and ict communities closer together in this work we analyze idrrelated documents and conduct expert interviews using open coding we extract empirical insights and translate the peculiarities of dro coordination and operation into tangible ict design requirements this information is based on interviews with active idr staff as well as dro guidelines and reports ultimately the goal',\n",
       " 'of this paper is to serve as a reference for future ict research endeavors to support and increase the efficiency of idr operations',\n",
       " 'we present an approach to derivative exposure management based on subjective and implied probabilities we suggest to maximize the valuation difference subject to risk constraints and propose a class of risk measures derived from the subjective distribution we illustrate this process with specific examples for the two and three dimensional case in these cases the optimization can be performed graphically',\n",
       " 'largescale disaster management applications are among the several realistic applications of the iot fire detection and earthquake early warning applications are just two examples several iot devices are used in such applications eg sensors and robots these sensors and robots are usually heterogeneous moreover in disaster scenarios the existing communication infrastructure may become completely or partially destroyed leaving mobile adhoc networks the only alternative to provide connectivity utilizing these',\n",
       " 'applications raises new challenges such as the need for dynamic flexible and distributed gateways which can accommodate new applications and new iot devices network functions virtualization nfv and software defined networking sdn are emerging paradigms that can help to overcome these challenges this paper leverages nfv and sdn to propose an architecture for onthefly distributed gateway provisioning in largescale disaster management in the proposed architecture the gateway functions are provisioned as',\n",
       " 'virtual network functions vnfs that are chained onthefly in the iot domain using sdn a prototype is built and the performance results are presented',\n",
       " 'we axiomatically introduce riskconsistent conditional systemic risk measures defined on multidimensional risks this class consists of those conditional systemic risk measures which can be decomposed into a statewise conditional aggregation and a univariate conditional risk measure our studies extend known results for unconditional risk measures on finite state spaces we argue in favor of a conditional framework on general probability spaces for assessing systemic risk mathematically the problem reduces to',\n",
       " 'selecting a realization of a random field with suitable properties moreover our approach covers many prominent examples of systemic risk measures from the literature and used in practice',\n",
       " 'to find a tradeoff between profitability and prudence financial practitioners need to choose appropriate risk measures two key points are firstly investors risk attitudes under uncertainty conditions should be an important reference for risk measures secondly risk attitudes are not absolute for different market performance investors have different risk attitudes we proposed a new risk measure named slidevar which sufficiently reflects the different subjective attitudes of investors and the impact of market',\n",
       " 'changes on investors attitudes we proposed the concept of risktail region and risktail subadditivity and proved that slidevar satisfies several important mathematical properties moreover slidevar has a simple and intuitive form of expression for practical application several simulate and empirical computations show that slidevar has obvious advantages in markets where the state changes frequently',\n",
       " 'communications play a vital role in the response to disasters and crises however existing communications infrastructure is often impaired destroyed or overwhelmed during such events this leads to the use of substitute communications solutions including analog twoway radio or unsecured internet access often provided by unknown third parties these solutions may have less sophisticated security characteristics than is desirable while substitute communications are often invaluable care is required to minimize',\n",
       " 'the risk to ngos and individuals stemming from the use of communications channels with reduced or unknown security properties this is particularly true if private information is involved including the location and disposition of individuals and first responders in this work we enumerate the principal risks and challenges that may arise and provide practical guidelines for mitigating them during crises we take plausible threats from contemporary disaster and crisis events into account and discuss the',\n",
       " 'security and privacy features of stateoftheart communications mechanisms',\n",
       " 'weather events put human lives at risk mostly when people might reside in areas susceptible to natural disasters weather monitoring is a pivotal task that is accomplished in vulnerable areas with the support of reliable weather stations such stations are frontend equipment typically mounted on a fixed mast structure with a set of digital and magnetic weather sensors connected to a datalogger while remote sensing from a number of stations is paramount the cost of professional weather instruments is extremely',\n",
       " 'high this imposes a challenge for largescale deployment and maintenance of weather stations for broad natural disaster monitoring to address this problem in this paper we validate the hypothesis that a lowcost automatic weather station system lcaws entirely developed from commercialofftheshelf and opensource iot technologies is able to provide data as reliable as a professional weather station pws of reference for natural disaster monitoring to achieve data reliability we propose an intelligent sensor',\n",
       " 'calibration method to correct weather parameters from the experimental results of a day uninterrupted observation period we show that the results of the calibrated lcaws sensors have no statistically significant differences with the pwss results together with the brazilian national center for monitoring and early warning of natural disasters cemaden lcaws has opened new opportunities towards reducing maintenance cost of its weather observational network',\n",
       " 'today is the era of intelligence in machines with the advances in artificial intelligence machines have started to impersonate different human traits a chatbot is the next big thing in the domain of conversational services a chatbot is a virtual person who is capable to carry out a natural conversation with people they can include skills that enable them to converse with the humans in audio visual or textual formats artificial intelligence conversational entities also called chatbots conversational agents',\n",
       " 'or dialogue system are an excellent example of such machines obtaining the right information at the right time and place is the key to effective disaster management the term disaster management encompasses both natural and humancaused disasters to assist citizens our project is to create a covid assistant to provide the need of up to date information to be available hours with the growth in the world wide web it is quite intelligible that users are interested in the swift and relatedly correct information',\n",
       " 'for their hunt a chatbot can be seen as a questionandanswer system in which experts provide knowledge to solicit users this master thesis is dedicated to discuss covid assistant chatbot and explain each component in detail the design of the proposed chatbot is introduced by its seven components ontology web scraping module db state machine keyword extractor trained chatbot and user interface',\n",
       " 'citizens and emergency managers need to be able to distinguish fake untrue news posts from real news posts on social media during disasters this paper is based on an online survey conducted in that produced responses from invitations distributed via email and through facebook it explores to what extent and how citizens generally assess whether postings are true or fake and describes indicators of the trustworthiness of content that users would like the mean response on a semantic differential scale',\n",
       " 'measuring how frequently users attempt to verify the news trustworthiness a scale from never to always was the most frequent message characteristics citizens use are grammar and the trustworthiness of the sender most respondents would find an indicator of trustworthiness helpful with the most popular choice being a colored graphic limitations and implications for assessments of trustworthiness during disasters are discussed',\n",
       " 'people increasingly use social media to report emergencies seek help or share information during disasters which makes social networks an important tool for disaster management to meet these timecritical needs we present a weakly supervised approach for rapidly building highquality classifiers that label each individual twitter message with finegrained event categories most importantly we propose a novel method to create highquality labeled data in a timely manner that automatically clusters tweets',\n",
       " 'containing an event keyword and asks a domain expert to disambiguate event word senses and label clusters quickly in addition to process extremely noisy and often rather short usergenerated messages we enrich tweet representations using preceding context tweets and reply tweets in building event recognition classifiers the evaluation on two hurricanes harvey and florence shows that using only personhours of human supervision the rapidly trained weakly supervised classifiers outperform supervised classifiers',\n",
       " 'trained using more than ten thousand annotated tweets created in over personhours',\n",
       " 'as climate change increases the intensity of natural disasters society needs better tools for adaptation floods for example are the most frequent natural disaster but during hurricanes the area is largely covered by clouds and emergency managers must rely on nonintuitive flood visualizations for mission planning to assist these emergency managers we have created a deep learning pipeline that generates visual satellite images of current and future coastal flooding we advanced a stateoftheart gan called pix',\n",
       " 'pixhd such that it produces imagery that is physicallyconsistent with the output of an expertvalidated storm surge model noaa slosh by evaluating the imagery relative to physicsbased flood maps we find that our proposed framework outperforms baseline models in both physicalconsistency and photorealism while this work focused on the visualization of coastal floods we envision the creation of a global visualization of how climate change will shape our earth',\n",
       " 'information security management aims at ensuring proper protection of information values and information processing systems ie assets information security risk management techniques are incorporated to deal with threats and vulnerabilities that impose risks to information security properties of these assets this paper investigates the current state of risk management practices being used in information security management in the dach region germany austria switzerland we used an anonymous online survey',\n",
       " 'targeting strategic and operative information security and risk managers and collected data from organizations we analyzed general practices documentation artifacts patterns of stakeholder collaboration as well as tool types and data sources used by enterprises to conduct information security management activities our findings show that the state of practice of information security risk management is in need of improvement current industrial practice heavily relies on manual data collection and complex',\n",
       " 'potentially subjective decision processes with multiple stakeholders involved dedicated risk management tools and methods are used selectively and neglected in favor of generalpurpose documentation tools and direct communication between stakeholders in light of our results we propose guidelines for the development of risk management practices that are better aligned with the current operational situation in information security management',\n",
       " 'this paper presents nonparametric estimates of spectral risk measures applied to long and short positions in prominent equity futures contracts it also compares these to estimates of two popular alternative measures the valueatrisk var and expected shortfall es the spectral risk measures are conditioned on the coefficient of absolute risk aversion and the latter two are conditioned on the confidence level our findings indicate that all risk measures increase dramatically and their estimators deteriorate in',\n",
       " 'precision when their respective conditioning parameter increases results also suggest that estimates of spectral risk measures and their precision levels are of comparable orders of magnitude as those of more conventional risk measures running head financial risk measures for futures positions',\n",
       " 'we survey systemic risks to financial markets and present a highlevel description of an algorithm that measures systemic risk in terms of coupled networks',\n",
       " 'the paper mentioned in the title introduces the entropic value at risk i give some extra comments and using the general theory make a relation with some commonotone risk measures',\n",
       " 'the development of multisynchronous decision support systems to facilitate collaboration between diverse users is an emerging field in emergency management traditionally information management for emergency response has been a centralised effort however modern devices such as smartphones provide new methods for gaining realtime information about a disaster from users in the field in this paper we present a framework for multisynchronous collaborative report writing in the scope of emergency management this',\n",
       " 'framework supports desktopbased users as information providers and consumers alongside mobile users as information providers to facilitate multisynchronous collaboration we consider the benefits of our framework for writing collaborative situation reports and discuss future directions for research',\n",
       " 'the globalization feeded by the technology explosion that begans in the end of the last century started the world to change faster every day the only todays certain is the tomorrows uncertain risk is defined as uncertain where one or many causes composed of ocurrence probality can generate an impact or consequence threat if negative and oportunity if positive to a determinated goal the risk management is composed of culture procedure and process of an organization or individual care of uncertain aiming to',\n",
       " 'minimize threats e maximizing the oportunities to reach a desired goal the risk maturity model in projects proposed on this document wants to measure the organizations capacity and skills to manage the riks involved in projects when adopting a generic risk management methodology',\n",
       " 'this paper gives an overview of the theory of dynamic convex risk measures for random variables in discrete time setting we summarize robust representation results of conditional convex risk measures and we characterize various time consistency properties of dynamic risk measures in terms of acceptance sets penalty functions and by supermartingale properties of risk processes and penalty functions',\n",
       " 'this letter uses the block maxima extreme value approach to quantify catastrophic risk in international equity markets risk measures are generated from a set threshold of the distribution of returns that avoids the pitfall of using absolute returns for markets exhibiting diverging levels of risk from an application to leading markets the letter finds that the nikkei is more prone to catastrophic risk than the ftse and dow jones indexes',\n",
       " 'we study the problem of finding the worstcase joint distribution of a set of risk factors given prescribed multivariate marginals and a nonlinear loss function we show that when the risk measure is cvar and the distributions are discretized the problem can be conveniently solved using linear programming technique the method has applications to any situation where marginals are provided and bounds need to be determined on total portfolio risk this arises in many financial contexts including pricing and risk',\n",
       " 'management of exotic options analysis of structured finance instruments and aggregation of portfolio risk across risk types applications to counterparty credit risk are emphasized and they include assessing wrongway risk in the credit valuation adjustment and counterparty credit risk measurement lastly a detailed application of the algorithm for counterparty risk measurement to a real portfolio case is also presented in this paper',\n",
       " 'we propose a new procedure for the risk measurement of large portfolios it employs the following objects as the building blocks coherent risk measures introduced by artzner delbaen eber and heath factor risk measures introduced in this paper which assess the risks driven by particular factors like the price of oil sp index or the credit spread risk contributions and factor risk contributions which provide a coherent alternative to the sensitivity coefficients we also propose two particular classes of',\n",
       " 'coherent risk measures called alpha vr and beta vr for which all the objects described above admit an extremely simple empirical estimation procedure this procedure uses no model assumptions on the structure of the price evolution moreover we consider the problem of the risk management on a firms level it is shown that if the risk limits are imposed on the risk contributions of the desks to the overall risk of the firm rather than on their outstanding risks and the desks are allowed to trade these limits',\n",
       " 'within a firm then the desks automatically find the globally optimal portfolio',\n",
       " 'we study the properties of expected shortfall from the point of view of financial risk management this measure which emerges as a natural remedy in some cases where value at risk var is not able to distinguish portfolios which bear different levels of risk is indeed shown to have much better properties than var we show in fact that unlike var this variable is in general subadditive and therefore it is a coherent measure of risk in the sense of reference artzner',\n",
       " 'managing a portfolio to a risk model can tilt the portfolio toward weaknesses of the model as a result the optimized portfolio acquires downside exposure to uncertainty in the model itself what we call second order risk we propose a risk measure that accounts for this bias studies of real portfolios in assetbyasset and factor model contexts demonstrate that second order risk contributes significantly to realized volatility and that the proposed measure accurately forecasts the outofsample behavior of',\n",
       " 'optimized portfolios',\n",
       " 'reliable estimates of indirect economic losses arising from natural disasters are currently out of scientific reach to address this problem we propose a novel approach that combines a probabilistic physical damage catastrophe model with a new generation of macroeconomic agentbased models abms the abm moves beyond the state of the art by exploiting large data sets from detailed national accounts census data and business information etc to simulate interactions of millions of agents representing empheach',\n",
       " 'natural person or legal entity in a national economy the catastrophe model introduces a copula approach to assess flood losses considering spatial dependencies of the flood hazard these loss estimates are used in a damage scenario generator that provides input for the abm which then estimates indirect economic losses due to the event for the first time we are able to link environmental and economic processes in a computer simulation at this level of detail we show that moderate disasters induce comparably',\n",
       " 'small but positive short to mediumterm and negative longterm economic impacts largescale events however trigger a pronounced negative economic response immediately after the event and in the long term while exhibiting a temporary short to mediumterm economic boost we identify winners and losers in different economic sectors including the fiscal consequences for the government we quantify the critical disaster size beyond which the resilience of an economy to rebuild reaches its limits our results might be',\n",
       " 'relevant for the management of the consequences of systemic events due to climate change and other disasters',\n",
       " 'security is considered one of the top ranked risks of cloud computing cc due to the outsourcing of sensitive data onto a third party in addition the complexity of the cloud model results in a large number of heterogeneous security controls that must be consistently managed hence no matter how strongly the cloud model is secured organizations continue suffering from lack of trust on cc and remain uncertain about its security risk consequences traditional risk management frameworks do not consider the impact',\n",
       " 'of cc security risks on the business objectives of the organizations in this paper we propose a novel cloud security risk management framework csrmf that helps organizations adopting cc identify analyze evaluate and mitigate security risks in their cloud platforms unlike traditional risk management frameworks csrmf is driven by the business objectives of the organizations it allows any organization adopting cc to be aware of cloud security risks and align their lowlevel management decisions according to',\n",
       " 'highlevel business objectives in essence it is designed to address impacts of cloudspecific security risks into business objectives in a given organization consequently organizations are able to conduct a costvalue analysis regarding the adoption of cc technology and gain an adequate level of confidence in cloud technology on the other hand cloud service providers csp are able to improve productivity and profitability by managing cloudrelated risks the proposed framework has been validated and evaluated',\n",
       " 'through a usecase scenario',\n",
       " 'identifying and quantifying factors influencing human decision making remains an outstanding challenge impacting the performance and predictability of social and technological systems in many cases system failures are traced to human factors including congestion overload miscommunication and delays here we report results of a behavioral network science experiment targeting decision making in a natural disaster in each scenario individuals are faced with a forced go versus no go evacuation decision based on',\n",
       " 'information available on competing broadcast and peertopeer sources in this controlled setting all actions and observations are recorded prior to the decision enabling development of a quantitative decision making model that accounts for the disaster likelihood severity and temporal urgency as well as competition between networked individuals for limited emergency resources individual differences in behavior within this social setting are correlated with individual differences in inherent risk attitudes as',\n",
       " 'measured by standard psychological assessments identification of robust methods for quantifying human decisions in the face of risk has implications for policy in disasters and other threat scenarios',\n",
       " 'during disasters crisis and emergencies the public relies on online services provided by official authorities to receive timely alerts trustworthy information and access to relief programs it is therefore crucial for the authorities to reduce risks when accessing their online services this includes catering to secure identification of service secure resolution of name to network service and content security and privacy as a minimum base for trustworthy communication in this paper we take a first look at',\n",
       " 'alerting authorities aa in the us and investigate security measures related to trustworthy and secure communication we study the domain namespace structure dnssec penetration and web certificates we introduce an integrative threat model to better understand whether and how the online presence and services of aas are harmed as an illustrative example we investigate alerting authorities backed by the united states federal emergency management agency us fema we observe partial heightened security relative to',\n",
       " 'the global internet trends yet find cause for concern as about of service providers fail to deploy measures of trustworthy service provision our analysis shows two major shortcomings about of organizations do not own their dedicated domain names and are dependent on others opt for unrestricteduse namespaces which simplifies phishing and less than of unique aa domain names are secured by dnssec which can lead to dns poisoning and possibly to certificate misissuance furthermore of all hosts provide none or',\n",
       " 'invalid certificates thus cannot cater to confidentiality and data integrity of the hosts provide domain validation certificates that lack any identity information and shared certificates have gained on popularity which leads to fatesharing and can be a cause for instability',\n",
       " 'electrical energy is a vital part of modern life and expectations for grid resilience to allow a continuous and reliable energy supply has tremendously increased even during adverse events eg ukraine cyberattack hurricane maria the global pandemic covid has raised the electric energy reliability risk due to potential workforce disruptions supply chain interruptions and increased possible cybersecurity threats the pandemic introduces a significant degree of uncertainly to the grid operation in the presence',\n",
       " 'of other extreme events like natural disasters unprecedented outages aging power grids high proliferation of distributed generation and cyberattacks this situation increases the need for measures for the resiliency of power grids to mitigate the impacts of the pandemic as well as simultaneous extreme events solutions to manage such an adverse scenario will be multifold a emergency planning and organizational support b following safety protocol c utilizing enhanced automation and sensing for situational',\n",
       " 'awareness and d integration of advanced technologies and data points for mldriven enhanced decision support enhanced digitalization and automation resulted in better network visibility at various levels including generation transmission and distribution these data or information can be utilized to take advantage of advanced machine learning techniques for automation and increased power grid resilience in this paper a we review the impact of covid on power grid operations and actions taken by',\n",
       " 'operatorsorganizations to minimize the impact of covid and b we have presented the recently developed tool and concepts using natural language processing nlp in the domain of machine learning and artificial intelligence that can be used for increasing resiliency of power systems in normal and in extreme scenarios such as covid pandemics',\n",
       " 'systematic and multifactor risk models are revisited via methods which were already successfully developed in signal processing and in automatic control the results which bypass the usual criticisms on those risk modeling are illustrated by several successful computer experiments',\n",
       " 'this is a comparative study of the traditional d computer graphics technique of geometric modelling and imagebased rendering techniques that were surveyed and implementedwe have discussed the classifications and representative methods of both the techniques the study has shown that there is a strong continuum between both the techniques and a hybrid of the two is most suitable for further implementationsthis hybridisation study is underway to create models of real life situations and provide disaster',\n",
       " 'management training',\n",
       " 'the banking systems that deal with risk management depend on underlying risk measures following the basel ii accord there are two separate methods by which banks may determine their capital requirement the value at risk measure plays an important role in computing the capital for both approaches in this paper we analyze the errors produced by using this measure we discuss other measures demonstrating their strengths and shortcomings we give examples showing the need for the information from multiple risk',\n",
       " 'measures in order to determine a banks loss distribution we conclude by suggesting a regulatory requirement of multiple risk measures being reported by banks giving specific recommendations',\n",
       " 'the aim of this paper is to introduce a risk measure that extends the ginitype measures of risk and variability the extended gini shortfall by taking risk aversion into consideration our risk measure is coherent and catches variability an important concept for risk management the analysis is made under the choquet integral representations framework we expose results for analytic computation under wellknown distribution functions furthermore we provide a practical application',\n",
       " 'we give an explicit algorithm and source code for constructing risk models based on machine learning techniques the resultant covariance matrices are not factor models based on empirical backtests we compare the performance of these machine learning risk models to other constructions including statistical risk models risk models based on fundamental industry classifications and also those utilizing multilevel clustering based industry classifications',\n",
       " 'in this paper we address risk aggregation and capital allocation problems in the presence of dependence between risks the dependence structure is defined by a mixed bernstein copula which represents a generalization of the wellknown archimedean copulas using this new copula the probability density function and the cumulative distribution function of the aggregate risk are obtained then closedform expressions for basic risk measures such as tail valueatrisktvar and tvarbased allocations are derived',\n",
       " 'since cascading outages are major threats to power systems it is important to reduce the risk of potential cascading outages in this paper a risk management method of cascading outages based on markovian tree search is proposed with the tree expansion on the cascading outage risk risk gradient is computed efficiently by a forwardbackward tree search scheme with good convergence and it is then employed in an optimization model to minimize control cost while effectively reducing the cascading outage risk to',\n",
       " 'overcome the limitation with linearization in computing risk gradient an iterative risk management irm approach is further developed tests on the rts area system verify the accuracy of the computed risk gradient and its effectiveness for risk reduction time performance of the proposed irm approach is tested on the rts system a bus uscanada northeast system and a bus mideuropean system and demonstrates its potentials for decision support on practical power systems online or on hourly basis',\n",
       " 'spectral risk measures are attractive risk measures as they allow the user to obtain risk measures that reflect their subjective riskaversion this paper examines spectral risk measures based on an exponential utility function and finds that these risk measures have nice intuitive properties it also discusses how they can be estimated using numerical quadrature methods and how confidence intervals for them can be estimated using a parametric bootstrap illustrative results suggest that estimated exponential',\n",
       " 'spectral risk measures obtained using such methods are quite precise in the presence of normally distributed losses',\n",
       " 'this paper applies the extremevalue ev generalised pareto distribution to the extreme tails of the return distributions for the sp ft dax hang seng and nikkei futures contracts it then uses tail estimators from these contracts to estimate spectral risk measures which are coherent risk measures that reflect a users riskaversion function it compares these to var and expected shortfall es risk measures and compares the precision of their estimators it also discusses the usefulness of these risk measures in the',\n",
       " 'context of clearinghouses setting initial margin requirements and compares these to the span measures typically used keywords spectral risk measures expected shortfall value at risk extreme value',\n",
       " 'stochastic optimization problems often involve the expectation in its objective when risk is incorporated in the problem description as well then risk measures have to be involved in addition to quantify the acceptable risk often in the objective for this purpose it is important to have an adjusted adapted and efficient evaluation scheme for the risk measure available in this article different representations of an important class of risk measures the spectral risk measures are elaborated the results allow',\n",
       " 'concise problem formulations they are particularly adapted for stochastic optimization problems efficient evaluation algorithms can be built on these new results which finally make optimization problems involving spectral risk measures eligible for stochastic optimization',\n",
       " 'we consider the problem of optimal risk sharing in a pool of cooperative agents we analyze the asymptotic behavior of the certainty equivalents and risk premia associated with the pareto optimal risk sharing contract as the pool expands we first study this problem under expected utility preferences with an objectively or subjectively given probabilistic model next we develop a robust approach by explicitly taking uncertainty about the probabilistic model ambiguity into account the resulting robust certainty',\n",
       " 'equivalents and risk premia compound risk and ambiguity aversion we provide explicit results on their limits and rates of convergence induced by pareto optimal risk sharing in expanding pools',\n",
       " 'risk statistic is a critical factor not only for risk analysis but also for financial application however the traditional risk statistics may fail to describe the characteristics of regulatorbased risk in this paper we consider the regulatorbased risk statistics for portfolios by further developing the properties related to regulatorbased risk statistics we are able to derive dual representation for such risk',\n",
       " 'the relationship between setvalued risk measures for processes and vectors on the optional filtration is investigated the equivalence of risk measures for processes and vectors and the equivalence of their penalty function formulations are provided in contrast with scalar risk measures this equivalence requires an augmentation of the setvalued risk measures for processes we utilize this result to deduce a new dual representation for risk measures for processes in the setvalued framework finally the',\n",
       " 'equivalence of multiportfolio time consistency between setvalued risk measures for processes and vectors are provided to accomplish this an augmented definition for multiportfolio time consistency of setvalued risk measures for processes is proposed',\n",
       " 'social networks can serve as a valuable communication channel for calls for help offering assistance and coordinating rescue activities in disaster social networks such as twitter allow users to continuously update relevant information which is especially useful during a crisis where the rapidly changing conditions make it crucial to be able to access accurate information promptly social media helps those directly affected to inform others of conditions on the ground in real time and thus enables rescue',\n",
       " 'workers to coordinate their efforts more effectively better meeting the survivors need this paper presents a new sequence to sequence based framework for forecasting peoples needs during disasters using social media and weather data it consists of two long shortterm memory lstm models one of which encodes input sequences of weather information and the other plays as a conditional decoder that decodes the encoded vector and forecasts the survivors needs case studies utilizing data collected during hurricane',\n",
       " 'sandy in hurricane harvey and hurricane irma in were analyzed and the results compared with those obtained using a statistical language model ngram and an lstm generative model our proposed sequence to sequence method forecast peoples needs more successfully than either of the other models this new approach shows great promise for enhancing disaster management activities such as evacuation planning and commodity flow management',\n",
       " 'owing to the increasing frequency and destruction of natural and manmade disasters to modern highlypopulated societies emergency management which provides solutions to prevent or address disasters have drawn considerable research over the last few decades and become a multidisciplinary area because of its open and inclusive nature new technologies always tend to influence change or even revolutionise this research area hence it is imperative to consolidate the stateoftheart studies and knowledge to meet the',\n",
       " 'research needs and identify the future research directions the paper presents a comprehensive and systemic review of the existing research in the field of emergency management from both the system design aspect and algorithm engineering aspect we begin with the history and evolution of the emergency management research then the two main research topics of this area emergency navigation and emergency search and rescue planning are introduced and discussed finally we suggest the emerging challenges and',\n",
       " 'opportunities from system optimisation evacuee behaviour modelling and optimisation computing patterns data analysis energy and cyber security aspects',\n",
       " 'past research shows that spreadsheet models are prone to such a high frequency of errors and data security implications that the risk management of spreadsheet development and spreadsheet use is of great importance to both industry and academia the underlying rationale for this paper is that spreadsheet training courses should specifically address risk management in the development process both from a generic and a domainspecific viewpoint this research specifically focuses on one of these namely those',\n",
       " 'generic issues of risk management that should be present in a training course that attempts to meet goodpractice within industry a pilot questionnaire was constructed showing a possible minimum set of risk management issues and sent to academics and industry practitioners for feedback the findings from this pilot survey will be used to refine the questionnaire for sending to a larger body of possible respondents it is expected these findings will form the basis of a risk management teaching approach to be',\n",
       " 'trialled in a number of selected ongoing spreadsheet training courses',\n",
       " 'we propose a riskaware framework for multirobot multidemand assignment and planning in unknown environments our motivation is disaster response and searchandrescue scenarios where ground vehicles must reach demand locations as soon as possible we consider a setting where the terrain information is available only in the form of an aerial georeferenced image deep learning techniques can be used for semantic segmentation of the aerial image to create a cost map for safe ground robot navigation such',\n",
       " 'segmentation may still be noisy hence we present a joint planning and perception framework that accounts for the risk introduced due to noisy perception our contributions are twofold i we show how to use bayesian deep learning techniques to extract risk at the perception level and ii use a risktheoretical measure cvar for riskaware planning and assignment the pipeline is theoretically established then empirically analyzed through two datasets we find that accounting for risk at both levels produces',\n",
       " 'quantifiably safer paths and assignments',\n",
       " 'in this paper we investigate risk measures such as value at risk var and the conditional tail expectation cte of the extreme maximum and minimum and the aggregate total of two dependent risks in finance insurance and the other fields when people invest their money in two or more dependent or independent markets it is very important to know the extreme and total risk before the investment to find these risk measures for dependent cases is quite challenging which has not been reported in the literature to the',\n",
       " 'best of our knowledge we use the fgm copula for modelling the dependence as it is relatively simple for computational purposes and has empirical successes the marginal of the risks are considered as exponential and pareto separately for the case of extreme risk and as exponential for the case of the total risk the effect of the degree of dependency on the var and cte of the extreme and total risks is analyzed we also make comparisons for the dependent and independent risks moreover we propose a new risk',\n",
       " 'measure called median of tail mot and investigate mot for the extreme and aggregate dependent risks',\n",
       " 'what makes cyber risks arising from connected systems challenging during the management of a pandemic assuming that a variety of cyberphysical systems are already operationalcollecting analyzing and acting on data autonomouslywhat risks might arise in their application to pandemic management we already have these systems operational collecting and analyzing data autonomously so how would a pandemic monitoring app be different or riskier in this review article we discuss the digitalization of covid pandemic',\n",
       " 'management and cyber risk from connected systems',\n",
       " 'we propose a markov chain model for credit rating changes we do not use any distributional assumptions on the asset values of the rated companies but directly model the rating transitions process the parameters of the model are estimated by a maximum likelihood approach using historical rating transitions and heuristic global optimization techniques we benchmark the model against a glmm model in the context of bond portfolio risk management the proposed model yields stronger dependencies and higher risks',\n",
       " 'than the glmm model as a result the risk optimal portfolios are more conservative than the decisions resulting from the benchmark model',\n",
       " 'the european insurance sector will soon be faced with the application of solvency regulation norms it will create a real change in risk management practices the orsa approach of the second pillar makes the capital allocation an important exercise for all insurers and specially for groups considering multibranches firms capital allocation has to be based on a multivariate risk modeling several allocation methods are present in the literature and insurers practices in this paper we present a new risk',\n",
       " 'allocation method we study its coherence using an axiomatic approach and we try to define what the best allocation choice for an insurance group is',\n",
       " 'risk and uncertainty will always be a matter of experience luck skills and modelling leverage is another concept which is critical for the investor decisions and results adaptive skills and quantitative probabilistic methods need to be used in successful management of risk uncertainty and leverage the author explores how uncertainty beyond risk determines consistent leverage in a simple model of the world with fat tails due to significant not fully quantifiable and not too rare events among particular',\n",
       " 'technical results for the single asset fractional kelly criterion is derived in the presence of the fat tails associated with subjective uncertainty for the multiasset portfolio kelly criterion provides an insightful perspective on risk parity strategies which can be extended for the assets with fat tails',\n",
       " 'in this paper we present a novel computational framework for portfoliowide risk management problems where the presence of a potentially large number of risk factors makes traditional numerical techniques ineffective the new method utilises a coupled system of bsdes for the valuation adjustments xva and solves these by a recursive application of a neural network based bsde solver this not only makes the computation of xva for highdimensional problems feasible but also produces hedge ratios and dynamic risk',\n",
       " 'measures for xva and allows simulations of the collateral account',\n",
       " 'when applying value at risk var procedures to specific positions or portfolios we often focus on developing procedures only for the specific assets in the portfolio however since this small portfolio risk analysis ignores information from assets outside the target portfolio there may be significant information loss in this paper we develop a dynamic process to incorporate the ignored information we also study how to overcome the curse of dimensionality and discuss where and when benefits occur from a large',\n",
       " 'number of assets which is called the blessing of dimensionality we find empirical support for the proposed method',\n",
       " 'with the wide deployment of network facilities and the increasing requirement of network reliability the disruptive event like natural disaster power outage or malicious attack has become a nonnegligible threat to the current communication network such disruptive event can simultaneously destroy all devices in a specific geographical area and affect many network based applications for a long time hence it is essential to build disasterresilient network for future highly survivable communication services in',\n",
       " 'this paper we consider the problem of designing a highly resilient network through the technique of sdn software defined networking in contrast to the conventional idea of handling all the failures on the control plane the controller we focus on an integrated design to mitigate disaster risks by adding some redundant functions on the data plane our design consists of a subgraph based proactive protection approach on the data plane and a splicing approach at the controller for effective restoration on the',\n",
       " 'control plane such a systematic design is implemented in the openflow framework through the mininet emulator and nox controller numerical results show that our approach can achieve high robustness with low control overhead',\n",
       " 'we discuss when and why custom multifactor risk models are warranted and give source code for computing some risk factors pensionmutual funds do not require customization but standardization however using standardized risk models in quant trading with much shorter holding horizons is suboptimal longer horizon risk factors value growth etc increase noise trades and trading costs arbitrary risk factors can neutralize alpha standardized industries are artificial and insufficiently granular normalization of',\n",
       " 'style risk factors is lost for the trading universe diversifying risk models lowers pl correlations reduces turnover and market impact and increases capacity we discuss various aspects of custom risk model building',\n",
       " 'in developed countries such as australia for recurring disasters eg floods there are dedicated document repositories of disaster management plans displans and supporting doctrine and processes that are used to prepare organisations and communities for disasters they are maintained on an ongoing cyclical basis and form a key information source for community education engagement and awareness programme in the preparation for and mitigation of disasters displans generally in semistructured text document format',\n",
       " 'are then accessed and activated during the response and recovery to incidents to coordinate emergency service and community safety actions however accessing the appropriate plan and the specific knowledge within the text document from across its conceptual areas in a timely manner and sharing activities between stakeholders requires intimate domain knowledge of the plan contents and its development this paper describes progress on an ongoing project with nsw state emergency service nsw ses to convert',\n",
       " 'displans into a collection of knowledge units that can be stored in a unified repository with the goal to form the basis of a future knowledge sharing capability all australian emergency services covering a wide range of hazards develop displans of various structure and intent in general the plans are created as instances of a template for example those which are developed centrally by the nsw and victorian sess state planning policies in this paper we illustrate how by using selected templates as part of',\n",
       " 'an elaborate agentbased process we can apply agentoriented analysis more efficiently to convert extant displans into a centralised repository the repository is structured as a layered abstraction according to meta object facility mof the work is illustrated using displans along the floodprone murrumbidgee river in central nsw',\n",
       " 'risk is unavoidable in business and risk management is needed amongst others to set up good security policies once the risks are evaluated the next step is to decide how they should be treated this involves managers making decisions on proper countermeasures to be implemented to mitigate the risks the countermeasure expenditure together with its ability to mitigate risks is factors that affect the selection while many approaches have been proposed to perform risk analysis there has been less focus on',\n",
       " 'delivering the prescriptive and specific information that managers require to select costeffective countermeasures this paper proposes a generic approach to integrate the cost assessment into risk analysis to aid such decision making the approach makes use of a risk model which has been annotated with potential countermeasures estimates for their cost and effect a calculus is then employed to reason about this model in order to support decision in terms of decision diagrams we exemplify the instantiation of',\n",
       " 'the generic approach in the coras method for security risk analysis',\n",
       " 'situational awareness is crucial for effective disaster management however obtaining information about the actual situation is usually difficult and timeconsuming while there has been some effort in terms of incorporating the affected population as a source of information the issue of obtaining trustworthy information has not yet received much attention therefore we introduce the concept of witnessbased report verification which enables users from the affected population to evaluate reports issued by other',\n",
       " 'users we present an extensive overview of the objectives to be fulfilled by such a scheme and provide a first approach considering security and privacy finally we evaluate the performance of our approach in a simulation study our results highlight synergetic effects of group mobility patterns that are likely in disaster situations',\n",
       " 'information flow during catastrophic events is a critical aspect of disaster management modern communication platforms in particular online social networks provide an opportunity to study such flow and a mean to derive earlywarning sensors improving emergency preparedness and response performance of the social networks sensor method based on topological and behavioural properties derived from the friendship paradox is studied here for over million twitter messages posted before during and after hurricane',\n",
       " 'sandy we find that differences in users network centrality effectively translate into moderate awareness advantage up to hours and that geolocation of users within or outside of the hurricaneaffected area plays significant role in determining the scale of such advantage emotional response appears to be universal regardless of the position in the network topology and displays characteristic easily detectable patterns opening a possibility of implementing a simple sentiment sensing technique to detect and',\n",
       " 'locate disasters',\n",
       " 'social sensing services use humans as sensor carriers sensor operators and sensors themselves in order to provide situationawareness to applications this promises to provide a multitude of benefits to the users for example in the management of natural disasters or in community empowerment however current social sensing services depend on internet connectivity since the services are deployed on central cloud platforms in many circumstances internet connectivity is constrained for instance when a natural',\n",
       " 'disaster causes internet outages or when people do not have internet access due to economical reasons in this paper we propose the emerging fog computing infrastructure to become a keyenabler of social sensing services in situations of constrained internet connectivity to this end we develop a generic architecture and api of fogenabled social sensing services we exemplify the usage of the proposed social sensing architecture on a number of concrete use cases from two different scenarios',\n",
       " 'the extensive use of social media platforms especially during disasters creates unique opportunities for humanitarian organizations to gain situational awareness and launch relief operations accordingly in addition to the textual content people post overwhelming amounts of imagery data on social networks within minutes of a disaster hit studies point to the importance of this online imagery content for emergency response despite recent advances in the computer vision field automatic processing of the',\n",
       " 'crisisrelated social media imagery data remains a challenging task it is because a majority of which consists of redundant and irrelevant content in this paper we present an image processing pipeline that comprises deduplication and relevancy filtering mechanisms to collect and filter social media image content in realtime during a crisis event results obtained from extensive experiments on realworld crisis datasets demonstrate the significance of the proposed pipeline for optimal utilization of both human',\n",
       " 'and machine computing resources',\n",
       " 'earthquake dss is an information technology environment which can be used by government to sharpen make faster and better the earthquake mitigation decision earthquake dss can be delivered as egovernment which is not only for government itself but in order to guarantee each citizens rights for education training and information about earthquake and how to overcome the earthquake knowledge can be managed for future use and would become mining by saving and maintain all the data and information about',\n",
       " 'earthquake and earthquake mitigation in indonesia using web technology will enhance global access and easy to use datawarehouse as unnormalized database for multidimensional analysis will speed the query process and increase reports variation link with other disaster dss in one national disaster dss link with other government information system and international will enhance the knowledge and sharpen the reports',\n",
       " 'evacuation is one of the main disaster management solutions to reduce the impact of manmade and natural threats on building occupants to date several modern technologies and gamification concepts eg immersive virtual reality and serious games have been used to enhance building evacuation preparedness and effectiveness those tools have been used both to investigate human behavior during building emergencies and to train building occupants on how to cope with building evacuations augmented reality ar is novel',\n",
       " 'technology that can enhance this process providing building occupants with virtual contents to improve their evacuation performance this work aims at reviewing existing ar applications developed for building evacuation this review identifies the disasters and types of building those tools have been applied for moreover the application goals hardware and evacuation stages affected by ar are also investigated in the review finally this review aims at identifying the challenges to face for further development',\n",
       " 'of ar evacuation tools',\n",
       " 'timely and reliable sensing of infrastructure conditions is critical in disaster management for planning effective infrastructure restorations social media a near realtime information source has been widely used in disasters for forming timely situational awareness yet using social media to sense electricity infrastructure conditions has not been explored this study aims to address the research gap through mining public topics from social media to achieve this purpose we proposed a systematic and customized',\n",
       " 'approach wherein electricityrelated social media data is extracted by the classifier developed based on bidirectional encoder representations from transformers bert and public topics are modeled with unigrams bigrams and trigrams to incorporate the formulaic expressions of infrastructure conditions in social media electricity infrastructures in florida impacted by hurricane irma are studied for illustration and demonstration results show that the proposed approach is capable of sensing the temporal',\n",
       " 'evolutions and geographic differences of electricity infrastructure conditions',\n",
       " 'in this paper we present a workflow management system which permits the kinds of datadriven workflows required by urgent computing namely where new data is integrated into the workflow as a disaster progresses in order refine the predictions as time goes on this allows the workflow to adapt to new data at runtime a capability that most workflow management systems do not possess the workflow management system was developed for the eufunded vestec project which aims to fuse hpc with realtime data for',\n",
       " 'supporting urgent decision making we first describe an example workflow from the vestec project and show why existing workflow technologies do not meet the needs of the project we then go on to present the design of our workflow management system describe how it is implemented into the vestec system and provide an example of the workflow system in use for a test case',\n",
       " 'we consider the problem of decomposing monetary risk in the presence of a fully traded market in it some risks we show that a marktomarket approach to pricing leads to such a decomposition if the risk measure is timeconsistent in the sense of delbaen',\n",
       " 'different approaches to defining dynamic market risk measures are available in the literature most are focused or derived from probability theory economic behavior or dynamic programming here we propose an approach to define and implement dynamic market risk measures based on recursion and state economy representation the proposed approach is to be implementable and to inherit properties from static market risk measures',\n",
       " 'in decision under risk the primal moments of mean and variance play a central role to define the local index of absolute risk aversion in this paper we show that in canonical noneu models dual moments have to be used instead of or on par with their primal counterparts to obtain an equivalent index of absolute risk aversion',\n",
       " 'we study coherent risk measures which are timeconsistent for multiple filtrations we show that a coherent risk measure is timeconsistent for every filtration if and only if it is one of four main types furthermore if the risk measure is strictly monotone it is linear and if the reference probability space is not atomic then it is either linear or an essential supremum',\n",
       " 'we discuss the systemic risk implied by the interbank exposures reconstructed with the maximum entropy method the maximum entropy method severely underestimates the risk of interbank contagion by assuming a fully connected network while in reality the structure of the interbank network is sparsely connected here we formulate an algorithm for sparse network reconstruction and we show numerically that it provides a more reliable estimation of the systemic risk',\n",
       " 'this note presents a kind of the strong law of large numbers for an insurance risk caused by a single catastrophic event rather than by an accumulation of independent and identically distributed risks we derive this result by a large diversification effect resulting from optimal allocation of the risk to many reinsurers or investors',\n",
       " 'this paper approaches the definition and properties of dynamic convex risk measures through the notion of a family of concave valuation operators satisfying certain simple and credible axioms exploring these in the simplest context of a finite time set and finite sample space we find natural risktransfer and timeconsistency properties for a firm seeking to spread its risk across a group of subsidiaries',\n",
       " 'uncertainty requires suitable techniques for risk assessment combining stochastic approximation and stochastic average approximation we propose an efficient algorithm to compute the worst case average value at risk in the face of tail uncertainty dependence is modelled by the distorted mix method that flexibly assigns different copulas to different regions of multivariate distributions we illustrate the application of our approach in the context of financial markets and cyber risk',\n",
       " 'the sharpe ratio is the most widely used risk metric in the quantitative finance community amazingly essentially everyone gets it wrong in this note we will make a quixotic effort to rectify the situation',\n",
       " 'how risks are managed implicitly and explicitly at multiple levels of agile projects has not been extensively studied and there is a need to investigate how risk management can be used in large agile projects this is the objective of this exploratory study which investigates the following research question how does a large softwarehardware development project using agile practices manage uncertainty at projectsubproject and work package levels',\n",
       " 'in risk management it is desirable to grasp the essential statistical features of a time series representing a risk factor this tutorial aims to introduce a number of different stochastic processes that can help in grasping the essential features of risk factors describing different asset classes or behaviors this paper does not aim at being exhaustive but gives examples and a feeling for practically implementable models allowing for stylised features in the data the reader may also use these models as',\n",
       " 'building blocks to build more complex models although for a number of risk management applications the models developed here suffice for the first step in the quantitative analysis the broad qualitative features addressed here are fat tails and mean reversion we give some orientation on the initial choice of a suitable stochastic process and then explain how the process parameters can be estimated based on historical data once the process has been calibrated typically through maximum likelihood estimation',\n",
       " 'one may simulate the risk factor and build future scenarios for the risky portfolio on the terminal simulated distribution of the portfolio one may then single out several risk measures although here we focus on the stochastic processes estimation preceding the simulation of the risk factors finally this first survey report focuses on single time series correlation or more generally dependence across risk factors leading to multivariate processes modeling will be addressed in future work',\n",
       " 'global warming may induce in western europe an increase in storms hence the forest managers will have to take into account the risk increase we study the impact of storm risk at the stand level from the analytical expressions of the faustmann criterion and the expected longrun average yield we deduce in presence of storm risk the influence of criteria and of discount rate in terms of optimal thinnings and cutting age we discuss the validity of using a risk adjusted discount rate a rate of storm risk added',\n",
       " 'to the discount rate without risk to mimic the storm risk case in terms of optimal thinnings',\n",
       " 'model risk has a huge impact on any risk measurement procedure and its quantification is therefore a crucial step in this paper we introduce three quantitative measures of model risk when choosing a particular reference model within a given class the absolute measure of model risk the relative measure of model risk and the local measure of model risk each of the measures has a specific purpose and so allows for flexibility we illustrate the various notions by studying some relevant examples so as to',\n",
       " 'emphasize the practicability and tractability of our approach',\n",
       " 'in the present contribution we characterize law determined convex risk measures that have convex level sets at the level of distributions by relaxing the assumptions in weber we show that these risk measures can be identified with a class of generalized shortfall risk measures as a direct consequence we are able to extend the results in ziegel and bellini and bignozzi on convex elicitable risk measures and confirm that expectiles are the only elicitable coherent risk measures further we provide a simple',\n",
       " 'characterization of robustness for convex risk measures in terms of a weak notion of mixture continuity',\n",
       " 'we show how risk measures originally defined in a model free framework in terms of acceptance sets and reference assets imply a meaningful underlying probability structure hereafter we construct a maximal domain of definition of the risk measure respecting the underlying ambiguity profile we particularly emphasise liquidity effects and discuss the correspondence between properties of the risk measure and the structure of this domain as well as subdifferentiability properties keywords model free risk',\n",
       " 'assessment extension of risk measures continuity properties of risk measures subgradients',\n",
       " 'most of the banks operational risk internal models are based on loss pooling in risk and business line categories the parameters and outputs of operational risk models are sensitive to the pooling of the data and the choice of the risk classification in a simple model we establish the link between the number of risk cells and the model parameters by requiring invariance of the banks loss distribution upon a change in classification we provide details on the impact of this requirement on the domain of',\n",
       " 'attraction of the loss distribution on diversification effects and on cell risk correlations',\n",
       " 'in the paper we use and investigate copulas models to represent multivariate dependence in financial time series we propose the algorithm of risk measure computation using copula models using the optimal meancvar portfolio we compute portfolios profit and loss series and corresponded risk measures curves valueatrisk and conditionalvalueatrisk curves were simulated by three copula models full gaussian students t and regular vine copula these risk curves are lower than historical values of the risk measures',\n",
       " 'curve all three models have superior prediction ability than a usual empirical method further directions of research are described',\n",
       " 'as regulators pay more attentions to losses rather than gains we are able to derive a new class of risk statistics named regulatorbased risk statistics with scenario analysis in this paper this new class of risk statistics can be considered as a kind of risk extension of risk statistics introduced by kou et al cite and also databased versions of lossbased risk measures introduced by cont et al cite and sun et al cite',\n",
       " 'the portfolios are a critical factor not only in risk analysis but also in insurance and financial applications in this paper we consider a special class of risk statistics from the perspective of time value of the money this new risk statistic can be uesd for the quantification of portfolio risk by further developing the properties related to cash subadditive risk statistics we are able to derive representation results for such risk',\n",
       " 'it is well known that expected shortfall also called average valueatrisk is a convex risk measure i e expected shortfall of a convex linear combination of arbitrary risk positions is not greater than a convex linear combination with the same weights of expected shortfalls of the same risk positions in this short paper we prove that expected shortfall is a concave risk measure with respect to probability distributions i e expected shortfall of a finite mixture of arbitrary risk positions is not lower than',\n",
       " 'the linear combination of expected shortfalls of the same risk positions with the same weights as in the mixture',\n",
       " 'risk measures connect probability theory or statistics to optimization particularly to convex optimization they are nowadays standard in applications of finance and in insurance involving risk aversion this paper investigates a wide class of risk measures on orlicz spaces the characterizing function describes the decision makers risk assessment towards increasing losses we link the risk measures to a crucial formula developed by rockafellar for the average valueatrisk based on convex duality which is',\n",
       " 'fundamental in corresponding optimization problems we characterize the dual and provide complementary representations',\n",
       " 'in this paper we study general monetary risk measures without any convexity or weak convexity a monetary respectively positively homogeneous risk measure can be characterized as the lower envelope of a family of convex respectively coherent risk measures the proof does not depend on but easily leads to the classical representation theorems for convex and coherent risk measures when the lawinvariance and the ssd secondorder stochastic dominanceconsistency are involved it is not the convexity respectively',\n",
       " 'coherence but the comonotonic convexity respectively comonotonic coherence of risk measures that can be used for such kind of lower envelope characterizations in a unified form the representation of a lawinvariant risk measure in terms of var is provided',\n",
       " 'in this paper we discuss various problems in the usage and definition of risk matrices we give an overview of the general process of risk assessment with risk matrices and ordinal scales furthermore we explain the fallacies in each phase of this process and give hints on which decisions may lead to more problems than others and how to avoid them among those discussed problems are ordinal scales semiquantitative arithmetics range compression risk inversion ambiguity and neglection of uncertainty finally we',\n",
       " 'make a case for avoiding risk matrices altogether and instead propose using fully quantitative risk assessment methods',\n",
       " 'this work studies a stochastic optimal control problem for a pension scheme which provides an incomedrawdown policy to its members after their retirement to manage the scheme efficiently the manager and members agree to share the investment risk based on a predecided risksharing rule the objective is to maximise both sides utilities by controlling the managers investment in risky assets and members benefit withdrawals we use stochastic affine class models to describe the force of mortality of the members',\n",
       " 'population and consider a longevity bond whose coupon payment is linked to a survival index in our framework we also investigate the longevity basis risk which arises when the members and the longevity bonds reference populations show different mortality behaviours by applying the dynamic programming principle to solve the corresponding hjb equations we derive optimal solutions for the single and subpopulation cases our numerical results show that by sharing the risk both manager and members increase their',\n",
       " 'utility moreover even in the presence of longevity basis risk we demonstrate that the longevity bond acts as an effective hedging instrument',\n",
       " 'incentives play an important role in security and it risk management of a largescale organization with multiple autonomous divisions this paper presents an incentive mechanism design framework for risk management based on a gametheoretic approach the risk manager acts as a mechanism designer providing rules and incentive factors such as assistance or subsidies to divisions or units which are modeled as selfish players of a strategic noncooperative game based on this model incentive mechanisms with various',\n",
       " 'objectives are developed that satisfy efficiency preferencecompatibility and strategyproofness criteria in addition iterative and distributed algorithms are presented which can be implemented under information limitations such as the risk manager not knowing the individual units preferences an example scenario illustrates the framework and results numerically the incentive mechanism design approach presented is useful for not only deriving guidelines but also developing computerassistance systems for',\n",
       " 'largescale risk management',\n",
       " 'any optimization algorithm based on the risk parity approach requires the formulation of portfolio total risk in terms of marginal contributions in this paper we use the independence of the underlying factors in the market to derive the centered moments required in the risk decomposition process when the modified versions of value at risk and expected shortfall are considered the choice of the mixed tempered stable distribution seems adequate for fitting skewed and heavy tailed distributions the ensuing',\n",
       " 'detailed description of the optimization procedure is due to the existence of analytical higher order moments better results are achieved in terms of out of sample performance and greater diversification',\n",
       " 'the aim of this paper is to provide several examples of convex risk measures necessary for the application of the general framework for portfolio theory of maierpaape and zhu presented in part i of this series arxiv qfinpm as alternative to classical portfolio risk measures such as the standard deviation we in particular construct risk measures related to the current drawdown of the portfolio equity combined with the results of part i arxiv qfinpm this allows us to calculate efficient portfolios based on a',\n",
       " 'drawdown risk measure constraint',\n",
       " 'financial institutions have to allocate socalled economic capital in order to guarantee solvency to their clients and counter parties mathematically speaking any methodology of allocating capital is a risk measure ie a function mapping random variables to the real numbers nowadays valueatrisk which is defined as a fixed level quantile of the random variable under consideration is the most popular risk measure unfortunately it fails to reward diversification as it is not subadditive in the search for a',\n",
       " 'suitable alternative to valueatrisk expected shortfall or conditional valueatrisk or tail valueatrisk has been characterized as the smallest coherent and law invariant risk measure to dominate valueatrisk we discuss these and some other properties of expected shortfall as well as its generalization to a class of coherent risk measures which can incorporate higher moment effects moreover we suggest a general method on how to attribute expected shortfall risk contributions to portfolio components key words',\n",
       " 'expected shortfall valueatrisk spectral risk measure coherence risk contribution',\n",
       " 'risk measures for multivariate financial positions are studied in a utilitybased framework under a certain incomplete preference relation shortfall and divergence risk measures are defined as the optimal values of specific set minimization problems the dual relationship between these two classes of multivariate risk measures is constructed via a recent lagrange duality for set optimization in particular it is shown that a shortfall risk measure can be written as an intersection over a family of divergence',\n",
       " 'risk measures indexed by a scalarization parameter examples include setvalued versions of the entropic risk measure and the average value at risk as a second step the minimization of these risk measures subject to trading opportunities is studied in a general convex market in discrete time the optimal value of the minimization problem called the market risk measure is also a setvalued risk measure a dual representation for the market risk measure that decomposes the effects of the original risk measure and',\n",
       " 'the frictions of the market is proved',\n",
       " 'we present a general framework for measuring the liquidity risk the theoretical framework defines a class of risk measures that incorporate the liquidity risk into the standard risk measures we consider a oneperiod risk measurement model the liquidity risk is defined as the risk that a given security or a portfolio of securities cannot be easily sold or bought by the financial institutions without causing significant changes in prices the new risk measures present some differences with respect to the',\n",
       " 'standard risk measures in particular they are increasing monotonic and convex cash subadditive on long positions the contrary in certain situations holds for the sell positions for the long positions case we provide these new risk measures with a dual representation in some specific cases also the sell positions can be equipped with a dual representation we apply our framework to the situation in which financial institutions break up large trades into many small ones dual representation results are also',\n",
       " 'obtained we give many practical examples of risk measures and derive for each of them the respective capital requirement as a particular example we discuss the var measure',\n",
       " 'the risk premium of a policy is the sum of the pure premium and the risk loading in the classification ratemaking process generalized linear models are usually used to calculate pure premiums and various premium principles are applied to derive the risk loadings no matter which premium principle is used some risk loading parameters should be given in advance subjectively to overcome this subjective problem and calculate the risk premium more reasonably and objectively we propose a topdown method to',\n",
       " 'calculate these risk loading parameters first we implement the bootstrap method to calculate the total risk premium of the portfolio then under the constraint that the portfolios total risk premium should equal the sum of the risk premiums of each policy the risk loading parameters are determined during this process besides using generalized linear models three kinds of quantile regression models are also applied namely traditional quantile regression model fully parametric quantile regression model and',\n",
       " 'quantile regression model with coefficient functions the empirical result shows that the risk premiums calculated by the method proposed in this study can reasonably differentiate the heterogeneity of different risk classes',\n",
       " 'during natural and manmade disasters people use social media platforms such as twitter to post textual and multime dia content to report updates about injured or dead people infrastructure damage and missing or found people among other information types studies have revealed that this on line information if processed timely and effectively is ex tremely useful for humanitarian organizations to gain situational awareness and plan relief operations in addition to the analysis of textual content recent studies',\n",
       " 'have shown that imagery content on social media can boost disaster response significantly despite extensive research that mainly focuses on textual content to extract useful information limited work has focused on the use of imagery content or the combination of both content types one of the reasons is the lack of labeled imagery data in this domain therefore in this paper we aim to tackle this limitation by releasing a large multimodal dataset collected from twitter during different natural disasters we',\n",
       " 'provide three types of annotations which are useful to address a number of crisis response and management tasks for different humanitarian organizations',\n",
       " 'unmanned aerial vehicles uavs equipped with camera sensors can facilitate enhanced situational awareness for many emergency response and disaster management applications since they are capable of operating in remote and difficult to access areas in addition by utilizing an embedded platform and deep learning uavs can autonomously monitor a disaster stricken area analyze the image in realtime and alert in the presence of various calamities such as collapsed buildings flood or fire in order to faster mitigate',\n",
       " 'their effects on the environment and on human population to this end this paper focuses on the automated aerial scene classification of disaster events from onboard a uav specifically a dedicated aerial image database for emergency response aider applications is introduced and a comparative analysis of existing approaches is performed through this analysis a lightweight convolutional neural network cnn architecture is developed capable of running efficiently on an embedded platform achieving x higher',\n",
       " 'performance compared to existing models with minimal memory requirements with less than accuracy drop compared to the stateoftheart these preliminary results provide a solid basis for further experimentation towards realtime aerial image classification for emergency response applications using uavs',\n",
       " 'in the monsoon season sudden flood events occur frequently in urban areas which hamper the social and economic activities and may threaten the infrastructure and lives the use of an efficient largescale waterlogging sensing and information system can provide valuable realtime disaster information to facilitate disaster management and enhance awareness of the general public to alleviate losses during and after flood disasters therefore in this study a visual sensing approach driven by deep neural networks',\n",
       " 'and information and communication technology was developed to provide an endtoend mechanism to realize waterlogging sensing and eventlocation mapping the use of a deep sensing system in the monsoon season in taiwan was demonstrated and waterlogging events were predicted on the islandwide scale the system could sense approximately vision sources through an internet of video things framework and transmit the eventlocation information in min the proposed approach can sense waterlogging events at a national',\n",
       " 'scale and provide an efficient and highly scalable alternative to conventional waterlogging sensing methods',\n",
       " 'the problem of estimation error of expected shortfall is analyzed with a view of its introduction as a global regulatory risk measure',\n",
       " 'we define scenarios propose different methods of aggregating them discuss their properties and benchmark them against quadrant requirements',\n",
       " 'we study the problem of portfolio insurance from the point of view of a fund manager who guarantees to the investor that the portfolio value at maturity will be above a fixed threshold if at maturity the portfolio value is below the guaranteed level a third party will refund the investor up to the guarantee in exchange for this protection the third party imposes a limit on the risk exposure of the fund manager in the form of a convex monetary risk measure the fund manager therefore tries to maximize the',\n",
       " 'investors utility function subject to the risk measure constraintwe give a full solution to this nonconvex optimization problem in the complete market setting and show in particular that the choice of the risk measure is crucial for the optimal portfolio to exist explicit results are provided for the entropic risk measure for which the optimal portfolio always exists and for the class of spectral risk measures for which the optimal portfolio may fail to exist in some cases',\n",
       " 'in this note we sketch an initial tentative approach to funding costs analysis and management for contracts with bilateral counterparty risk in a simplified setting we depart from the existing literature by analyzing the issue of funding costs and benefits under the assumption that the associated risks cannot be hedged properly we also model the treasury funding spread by means of a stochastic weighted cost of funding spread wcfs which helps describing more realistic financing policies of a financial',\n",
       " 'institution we elaborate on some limitations in replicationbased funding credit valuation adjustments we worked on ourselves in the past namely cva dva fva and related quantities as generally discussed in the industry we advocate as a different possibility when replication is not possible the analysis of the funding profit and loss distribution and explain how long term funding spreads wrong way risk and systemic risk are generally overlooked in most of the current literature on risk measurement of funding',\n",
       " 'costs as a matter of initial illustration we discuss in detail the funding management of interest rate swaps with bilateral counterparty risk in the simplified setup of our framework through numerical examples and via a few simplified assumptions',\n",
       " 'modern society heavily relies on strongly connected sociotechnical systems as a result distinct risks threatening the operation of individual systems can no longer be treated in isolation consequently risk experts are actively seeking for ways to relax the risk independence assumption that undermines typical risk management models prominent work has advocated the use of risk networks as a way forward yet the inevitable biases introduced during the generation of these surveybased risk networks limit our',\n",
       " 'ability to examine their topology and in turn challenge the utility of the very notion of a risk network to alleviate these concerns we proposed an alternative methodology for generating weighted risk networks we subsequently applied this methodology to an empirical dataset of financial data this paper reports our findings on the study of the topology of the resulting risk network we observed a modular topology and reasoned on its use as a robust risk classification framework using these modules we',\n",
       " 'highlight a tendency of specialization during the risk identification process with some firms being solely focused on a subset of the available risk classes finally we considered the independent and systemic impact of some risks and attributed possible mismatches to their emerging nature',\n",
       " 'expectiles were defined using a minimisation principle they form a special class of coherent risk measures we will describe the scenario set and we will show that there is a most severe commonotonic risk measure that is smaller than the given expectile',\n",
       " 'conditional forecasts of risk measures play an important role in internal risk management of financial institutions as well as in regulatory capital calculations in order to assess forecasting performance of a risk measurement procedure risk measure forecasts are compared to the realized financial losses over a period of time and a statistical test of correctness of the procedure is conducted this process is known as backtesting such traditional backtests are concerned with assessing some optimality',\n",
       " 'property of a set of risk measure estimates however they are not suited to compare different risk estimation procedures we investigate the proposal of comparative backtests which are better suited for method comparisons on the basis of forecasting accuracy but necessitate an elicitable risk measure we argue that supplementing traditional backtests with comparative backtests will enhance the existing trading book regulatory framework for banks by providing the correct incentive for accuracy of risk measure',\n",
       " 'forecasts in addition the comparative backtesting framework could be used by banks internally as well as by researchers to guide selection of forecasting methods the discussion focuses on three risk measures valueatrisk expected shortfall and expectiles and is supported by a simulation study and data analysis',\n",
       " 'starting from the requirement that risk measures of financial portfolios should be based on their losses not their gains we define the notion of lossbased risk measure and study the properties of this class of risk measures we characterize lossbased risk measures by a representation theorem and give examples of such risk measures we then discuss the statistical robustness of estimators of lossbased risk measures we provide a general criterion for qualitative robustness of risk estimators and compare this',\n",
       " 'criterion with sensitivity analysis of estimators based on influence functions finally we provide examples of statistically robust estimators for lossbased risk measures',\n",
       " 'previous literature shows that prevalent risk measures such as value at risk or expected shortfall are ineffective to curb excessive risktaking by a tailriskseeking trader with sshaped utility function in the context of portfolio optimisation however these conclusions hold only when the constraints are static in the sense that the risk measure is just applied to the terminal portfolio value in this paper we consider a portfolio optimisation problem featuring sshaped utility and a dynamic risk constraint',\n",
       " 'which is imposed throughout the entire trading horizon provided that the risk control policy is sufficiently strict relative to the asset performance the traders portfolio strategies and the resulting maximal expected utility can be effectively constrained by a dynamic risk measure finally we argue that dynamic risk constraints might still be ineffective if the trader has access to a derivatives market',\n",
       " 'the downside risk of a portfolio of equityassets is generally substantially higher than the downside risk of its components in particular in times of crises when assets tend to have high correlation the understanding of this difference can be crucial in managing systemic risk of a portfolio in this paper we generalize mertons option formula in the presence jumps to the multiasset case it is shown how common jumps across assets provide an intuitive and powerful tool to describe systemic risk that is',\n",
       " 'consistent with data the methodology provides a new way to mark and riskmanage systemic risk of portfolios in a systematic way',\n",
       " 'potential future exposure pfe is a standard risk metric for managing business unit counterparty credit risk but there is debate on how it should be calculated the debate has been whether to use one of many historical physical measures one per calibration setup or one of many riskneutral measures one per numeraire however we argue that limits should be based on the banks own risk appetite provided that this is consistent with regulatory backtesting and that whichever measure is used it should behave in a',\n",
       " 'sense made precise like a historical measure backtesting is only required by regulators for banks with imm approval but we expect that similar methods are part of limit maintenance generally we provide three methods for computing the bank price of risk from readily available business unit data ie business unit budgets rate of return and limits eg exposure percentiles hence we define and propose a risk appetite measure a for pfe and suggest that this is uniquely consistent with the banks risk appetite',\n",
       " 'framework as required by sound governance',\n",
       " 'we provide analytical results for a static portfolio optimization problem with two coherent risk measures the use of two risk measures is motivated by joint decisionmaking for portfolio selection where the risk perception of the portfolio manager is of primary concern hence it appears in the objective function and the risk perception of an external authority needs to be taken into account as well which appears in the form of a risk constraint the problem covers the risk minimization problem with an expected',\n",
       " 'return constraint and the expected return maximization problem with a risk constraint as special cases for the general case of an arbitrary joint distribution for the asset returns under certain conditions we characterize the optimal portfolio as the optimal lagrange multiplier associated to an equalityconstrained dual problem then we consider the special case of gaussian returns for which it is possible to identify all cases where an optimal solution exists and to give an explicit formula for the optimal',\n",
       " 'portfolio whenever it exists',\n",
       " 'we consider the problem of active portfolio management where a lossaverse andor gainseeking investor aims to outperform a benchmark strategys risk profile while not deviating too much from it specifically an investor considers alternative strategies that comove with the benchmark and whose terminal wealth lies within a wasserstein ball surrounding it the investor then chooses the alternative strategy that minimises their personal risk preferences modelled in terms of a distortion risk measure in a general',\n",
       " 'market model we prove that an optimal dynamic strategy exists and is unique and provide its characterisation through the notion of isotonic projections finally we illustrate how investors with different risk preferences invest and improve upon the benchmark using the tail valueatrisk inverse sshaped distortion risk measures and lower and uppertail risk measures as examples we find that investors optimal terminal wealth distribution has larger probability masses in regions that reduce their risk measure',\n",
       " 'relative to the benchmark while preserving some aspects of the benchmark',\n",
       " 'we study a static portfolio optimization problem with two risk measures a principle risk measure in the objective function and a secondary risk measure whose value is controlled in the constraints this problem is of interest when it is necessary to consider the risk preferences of two parties such as a portfolio manager and a regulator at the same time a special case of this problem where the risk measures are assumed to be coherent positively homogeneous is studied recently in a joint work of the author',\n",
       " 'the present paper extends the analysis to a more general setting by assuming that the two risk measures are only quasiconvex first we study the case where the principal risk measure is convex we introduce a dual problem show that there is zero duality gap between the portfolio optimization problem and the dual problem and finally identify a condition under which the lagrange multiplier associated to the dual problem at optimality gives an optimal portfolio next we study the general case without the',\n",
       " 'convexity assumption and show that an approximately optimal solution with prescribed optimality gap can be achieved by using the wellknown bisection algorithm combined with a duality result that we prove',\n",
       " 'major disasters such as extreme weather events can magnify and exacerbate preexisting social disparities with disadvantaged populations bearing disproportionate costs despite the implications for equity and emergency planning we lack a quantitative understanding of how these social fault lines translate to different behaviors in largescale emergency contexts here we investigate this problem in the context of hurricane harvey using over million anonymized gps records from over optedin users in the greater',\n",
       " 'houston area to quantify patterns of disasterinflicted relocation activities before during and after the shock we show that evacuation distance is highly homogenous across individuals from different types of neighborhoods classified by race and wealth obeying a truncated powerlaw distribution yet here the similarities end we find that both race and wealth strongly impact evacuation patterns with disadvantaged minority populations less likely to evacuate than wealthier white residents finally there are',\n",
       " 'considerable discrepancies in terms of departure and return times by race and wealth with strong social cohesion among evacuees from advantaged neighborhoods in their destination choices these empirical findings bring new insights into mobility and evacuations providing policy recommendations for residents decision makers and disaster managers alike',\n",
       " 'high precision analytical approximation is proposed for variancecovariance based risk allocation in a portfolio of risky assets a general case of a singleperiod multifactor mertontype model with stochastic recovery is considered the accuracy of the approximation as well as its speed are compared to and shown to be superior to those of monte carlo simulation',\n",
       " 'in the paper portfolio optimization over long run risk sensitive criterion is considered it is assumed that economic factors which stimulate asset prices are ergodic but non necessarily uniformly ergodic solution to suitable bellman equation using local span contraction with weighted norms is shown the form of optimal strategy is presented and examples of market models satisfying imposed assumptions are shown',\n",
       " 'a new class of risk measures called cash subadditive risk measures is introduced to assess the risk of future financial nonfinancial and insurance positions the debated cash additive axiom is relaxed into the cash sub additive axiom to preserve the original difference between the numeraire of the current reserve amounts and future positions consequently cash subadditive risk measures can model stochastic andor ambiguous interest rates or defaultable contingent claims practical examples are presented and in',\n",
       " 'such contexts cash additive risk measures cannot be used several representations of the cash subadditive risk measures are provided the new risk measures are characterized by penalty functions defined on a set of sublinear probability measures and can be represented using penalty functions associated with cash additive risk measures defined on some extended spaces the issue of the optimal risk transfer is studied in the new framework using infconvolution techniques examples of dynamic cash subadditive risk',\n",
       " 'measures are provided via bsdes where the generator can locally depend on the level of the cash subadditive risk measure',\n",
       " 'in this paper we address the aggregation of dependent stop loss reinsurance risks where the dependence among the ceding insurers risks is governed by the sarmanov distribution and each individual risk belongs to the class of erlang mixtures we investigate the effects of the ceding insurers risk dependencies on the reinsurer risk profile by deriving a closed formula for the distribution function of the aggregated stop loss reinsurance risk furthermore diversification effects from aggregating reinsurance',\n",
       " 'risks are examined by deriving a closed expression for the risk capital needed for the whole portfolio of the reinsurer and also the allocated risk capital for each business unit under the tvar capital allocation principle moreover given the risk capital that the reinsurer holds we express the default probability of the reinsurer analytically in case the reinsurer is in default we determine analytical expressions for the amount of the aggregate reinsured unpaid losses and the unpaid losses of each reinsured',\n",
       " 'line of business of the ceding insurers these results are illustrated by numerical examples',\n",
       " 'in this paper we introduce the rich classes of conditional distortion cod risk measures and distortion risk contribution deltacod measures as measures of systemic risk and analyze their properties and representations the classes include the wellknown conditional valueatrisk conditional expected shortfall and risk contribution measures in terms of the var and es as special cases sufficient conditions are presented for two random vectors to be ordered by the proposed codrisk measures and distortion risk',\n",
       " 'contribution measures these conditions are expressed using the conventional stochastic dominance increasing convexconcave dispersive and excess wealth orders of the marginals and canonical positivenegative stochastic dependence notions numerical examples are provided to illustrate our theoretical findings this paper is the second in a triplet of papers on systemic risk by the same authors in citedlzorder a we introduce and analyze some new stochastic orders related to systemic risk in a third forthcoming',\n",
       " 'paper we attribute systemic risk to the different participants in a given risky environment',\n",
       " 'risk specialists are trying to understand risk better and use complex models for risk assessment while many risks are not yet well understood the lack of empirical data and complex causal and outcome relationships make it difficult to estimate the degree to which certain risk types are exposed traditional risk models are based on classical set theory in comparison fuzzy logic models are built on fuzzy set theory and are useful for analyzing risks with insufficient knowledge or inaccurate data fuzzy logic',\n",
       " 'systems help to make largescale risk management frameworks more simple for risks that do not have an appropriate probability model a fuzzy logic system can help model the cause and effect relationships assess the level of risk exposure rank key risks in a consistent way and consider available data and expertsopinions besides in fuzzy logic systems some rules explicitly explain the connection dependence and relationships between model factors this can help identify risk mitigation solutions resources can be',\n",
       " 'used to mitigate risks with very high levels of exposure and relatively low hedging costs fuzzy set and fuzzy logic models can be used with bayesian and other types of method recognition and decision models including artificial neural networks and decision tree models these developed models have the potential to solve difficult risk assessment problems this research paper explores areas in which fuzzy logic models can be used to improve risk assessment and risk decision making we will discuss the',\n",
       " 'methodology framework and process of using fuzzy logic systems in risk assessment',\n",
       " 'it is no secret that many projects fail regardless of the business sector software projects are notoriously disaster victims not necessarily because of technological failure but more often due to their uncertainties the threats identified by uncertainty in daytoday of a project are real and immediate and the stakes in a project are often high this paper presents a systematic review about software project management uncertainties it helps to identify the difficulties and the actions that can minimize the',\n",
       " 'uncertainties effects in the projects and how managers and teams can prepare themselves for the challenges of their projects scenario with the aim of contributing to the improvement of project management in organizations as well as contributing to project success',\n",
       " 'floods of research and practical applications employ social media data for a wide range of public applications including environmental monitoring water resource managing disaster and emergency responsehydroinformatics can benefit from the social media technologies with newly emerged data techniques and analytical tools to handle large datasets from which creative ideas and new values could be minedthis paper first proposes a w what why when how model and a methodological structure to better understand and',\n",
       " 'represent the application of social media to hydroinformatics then provides an overview of academic research of applying social media to hydroinformatics such as water environment water resources flood drought and water scarcity management at lastsome advanced topics and suggestions of water related social media applications from data collection data quality management fake news detection privacy issues algorithms and platforms was present to hydroinformatics managers and researchers based on previous',\n",
       " 'discussion',\n",
       " 'this article studies the impact of carbon risk on stock pricing to address this we consider the seminal approach of gorgen textslet al who proposed estimating the carbon financial risk of equities by their carbon beta to achieve this the primary task is to develop a brownminusgreen or bmg risk factor similar to fama and french secondly we must estimate the carbon beta using a multifactor model while gorgen textslet al considered that the carbon beta is constant we propose a timevarying estimation model to',\n",
       " 'assess the dynamics of the carbon risk moreover we test several specifications of the bmg factor to understand which climate changerelated dimensions are priced in by the stock market in the second part of the article we focus on the carbon risk management of investment portfolios first we analyze how carbon risk impacts the construction of a minimum variance portfolio as the goal of this portfolio is to reduce unrewarded financial risks of an investment incorporating the carbon risk into this approach',\n",
       " 'fulfils this objective second we propose a new framework for building enhanced index portfolios with a lower exposure to carbon risk than capitalizationweighted stock indices finally we explore how carbon sensitivities can improve the robustness of factor investing portfolios',\n",
       " 'most risk analysis models systematically underestimate the probability and impact of catastrophic events eg economic crises natural disasters and terrorism by not taking into account interconnectivity and interdependence of risks to address this weakness we propose the cascading alternating renewal process carp to forecast interconnected global risks however assessments of the models prediction precision are limited by lack of sufficient ground truth data here we establish prediction precision as a function',\n",
       " 'of input data size by using alternative long ground truth data generated by simulations of the carp model with known parameters we illustrate the approach on a model of fires in artificial cities assembled from basic city blocks with diverse housing the results confirm that parameter recovery variance exhibits power law decay as a function of the length of available ground truth data using carp we also demonstrate estimation using a disparate dataset that also has dependencies realworld prediction precision',\n",
       " 'for the global risk model based on the world economic forum global risk report we conclude that the carp model is an efficient method for predicting catastrophic cascading events with potential applications to emerging local and global interconnected risks',\n",
       " 'spreadsheets are used extensively within todays organisations although spreadsheets have many benefits they can also present a significant risk exposure requiring appropriate management protiviti has worked with a number of organisations ranging in size up to huge multinationals to help them build appropriate spreadsheet governance frameworks including the design and implementation of policies minimum design standards control processes training and awareness programmes and the consideration and',\n",
       " 'implementation of spreadsheet management tools this paper presents a casestudy explaining the practical and pragmatic approach that was recently taken to control spreadsheet risk at one of protivitis clients a global energy firm',\n",
       " 'in this paper we consider the assetliability management under the meanvariance criterion the financial market consists of a riskfree bond and a stock whose price process is modeled by a geometric brownian motion the liability of the investor is uncontrollable and is modeled by another geometric brownian motion we consider a specific statedependent risk aversion which depends on a power function of the liability by solving a flow of fbsdes with bivariate state process we obtain the equilibrium strategy among',\n",
       " 'all the openloop controls for this timeinconsistent control problem it shows that the equilibrium strategy is a feedback control of the liability',\n",
       " 'anticipatory thinking is a complex cognitive process for assessing and managing risk in many contexts humans use anticipatory thinking to identify potential future issues and proactively take actions to manage their risks in this paper we define a cognitive systems approach to anticipatory thinking as a metacognitive goal reasoning mechanism the contributions of this paper include defining anticipatory thinking in the midca cognitive architecture operationalizing anticipatory thinking as a three step',\n",
       " 'process for managing risk in plans and a numeric risk assessment calculating an expected costbenefit ratio for modifying a plan with anticipatory actions',\n",
       " 'decisions on how to manage future flood risks are frequently informed by both sophisticated and computationally expensive models this complexity often limits the representation of uncertainties and the consideration of strategies here we use an intermediate complexity model framework that enables us to analyze a rich set of strategies objectives and uncertainties we find that allowing for more combinations of risk mitigation strategies can expand the solution set help explain synergies and tradeoffs and',\n",
       " 'point to strategies that can improve outcomes',\n",
       " 'we present a constructive approach to bernstein copulas with an admissible discrete skeleton in arbitrary dimensions when the underlying marginal grid sizes are smaller than the number of observations this prevents an overfitting of the estimated dependence model and reduces the simulation effort for bernstein copulas a lot in a case study we compare different approaches of bernstein and gaussian copulas wrt the estimation of risk measures in risk management',\n",
       " 'although portfolio management didnt change much during the years after the seminal works of markowitz and sharpe the development of risk budgeting techniques marked an important milestone in the deepening of the relationship between risk and asset management risk parity then became a popular financial model of investment after the global financial crisis in today pension funds and institutional investors are using this approach in the development of smart indexing and the redefinition of longterm investment',\n",
       " 'policies introduction to risk parity and budgeting provides an uptodate treatment of this alternative method to markowitz optimization it builds financial exposure to equities and commodities considers credit risk in the management of bond portfolios and designs longterm investment policy this book contains the solutions of tutorial exercices which are included in introduction to risk parity and budgeting',\n",
       " 'a fundamental problem in risk management is the robust aggregation of different sources of risk in a situation where little or no data are available to infer information about their dependencies a popular approach to solving this problem is to formulate an optimization problem under which one maximizes a risk measure over all multivariate distributions that are consistent with the available data in several special cases of such models there exist dual problems that are easier to solve or approximate',\n",
       " 'yielding robust bounds on the aggregated risk in this chapter we formulate a general optimization problem which can be seen as a doubly infinite linear programming problem and we show that the associated dual generalizes several well known special cases and extends to new risk management models we propose',\n",
       " 'this report was originally written as an industry white paper on hedge funds this paper gives an overview to hedge funds with a focus on risk management issues we define and explain the general characteristics of hedge funds their main investment strategies and the risk models employed we address the problems in hedge fund modelling survey current hedge funds available on the market and those that have been withdrawn finally we summarise the supporting and opposing arguments for hedge fund usage a unique',\n",
       " 'value of this paper compared to other hedge fund literature freely available on the internet is that this review is fully sourced from academic references such as peer reviewed journals and is thus a bona fide study this paper will be of interest to hedge fund and mutual fund managers quantitative analysts front and middle office banking functions eg treasury management regulators concerned with hedge fund financial risk management private and institutional investors academic researchers in the area of',\n",
       " 'financial risk management and the general finance community',\n",
       " 'the current globalization is faced to the rapid development of product design process with the different structure of the actor relationships in the process currently the risk in the failure relationship among different actors in the project is shaped by the complexity towards the future all kinds of challenges when it comes to the interdependent failure effect the risk management for future organization structure in design process will be much more complex to grasp in order to cope with adaption of',\n",
       " 'productprocessorganization ppo model for industry of the future we propose a risk management methodology to cope with this interdependent relationship structure the main objective of this research is to manage the risks so that the project manager can find the priority order of all the actors total effect to the project with the consideration of interdependent failure affection and according to the order project manager can release corresponding respond measures',\n",
       " 'estimating and assessing the risk of a large portfolio is an important topic in financial econometrics and risk management the risk is often estimated by a substitution of a good estimator of the volatility matrix however the accuracy of such a risk estimator for large portfolios is largely unknown and a simple inequality in the previous literature gives an infeasible upper bound for the estimation error in addition numerical studies illustrate that this upper bound is very crude in this paper we propose',\n",
       " 'factorbased risk estimators under a large amount of assets and introduce a highconfidence level upper bound hclub to assess the accuracy of the risk estimation the hclub is constructed based on three different estimates of the volatility matrix sample covariance approximate factor model with known factors and unknown factors poet fan liao and mincheva for the first time in the literature we derive the limiting distribution of the estimated risks in high dimensionality our numerical results demonstrate that',\n",
       " 'the proposed upper bounds significantly outperform the traditional crude bounds and provide insightful assessment of the estimation of the portfolio risks in addition our simulated results quantify the relative error in the risk estimation which is usually negligible using month daily data finally the proposed methods are applied to an empirical study',\n",
       " 'determining risk contributions of unit exposures to portfoliowide economic capital is an important task in financial risk management computing risk contributions involves difficulties caused by rareevent simulations in this study we address the problem of estimating risk contributions when the total risk is measured by valueatrisk var our proposed estimator of var contributions is based on the metropolishasting mh algorithm which is one of the most prevalent markov chain monte carlo mcmc methods unlike',\n",
       " 'existing estimators our mhbased estimator consists of samples from conditional loss distribution given a rare event of interest this feature enhances sample efficiency compared with the crude monte carlo method moreover our method has the consistency and asymptotic normality and is widely applicable to various risk models having joint loss density our numerical experiments based on simulation and realworld data demonstrate that in various risk models even those having highdimensional approximately',\n",
       " 'inhomogeneous margins our mh estimator has smaller bias and mean squared error compared with existing estimators',\n",
       " 'this paper is directed to the financial community and focuses on the financial risks associated with climate change it specifically addresses the estimate of climate risk embedded within a bank loan portfolio during the st century manmade carbon dioxide emissions in the atmosphere will raise global temperatures resulting in severe and unpredictable physical damage across the globe another uncertainty associated with climate known as the energy transition risk comes from the unpredictable pace of political',\n",
       " 'and legal actions to limit its impact the climate extended risk model cerm adapts well known credit risk models it proposes a method to calculate incremental credit losses on a loan portfolio that are rooted into physical and transition risks the document provides detailed description of the model hypothesis and steps this work was initiated by the association green rwa risk weighted assets it was written in collaboration with jeanbaptiste gaudemet anne gruz and olivier vinciguerra cermgreenrwaorg who',\n",
       " 'contributed their financial and risk expertise taking care of its application to a pilotportfolio it extends the model proposed in a first white paper published by green rwa',\n",
       " 'this paper applies an ar garch process to detail the conditional distributions of the return distributions for the sp ft dax hang seng and nikkei futures contracts it then uses the conditional distribution for these contracts to estimate spectral risk measures which are coherent risk measures that reflect a users riskaversion function it compares these to more familiar var and expected shortfall es measures of risk and also compares the precision and discusses the relative usefulness of each of these risk',\n",
       " 'measures in setting variation margins that incorporate timevarying market conditions the goodness of fit of the model is confirmed by a variety of backtests',\n",
       " 'this paper examines the precision of estimators of quantilebased risk measures value at risk expected shortfall spectral risk measures it first addresses the question of how to estimate the precision of these estimators and proposes a monte carlo method that is free of some of the limitations of existing approaches it then investigates the distribution of risk estimators and presents simulation results suggesting that the common practice of relying on asymptotic normality results might be unreliable with',\n",
       " 'the sample sizes commonly available to them finally it investigates the relationship between the precision of different risk estimators and the distribution of underlying losses or returns and yields a number of useful conclusions',\n",
       " 'this paper studies the problem of optimal investment with crra constant relative risk aversion preferences subject to dynamic risk constraints on trading strategies the market model considered is continuous in time and incomplete the prices of financial assets are modeled by ito processes the dynamic risk constraints which are time and state dependent are generated by risk measures optimal trading strategies are characterized by a quadratic bsde within the class of textittime consistent distortion risk',\n",
       " 'measures a threefund separation result is established numerical results emphasize the effects of imposing risk constraints on trading',\n",
       " 'in this paper we investigate risk minimization problem of derivatives based on nontradable underlyings by means of dynamic gexpectations which are slight different from conditional gexpectations in this framework inspired by and we introduce risk indifference price marginal risk price and derivative hedge and obtain their corresponding explicit expressions the interesting thing is that their expressions have nothing to do with nonlinear generator g and one deep reason for this is due to the completeness of',\n",
       " 'financial market by giving three useful special risk minimization problems we obtain the explicit optimal strategies with initial wealth involved demonstrate some qualitative analysis among optimal strategies risk aversion parameter and market price of risk together with some economic interpretations',\n",
       " 'the work deals with the risk assessment theory an unitary risk algorithm is elaborated the algorithm is based on parallel curves the basic curve of risk is a hyperbolic curve obtained as a multiplication between the probability of occurrence of certain event and its impact section contains the problem formulation section contains some specific notations and the mathematical background of risk algorithm a numerical application based on risk algorithm is the content of section section contains several',\n",
       " 'conclusions',\n",
       " 'we discuss equivalent axiomatic characterizations of distortion risk measures and give a novel and concise proof of the characterization of elicitable distortion risk measures elicitability has recently been discussed as a desirable criterion for risk measures motivated by statistical considerations of forecasting we reveal the mathematical conflict between the requirements of elicitability and comonotonic additivity which intuitively explains why only valueatrisk and the mean are elicitable distortion risk',\n",
       " 'measures in a general sense',\n",
       " 'we introduce a class of dependence structures that we call the multiple risk factor mrf dependence structures on the one hand the new constructions extend the popular creditrisk approach and as such they formally describe default risk portfolios exposed to an arbitrary number of fatal risk factors with conditionally exponential and dependent hitting or occurrence times on the other hand the mrf structures can be seen as an encompassing family of multivariate probability distributions with univariate margins',\n",
       " 'distributed pareto of the nd kind and in this role they can be used to model insurance risk portfolios of dependent and heavy tailed risk components',\n",
       " 'we present a dialogue on counterparty credit risk touching on credit value at risk credit var potential future exposure pfe expected exposure ee expected positive exposure epe credit valuation adjustment cva debit valuation adjustment dva dva hedging closeout conventions netting clauses collateral modeling gap risk rehypothecation wrong way risk basel iii inclusion of funding costs first to default risk contingent credit default swaps ccds and cva restructuring possibilities through margin lending the',\n",
       " 'dialogue is in the form of a qa between a cva expert and a newly hired colleague',\n",
       " 'we study the effects of nonsystematic and systematic mortality risks on the required initial capital in a pension plan in the presence of financial risks we discover that for a pension plan with few members the impact of pooling on the required capital per person is strong but nonsystematic risk diminishes rapidly as the number of members increases systematic mortality risk on the other hand is a significant source of risk is a pension portfolio',\n",
       " 'systemic risk in banking systems remains a crucial issue that it has not been completely understood in our toy model banks are exposed to two sources of risks namely market risk from their investments in assets external to the banking system and credit risk from their lending in the interbank market by and large both risks increase during severe financial turmoil under this scenario the paper shows the conditions under which both the individual and the systemic default tend to coincide',\n",
       " 'since the quasiconvex risk measures is a bigger class than the well known convex risk measures the study of quasiconvex risk measures makes sense especially in the financial markets with volatility in this paper we will study the quasiconvex risk measures defined on a special space lpcdot where the variable exponent pcdot is no longer a given real number like the space lp but a random variable which reflects the possible volatility of the financial markets the dual representation for this quasiconvex risk',\n",
       " 'measures will also provided',\n",
       " 'what are the origins of risks and how material are they these are the two most fundamental questions of any risk analysis quantitative structuring a technology for building financial products provides economically meaningful answers for both of these questions it does so by considering risk as an investment opportunity the structure of the investment reveals the precise sources of risk and its expected performance measures materiality we demonstrate these capabilities of quantitative structuring using a',\n",
       " 'concrete practical example model risk in options on voltargeted indices',\n",
       " 'the equivalence between multiportfolio time consistency of a dynamic multivariate risk measure and a supermartingale property is proven furthermore the dual variables under which this setvalued supermartingale is a martingale are characterized as the worstcase dual variables in the dual representation of the risk measure examples of multivariate risk measures satisfying the supermartingale property are given crucial for obtaining the results are dual representations of scalarizations of setvalued dynamic',\n",
       " 'risk measures which are of independent interest in the fast growing literature on multivariate risks',\n",
       " 'motivated by liquidity risk in mathematical finance d lacker introduced concentration inequalities for risk measures ie upper bounds on the emphliquidity risk profile of a financial loss we derive these inequalities in the case of timeconsistent dynamic risk measures when the filtration is assumed to carry a brownian motion the theory of backward stochastic differential equations bsdes and their dual formulation plays a crucial role in our analysis natural byproducts of concentration of risk measures are a',\n",
       " 'description of the tail behavior of the financial loss and transporttype inequalities in terms of the generator of the bsde which in the present case can grow arbitrarily fast',\n",
       " 'since the latest financial crisis the idea of systemic risk has received considerable interest in particular contagion effects arising from crossholdings between interconnected financial firms have been studied extensively drawing inspiration from the field of complex networks these attempts are largely unaware of models and theories for credit risk of individual firms here we note that recent network valuation models extend the seminal structural risk model of merton furthermore we formally compute',\n",
       " 'sensitivities to various risk factors commonly known as greeks in a network context in particular we propose the network delta as a quantitative measure of systemic risk and illustrate our findings on some numerical examples',\n",
       " 'a so called zipf analysis portofolio management technique is introduced in order to comprehend the risk and returns two portofoios are built each from a well known financial index the portofolio management is based on two approaches one called the equally weighted portofolio the other the confidence parametrized portofolio a discussion of the yearly expected return variance sharpe ratio and beta follows optimization levels of high returns or low risks are found',\n",
       " 'shrunk sample covariance matrix is a factor model of a special form combining some typically style risk factors and principal components with a blockdiagonal factor covariance matrix as such shrinkage which essentially inherits outofsample instabilities of the sample covariance matrix is not an alternative to multifactor risk models but one out of myriad possible regularization schemes we give an example of a scheme designed to be less prone to said instabilities we contextualize this within multifactor',\n",
       " 'models',\n",
       " 'we give an explicit algorithm and source code for extracting equity risk factors from dead aka flatlined or hockeystick alphas and using them to improve performance characteristics of good tradable alphas in a nutshell we use dead alphas to extract directions in the space of stock returns along which there is no money to be made andor those bets are too volatile in practice the number of dead alphas can be large compared with the number of underlying stocks and care is required in identifying the aforesaid',\n",
       " 'directions',\n",
       " 'the interconnectivity of cyber and physical systems and internet of things has created ubiquitous concerns of cyber threats for enterprise system managers it is common that the asset owners and enterprise network operators need to work with cybersecurity professionals to manage the risk by remunerating them for their efforts that are not directly observable in this paper we use a principalagent framework to capture the service relationships between the two parties ie the asset owner principal and the cyber',\n",
       " 'risk manager agent specifically we consider a dynamic systemic risk management problem with asymmetric information where the principal can only observe cyber risk outcomes of the enterprise network rather than directly the efforts that the manager expends on protecting the resources under this information pattern the principal aims to minimize the systemic cyber risks by designing a dynamic contract that specifies the compensation flows and the anticipated efforts of the manager by taking into account his',\n",
       " 'incentives and rational behaviors we formulate a bilevel mechanism design problem for dynamic contract design within the framework of a class of stochastic differential games we show that the principal has rational controllability of the systemic risk by designing an incentive compatible estimator of the agents hidden efforts we characterize the optimal solution by reformulating the problem as a stochastic optimal control program which can be solved using dynamic programming we further investigate a',\n",
       " 'benchmark scenario with complete information and identify conditions that yield zero information rent and lead to a new certainty equivalence principle for principalagent problems finally case studies over networked systems are carried out to illustrate the theoretical results obtained',\n",
       " 'success of any it industry depends on the success rate of their projects which in turn depends on several factors such as cost time and availability of resources these factors formulate the risk areas which needs to be addressed in a proactive way the rudimentary objective of risk management is to circumvent the possibility of their occurrence by identifying the risks preparing the contingency plans and mitigation plans in order to reduce the consequences of the risks hence effective risk management becomes',\n",
       " 'one of the imperative challenges in any organization which if deemed in an apt way assures the continued sustainability of the organization in the highend competitive environment this paper provides visualization of risk assessment through a graphical model further the matrix representation of the risk assessment aids the project personnel to identify all the risks comprehend their frequency and probability of their occurrence in addition the graphical model enables one to analyze the impact of identified',\n",
       " 'risks and henceforth to assign their priorities this mode of representation of risk assessment factors helps the organization in accurate prediction of success rate of the project',\n",
       " 'management of systemic risk in financial markets is traditionally associated with setting higher capital requirements for market participants there are indications that while equity ratios have been increased massively since the financial crisis systemic risk levels might not have lowered but even increased it has been shown that systemic risk is to a large extent related to the underlying network topology of financial exposures a natural question arising is how much systemic risk can be eliminated by',\n",
       " 'optimally rearranging these networks and without increasing capital requirements overlapping portfolios with minimized systemic risk which provide the same market functionality as empirical ones have been studied by pichler here we propose a similar method for direct exposure networks and apply it to crosssectional interbank loan networks consisting of quarterly observations of the austrian interbank market we show that the suggested framework rearranges the network topology such that systemic risk is',\n",
       " 'reduced by a factor of approximately and leaves the relevant economic features of the optimized network and its agents unchanged the presented optimization procedure is not intended to actually reconfigure interbank markets but to demonstrate the huge potential for systemic risk management through rearranging exposure networks in contrast to increasing capital requirements that were shown to have only marginal effects on systemic risk poledna ways to actually incentivize a selforganized formation toward',\n",
       " 'optimal network configurations were introduced in thurner and poledna for regulatory policies concerning financial market stability the knowledge of minimal systemic risk for a given economic environment can serve as a benchmark for monitoring actual systemic risk in markets',\n",
       " 'wildfire is one of the biggest disasters that frequently occurs on the west coast of the united states many efforts have been made to understand the causes of the increases in wildfire intensity and frequency in recent years in this work we propose static and dynamic prediction models to analyze and assess the areas with high wildfire risks in california by utilizing a multitude of environmental data including population density normalized difference vegetation index ndvi palmer drought severity index pdsi',\n",
       " 'tree mortality area tree mortality number and altitude moreover we focus on a better understanding of the impacts of different factors so as to inform preventive actions to validate our models and findings we divide the land of california into grids of degrees times degrees in latitude and longitude and compute the risk of each grid based on spatial and temporal conditions by performing counterfactual analysis we uncover the effects of several possible methods on reducing the number of high risk wildfires',\n",
       " 'taken together our study has the potential to estimate monitor and reduce the risks of wildfires across diverse areas provided that such environment data is available',\n",
       " 'worstcase risk measures refer to the calculation of the largest value for risk measures when only partial information of the underlying distribution is available for the popular risk measures such as valueatrisk var and conditional valueatrisk cvar it is now known that their worstcase counterparts can be evaluated in closed form when only the first two moments are known for the underlying distribution these results are remarkable since they not only simplify the use of worstcase risk measures but also',\n",
       " 'provide great insight into the connection between the worstcase risk measures and existing risk measures we show in this paper that somewhat surprisingly similar closedform solutions also exist for the general class of law invariant coherent risk measures which consists of spectral risk measures as special cases that are arguably the most important extensions of cvar we shed light on the onetoone correspondence between a worstcase law invariant risk measure and a worstcase cvar and a worstcase var which',\n",
       " 'enables one to carry over the development of worstcase var in the context of portfolio optimization to the worstcase law invariant risk measures immediately',\n",
       " 'reliable calculations of financial risk require that the fattailed nature of prices changes is included in risk measures to this end a nongaussian approach to financial risk management is presented modeling the powerlaw tails of the returns distribution in terms of a studentt distribution nongaussian closedform solutions for valueatrisk and expected shortfall are obtained and standard formulae known in the literature under the normality assumption are recovered as a special case the implications of the',\n",
       " 'approach for risk management are demonstrated through an empirical analysis of financial time series from the italian stock market and in comparison with the results of the most widely used procedures of quantitative finance particular attention is paid to quantify the size of the errors affecting the market risk measures obtained according to different methodologies by employing a bootstrap technique',\n",
       " 'we show that any objective risk measurement algorithm mandated by central banks for regulated financial entities will result in more risk being taken on by those financial entities than would otherwise be the case furthermore the risks taken on by the regulated financial entities are far more systemically concentrated than they would have been otherwise making the entire financial system more fragile this result leaves three directions for the future of financial regulation continue regulating by enforcing',\n",
       " 'risk measurement algorithms at the cost of occasional severe crises regulate more severely and subjectively by fully nationalizing all financial entities or abolish all central banking regulations including deposit insurance to let risk be determined by the entities themselves and ultimately by their depositors through voluntary market transactions rather than by the taxpayers through enforced government participation',\n",
       " 'in this paper we attempt to introduce an econophysics approach to evaluate some aspects of the risks in financial markets for this purpose the thermodynamical methods and statistical physics results about entropy and equilibrium states in the physical systems are used some considerations on economic value and financial information are made finally on this basis a new index for the financial risk estimation of the stockexchange market transactions named macrostate parameter was introduced and discussed',\n",
       " 'keywords econophysics stockexchange markets financial risk informational fascicle entropy macrostate parameter',\n",
       " 'analytical free of time consuming monte carlo simulations framework for credit portfolio systematic risk metrics calculations is presented techniques are described that allow calculation of portfoliolevel systematic risk measures standard deviation var and expected shortfall as well as allocation of risk down to individual transactions the underlying model is the industry standard multifactor mertontype model with arbitrary valuation function at horizon in contrast to the simplistic defaultonly case high',\n",
       " 'accuracy of the proposed analytical technique is demonstrated by benchmarking against monte carlo simulations',\n",
       " 'this paper discusses the financial risks faced by the uk pension protection fund ppf and what if anything it can do about them it draws lessons from the regulatory regimes under which other financial institutions such as banks and insurance companies operate and asks why pension funds are treated differently it also reviews the experience with other governmentsponsored insurance schemes such as the us pension benefit guaranty corporation upon which the ppf is modelled we conclude that the ppf will live',\n",
       " 'under the permanent risk of insolvency as a consequence of the moral hazard adverse selection and especially systemic risks that it faces',\n",
       " 'we extend the classical risk minimization model with scalar risk measures to the general case of setvalued risk measures the problem we obtain is a setvalued optimization model and we propose a goal programmingbased approach with satisfaction function to obtain a solution which represents the best compromise between goals and the achievement levels numerical examples are provided to illustrate how the method works in practical situations',\n",
       " 'using elements from the theory of ergodic backward stochastic differential equations bsde we study the behavior of forward entropic risk measures we provide their general representation results via both bsde and convex duality and examine their behavior for risk positions of long maturities we show that forward entropic risk measures converge to some constant exponentially fast we also compare them with their classical counterparts and derive a parity result',\n",
       " 'we examine the efficiency of the asymmetric power arch aparch model in the case where the residuals follow the standardized pearson type iv distribution the model is tested with a variety of loss functions and the efficiency is examined via application of several statistical tests and risk measures the results indicate that the aparch model with the standardized pearson type iv distribution is accurate within the general financial risk modeling perspective providing the financial analyst with an additional',\n",
       " 'skewed distribution for incorporation in the risk management tools',\n",
       " 'in the present work the optimal portfolio minimizing the investment risk with cost is discussed analytically where this objective function is constructed in terms of two negative aspects of investment the risk and cost we note the mathematical similarity between the hamiltonian in the meanvariance model and the hamiltonians in the hopfield model and the sherringtonkirkpatrick model and show that we can analyze this portfolio optimization problem by using replica analysis and derive the minimal investment',\n",
       " 'risk with cost and the investment concentration of the optimal portfolio furthermore we validate our proposed method through numerical simulations',\n",
       " 'we introduce simple cost and risk proxy metrics that can be attached to treasury issuance strategy to complement analysis of the resulting portfolio weightedaverage maturity wam these metrics are based on mapping issuance fractions to their longterm asymptotic portfolio implications for cost and risk under mechanical debtrolling dynamics the resulting mapping enables one to visualize tradeoffs involved in contemplated issuance reallocation and identify an efficient frontier and optimal tenor historical',\n",
       " 'treasury issuance strategy is analyzed empirically using these cost and risk metrics to illustrate how changes in issuance needs and strategy have translated into structural shifts in the cost and risk stance of treasury issuance',\n",
       " 'portfolio selection is the central task for assets management but it turns out to be very challenging methods based on pattern matching particularly the cornk algorithm have achieved promising performance on several stock markets a key shortage of the existing pattern matching methods however is that the risk is largely ignored when optimizing portfolios which may lead to unreliable profits particularly in volatile markets we present a riskaversion cornk algorithm racornk that penalizes risk when searching',\n",
       " 'for optimal portfolios experiments on four datasets djia msci sp n hsi demonstrate that the new algorithm can deliver notable and reliable improvements in terms of return sharp ratio and maximum drawdown especially on volatile markets',\n",
       " 'we propose some machinelearningbased algorithms to solve hedging problems in incomplete markets sources of incompleteness cover illiquidity untradable risk factors discrete hedging dates and transaction costs the proposed algorithms resulting strategies are compared to classical stochastic control techniques on several payoffs using a variance criterion one of the proposed algorithm is flexible enough to be used with several existing risk criteria we furthermore propose a new momentbased risk criteria',\n",
       " 'the pareto model is very popular in risk management since simple analytical formulas can be derived for financial downside risk measures valueatrisk expected shortfall or reinsurance premiums and related quantities large claim index return period nevertheless in practice distributions are strictly pareto only in the tails above possible very large threshold therefore it could be interesting to take into account second order behavior to provide a better fit in this article we present how to go from a strict',\n",
       " 'pareto model to paretotype distributions we discuss inference and derive formulas for various measures and indices and finally provide applications on insurance losses and financial risks',\n",
       " 'we study general classes of parametric measures of variability with applications in risk management particular focus is put on variability measures induced by three classes of popular risk measures the valueatrisk the expected shortfall and the expectiles properties of these variability measures are explored in detail and a characterization result is obtained via the mixture of interes differences convergence properties and asymptotic normality of their empirical estimators are established we provide an',\n",
       " 'illustration of the three classes of variability measures applied to financial data and analyze their relative advantages',\n",
       " 'forest management relies on the evaluation of silviculture practices the increase in natural risk due to climate change makes it necessary to consider evaluation criteria that take natural risk into account risk integration in existing software requires advanced programming skillswe propose a userfriendly software to simulate evenaged and monospecific forest at the stand level in order to evaluate and optimize forest management the software gives the possibility to run management scenarii with or without',\n",
       " 'considering the impact of natural risk the control variables are the dates and rates of thinning and the cutting agethe risk model is based on a poisson processus the faustmann approach including tree damage risk is used to evaluate future benefits economic or ecosystem services it relies on the calculation of expected values for which a dedicated mathematical development has been done the optimized criteria used to evaluate the various scenarii are the faustmann value and the averaged yield valuewe',\n",
       " 'illustrate the approach and the software on two case studies economic optimization of a beech stand and carbon sequestration optimization of a pine standsoftware interface makes it easy for users to write their own growthtree damageeconomic models without advanced programming skills the possibility to run management scenarii withwithout considering the impact of natural risk may contribute improving silviculture guidelines and adapting them to climate change we propose future lines of research and',\n",
       " 'improvement',\n",
       " 'this article is part of a comprehensive research project on liquidity risk in asset management which can be divided into three dimensions the first dimension covers liability liquidity risk or funding liquidity modeling the second dimension focuses on asset liquidity risk or market liquidity modeling and the third dimension considers assetliability liquidity risk management or assetliability matching the purpose of this research is to propose a methodological and practical framework in order to perform',\n",
       " 'liquidity stress testing programs which comply with regulatory guidelines esma and are useful for fund managers the review of the academic literature and professional research studies shows that there is a lack of standardized and analytical models the aim of this research project is then to fill the gap with the goal to develop mathematical and statistical approaches and provide appropriate answers in this first part that focuses on liability liquidity risk modeling we propose several statistical models',\n",
       " 'for estimating redemption shocks the historical approach must be complemented by an analytical approach based on zeroinflated models if we want to understand the true parameters that influence the redemption shocks moreover we must also distinguish aggregate population models and individualbased models if we want to develop behavioral approaches once these different statistical models are calibrated the second big issue is the risk measure to assess normal and stressed redemption shocks finally the last',\n",
       " 'issue is to develop a factor model that can translate stress scenarios on market risk factors into stress scenarios on fund liabilities',\n",
       " 'we describe a general framework for measuring risks where the risk measure takes values in an abstract cone it is shown that this approach naturally includes the classical risk measures and setvalued risk measures and yields a natural definition of vectorvalued risk measures several main constructions of risk measures are described in this abstract axiomatic framework it is shown that the concept of depthtrimmed or central regions from the multivariate statistics is closely related to the definition of risk',\n",
       " 'measures in particular the halfspace trimming corresponds to the valueatrisk while the zonoid trimming yields the expected shortfall in the abstract framework it is shown how to establish a bothways correspondence between risk measures and depthtrimmed regions it is also demonstrated how the lattice structure of the space of risk values influences this relationship',\n",
       " 'expanding on techniques of concentration of measure we develop a quantitative framework for modeling liquidity risk using convex risk measures the fundamental objects of study are curves of the form rholambda xlambda ge where rho is a convex risk measure and x a random variable and we call such a curve a emphliquidity risk profile the shape of a liquidity risk profile is intimately linked with the tail behavior of the underlying x for some notable classes of risk measures namely shortfall risk measures we',\n",
       " 'exploit this link to systematically bound liquidity risk profiles from above by other real functions gamma deriving tractable necessary and sufficient conditions for emphconcentration inequalities of the form rholambda x le gammalambda for all lambda ge these concentration inequalities admit useful dual representations related to transport inequalities and this leads to efficient uniform bounds for liquidity risk profiles for large classes of x on the other hand some modest new mathematical results emerge',\n",
       " 'from this analysis including a new characterization of some classical transportentropy inequalities lastly the analysis is deepened by means of a surprising connection between time consistency properties of law invariant risk measures and the tensorization of concentration inequalities',\n",
       " 'we suggest use continuous numerical risk grades of r for a single risk or the unit cube in rn for n risks as the economic domain we consider risk ratings of economic agents as their coordinates in the economic domain economic activity of agents economic or other factors change agents risk ratings and that cause motion of agents in the economic domain aggregations of variables and transactions of individual agents in small volume of economic domain establish the continuous economic media approximation that',\n",
       " 'describes collective variables transactions and their flows in the economic domain as functions of risk coordinates any economic variable atx defines mean risk xat as risk weighted by economic variable atx collective flows of economic variables in bounded economic domain fluctuate from secure to risky area and back these fluctuations of flows cause time oscillations of macroeconomic variables at and their mean risks xat in economic domain and are the origin of any business and credit cycles we derive',\n",
       " 'equations that describe evolution of collective variables transactions and their flows in the economic domain as illustration we present simple selfconsistent equations of supplydemand cycles that describe fluctuations of supply demand and their mean risks',\n",
       " 'street networks as one of the oldest infrastructures of transport in the world play a significant role in modernization sustainable development and human daily activities in both ancient and modern times although street networks have been well studied in a variety of engineering and scientific disciplines including for instance transport geography urban planning economics and even physics our understanding of street networks in terms of their structure and dynamics remains limited especially when dealing',\n",
       " 'with such realworld problems as traffic jams pollution and human evacuations for disaster management one goal of this special issue is to promote different ways of thinking about understanding street networks and of conducting spatial analysis',\n",
       " 'the importance of timely response to natural disasters and evacuating affected people to safe areas is paramount to save lives emergency services are often handicapped by the amount of rescue resources at their disposal we present a system that leverages the power of a social network forming new connections among people based on textitrealtime location and expands the rescue resources pool by adding private sector cars we also introduce a carsharing algorithm to identify safe routes in an emergency with the',\n",
       " 'aim of minimizing evacuation time maximizing pickup of people without cars and avoiding traffic congestion',\n",
       " 'fine population distribution both in space and in time is crucial for epidemic management disaster preventionurban planning and more human mobility data have a great potential for mapping population distribution at a high level of spatiotemporal resolution power law models are the most popular ones for mapping mobility data to population howeverthey fail to provide consistent estimations under different spatial and temporal resolutions ie they have to be recalibrated whenever the spatial or temporal',\n",
       " 'partitioning scheme changes we propose a bayesian model for dynamic population estimation using static census data and anonymized mobility data our model gives consistent population estimations under different spatial and temporal resolutions',\n",
       " 'in this paper we generalize the parametric deltavar methods from portfolios with elliptic distributed risk factors to portfolios with mixture of elliptically distributed ones we treat both the expected shortfall and the valueatrisk of such portfolios special attention is given to the particular case of the mixture of studentt distributions',\n",
       " 'we introduce a model in which a regulator employs mechanism design to embed her human capital beta signals in a firms capital structure in order to enhance the value of her post career change indexed executive stock option contract with the firm we prove that the agency cost of this revolving door behavior increases the firms financial leverage bankruptcy risk and affects estimation of firm value at risk var',\n",
       " 'the socalled risk diversification principle is analyzed showing that its convenience depends on individual characteristics of the risks involved and the dependence relationship among them se analiza el principio de diversificacion de riesgos y se demuestra que no siempre resulta mejor que no diversificar pues esto depende de caracteristicas individuales de los riesgos involucrados asi como de la relacion de dependencia entre los mismos',\n",
       " 'we present a method of hedging conditional value at risk of a position in stock using put options the result leads to a linear programming problem that can be solved to optimise risk hedging',\n",
       " 'this survey gives an introduction to monetary measures of risk as monotone and cash additive functions on spaces of univariate random variables primal and dual representation results as well as several examples are discussed principal ways to construct risk measures are given and extensions to more general situations indicated',\n",
       " 'risk assessment under different possible scenarios is a source of uncertainty that may lead to concerning financial losses we address this issue first by adapting a robust framework to the class of spectral risk measures second we propose a deviationbased approach to quantify uncertainty furthermore the theory is illustrated with a practical case study from nasdaq index',\n",
       " 'understanding the collective dynamics of crowd movements during stressful emergency situations is central to reducing the risk of deadly crowd disasters yet their systematic experimental study remains a challenging open problem due to ethical and methodological constraints in this paper we demonstrate the viability of shared d virtual environments as an experimental platform for conducting crowd experiments with real people in particular we show that crowds of real human subjects moving and interacting in',\n",
       " 'an immersive d virtual environment exhibit typical patterns of real crowds as observed in reallife crowded situations these include the manifestation of social conventions and the emergence of selforganized patterns during egress scenarios highstress evacuation experiments conducted in this virtual environment reveal movements characterized by mass herding and dangerous overcrowding as they occur in crowd disasters we describe the behavioral mechanisms at play under such extreme conditions and identify',\n",
       " 'critical zones where overcrowding may occur furthermore we show that herding spontaneously emerges from a density effect without the need to assume an increase of the individual tendency to imitate peers our experiments reveal the promise of immersive virtual environments as an ethical costefficient yet accurate platform for exploring crowd behaviour in highrisk situations with real human subjects',\n",
       " 'we provide and perform a risk theoretic statistical analysis of a dataset that is percent larger than the previous best dataset on nuclear incidents and accidents comparing three measures of severity ines international nuclear event scale radiation released and damage dollar losses the annual rate of nuclear accidents with size above million us per plant decreased from the s until dropping significantly after chernobyl april the rate is now roughly stable at to ie around event per year across the current',\n",
       " 'fleet the distribution of damage values changed after three mile island tmi march where moderate damages were suppressed but the tail became very heavy being described by a pareto distribution with tail index further there is a runaway disaster regime associated with the dragonking phenomenon amplifying the risk of extreme damage in fact the damage of the largest event fukushima march is equal to percent of the total damage of all accidents in our database since in dollar losses we compute a chance that i a',\n",
       " 'fukushima event or larger occurs in the next years ii a chernobyl event or larger occurs in the next years and iii a tmi event or larger occurs in the next years finally we find that the ines scale is inconsistent to be consistent with damage the fukushima disaster would need to have an ines level of rather than the maximum of',\n",
       " 'the inability to see and quantify systemic financial risk comes at an immense social cost systemic risk in the financial system arises to a large extent as a consequence of the interconnectedness of its institutions which are linked through networks of different types of financial contracts such as credit derivatives foreign exchange and securities the interplay of the various exposure networks can be represented as layers in a financial multilayer network in this work we quantify the daily contributions to',\n",
       " 'systemic risk from four layers of the mexican banking system from we show that focusing on a single layer underestimates the total systemic risk by up to by assigning systemic risk levels to individual banks we study the systemic risk profile of the mexican banking system on all market layers this profile can be used to quantify systemic risk on a national level in terms of nationwide expected systemic losses we show that marketbased systemic risk indicators systematically underestimate expected systemic',\n",
       " 'losses we find that expected systemic losses are up to a factor four higher now than before the financial crisis of we find that systemic risk contributions of individual transactions can be up to a factor of thousand higher than the corresponding credit risk which creates huge risks for the public we find an intriguing nonlinear effect whereby the sum of systemic risk of all layers underestimates the total risk the method presented here is the first objective data driven quantification of systemic risk on',\n",
       " 'national scales that reveal its true levels',\n",
       " 'to the best of our knowledge the application of deep learning in the field of quantitative risk management is still a relatively recent phenomenon this article presents the key notions of deep asset liability management deepalm for a technological transformation in the management of assets and liabilities along a whole term structure the approach has a profound impact on a wide range of applications such as optimal decision making for treasurers optimal procurement of commodities or the optimisation of',\n",
       " 'hydroelectric power plants as a byproduct intriguing aspects of goalbased investing or asset liability management alm in abstract terms concerning urgent challenges of our society are expected alongside we illustrate the potential of the approach in a stylised case',\n",
       " 'the conventional wisdom of meanvariance mv portfolio theory asserts that the nature of the relationship between risk and diversification is a decreasing asymptotic function with the asymptote approximating the level of portfolio systematic risk or undiversifiable risk this literature assumes that investors hold an equallyweighted or a mv portfolio and quantify portfolio diversification using portfolio size however the equallyweighted portfolio and portfolio size are mv optimal if and only if asset returns',\n",
       " 'distribution is exchangeable or investors have no useful information about asset expected return and risk moreover the whole of literature absolutely all of it focuses only on risky assets ignoring the role of the risk free asset in the efficient diversification therefore it becomes interesting and important to answer this question how valid is this conventional wisdom when investors have full information about asset expected return and risk and asset returns distribution is not exchangeable in both the',\n",
       " 'case where the risk free rate is available or not unfortunately this question have never been addressed in the current literature this paper fills the gap',\n",
       " 'riskonly investment strategies have been growing in popularity as traditional in vestment strategies have fallen short of return targets over the last decade however riskbased investors should be aware of four things first theoretical considerations and empirical studies show that apparently dictinct riskbased investment strategies are manifestations of a single effect second turnover and associated transaction costs can be a substantial drag on return third capital diversification benefits may be reduced',\n",
       " 'fourth there is an apparent connection between performance and risk diversification to analyze risk diversification benefits in a consistent way we introduce the risk diversification index rdi which measures risk concentrations and complements the herfindahlherschman index hhi for capital concentrations',\n",
       " 'we implement momentum strategies using rewardrisk measures as ranking criteria based on classical tempered stable distribution performances and risk characteristics for the alternative portfolios are obtained in various asset classes and markets the rewardrisk momentum strategies with lower volatility levels outperform the traditional momentum strategy regardless of asset class and market additionally the alternative portfolios are not only less riskier in risk measures such as var cvar and maximum drawdown',\n",
       " 'but also characterized by thinner downside tails similar patterns in performance and risk profile are also found at the level of each ranking basket in the rewardrisk portfolios higher factorneutral returns achieved by the rewardrisk momentum strategies are statistically significant and large portions of the performances are not explained by the carhart fourfactor model',\n",
       " 'multiperiod measures of risk account for the path that the value of an investment portfolio takes in the context of probabilistic risk measures the focus has traditionally been on the magnitude of investment loss and not on the dimension associated with the passage of time in this paper the concept of temporal pathdependent risk measure is mathematically formalized to capture the risk associated with the temporal dimension of a stochastic process we discuss the properties of temporal measures of risk and',\n",
       " 'show that they can never be coherent we then study the temporal dimension of investment drawdown its duration which measures the length of excursions below a running maximum its properties in the context of risk measures are analyzed both theoretically and empirically in particular we show that duration captures serial correlation in the returns of two major asset classes we conclude by discussing the challenges of pathdependent temporal risk estimation in practice',\n",
       " 'we give a complete algorithm and source code for constructing general multifactor risk models for equities via any combination of style factors principal components betas andor industry factors for short horizons we employ the russiandoll risk model construction to obtain a nonsingular factor covariance matrix this generalizes the heterotic risk model construction to include arbitrary nonindustry risk factors as well as industry risk factors with generic weights the aim of sharing our proprietary knowhow',\n",
       " 'with the investment community is to encourage organic risk model building the presentation is intended to be essentially selfcontained and pedagogical so stop wasting money and complaining start building risk models and enjoy',\n",
       " 'equity risk premium is a central component of every risk and return model in finance and a key input to estimate costs of equity and capital in both corporate finance and valuation an article by damodaran examines three broad approaches for estimating the equity risk premium the first is survey based it consists in asking common investors or big players like pension fund managers what they require as a premium to invest in equity the second is to look at the premia earned historically by investing in stocks',\n",
       " 'as opposed to riskfree investments the third method tries to extrapolate a marketconsensus on equity risk premium implied equity risk premium by analysing equity prices on the market today after having introduced some basic concepts and models ill briefly explain the pluses and minuses of the first two methods and analyse more deeply the third in the end ill show the results of my estimation of erp on real data using variants of the implied erp third method',\n",
       " 'quantification of risk positions under model uncertainty is of crucial importance from both viewpoints of external regulation and internal management the concept of model uncertainty sometimes also referred to as model ambiguity although we know the family of models we cannot precisely decide which one to use given the set mathcalp the value of the risk measure rho varies in a range over the set of all possible models the largest value in such a range is referred to as a worstcase value and the',\n",
       " 'corresponding model is called a worst scenario valueatriskvar has become a very popular riskmeasurement tool since it was first proposed naturally wvarworstcase valueatrisk attracts the attention of many researchers although many literatures investigated wvar the implications for empirical data analysis remain rare in this paper we proposed a special model uncertainty market model to simply the mathcalp to a set contain finite number of probability distributions the model has the structure of the twolayer',\n",
       " 'mixed distribution model we used change point detection method to divide the returns series and then used em algorithm to estimate the parameters finally we calculated var wvarworstcase valueatrisk and bvarbestcase valueatrisk for four financial markets and then analyzed their different performance',\n",
       " 'expected shortfall es has been widely accepted as a risk measure that is conceptually superior to valueatrisk var at the same time however it has been criticised for issues relating to backtesting in particular es has been found not to be elicitable which means that backtesting for es is less straightforward than eg backtesting for var expectiles have been suggested as potentially better alternatives to both es and var in this paper we revisit commonly accepted desirable properties of risk measures like',\n",
       " 'coherence comonotonic additivity robustness and elicitability we check var es and expectiles with regard to whether or not they enjoy these properties with particular emphasis on expectiles we also consider their impact on capital allocation an important issue in risk management we find that despite the caveats that apply to the estimation and backtesting of es it can be considered a good risk measure as a consequence there is no sufficient evidence to justify an allinclusive replacement of es by expectiles',\n",
       " 'in applications for backtesting es we propose an empirical approach that consists in replacing es by a set of four quantiles which should allow to make use of backtesting methods for var keywords backtesting capital allocation coherence diversification elicitability expected shortfall expectile forecasts probability integral transform pit risk measure risk management robustness valueatrisk',\n",
       " 'this paper considers the textual plan guidelines proposed by peoples committee of ho chi minh city vietnam to manage earthquake and tsunami and try to represent it in a more formal way in order to provide means to simulate analyse and adapt it we first present a state of the art about coordination models for disaster management with a focus on process oriented approaches we give an overview of the different dimensions of the textual tsunami plan of ho chi minh city and then the graphical representation of',\n",
       " 'its process with bpmn business process model and notation we finally show how to exploit this process with workflow tools to simulate yawl tool and analyse it prom tool',\n",
       " 'potholes though seem inconsequential may cause accidents resulting in loss of human life in this paper we present an automated system to efficiently manage the potholes in a ward by deploying geotagging and image processing techniques that overcomes the drawbacks associated with the existing surveyoriented systems image processing is used for identification of target pothole regions in the d images using edge detection and morphological image processing operations a method is developed to accurately',\n",
       " 'estimate the dimensions of the potholes from their images analyze their area and depth estimate the quantity of filling material required and therefore enabling pothole attendance on a priority basis this will further enable the government official to have a fully automated system for effectively managing pothole related disasters',\n",
       " 'the purpose of this research article is to discover how the econophysics analysis can complement the econometrics models in application to the risk management in the central banks and financial institutions operating within the nonlinear dynamical financial system we consider the modern risk management models and show the appropriate techniques to calculate the various existing risks in the finances we make a few comments on the possible limitations in the models of statistical modeling of volatility such',\n",
       " 'as the autoregressive conditional heteroskedasticity garch model because of the nonlinearities appearance in the nonlinear dynamical financial systems we propose that the various types of nonlinearities which can originate in the financial and economical systems have to be taken to the detailed consideration during the cost of capital calculation in the finances and economics we propose the new theory of nonlinear dynamic volatilities and the new nonlinear dynamic chaos ndc volatility model for the',\n",
       " 'statistical modeling of financial volatility with the aim to determine the value at risk',\n",
       " 'a major source of risk in project management is inaccurate forecasts of project costs demand and other impacts the paper presents a promising new approach to mitigating such risk based on theories of decision making under uncertainty which won the nobel prize in economics first the paper documents inaccuracy and risk in project management second it explains inaccuracy in terms of optimism bias and strategic misrepresentation third the theoretical basis is presented for a promising new method called',\n",
       " 'reference class forecasting which achieves accuracy by basing forecasts on actual performance in a reference class of comparable projects and thereby bypassing both optimism bias and strategic misrepresentation fourth the paper presents the first instance of practical reference class forecasting which concerns cost forecasts for large transportation infrastructure projects finally potentials for and barriers to reference class forecasting are assessed',\n",
       " 'the gametheoretic risk management framework put forth in the precursor reports towards a theory of games with payoffs that are probabilitydistributions arxiv qfinec and algorithms to compute nashequilibria in games with distributions as payoffs arxiv v qfinec is herein concluded by discussing how to integrate the previously developed theory into risk management processes to this end we discuss how loss models primarily but not exclusively nonparametric can be constructed from data furthermore hints are',\n",
       " 'given on how a meaningful game theoretic model can be set up and how it can be used in various stages of the iso risk management process examples related to advanced persistent threats and social engineering are given we conclude by a discussion on the meaning and practical use of mixed nash equilibria equilibria for risk management',\n",
       " 'the basic financial purpose of an enterprise is maximization of its value trade credit management should also contribute to realization of this fundamental aim many of the current asset management models that are found in financial management literature assume book profit maximization as the basic financial purpose these book profitbased models could be lacking in what relates to another aim ie maximization of enterprise value the enterprise value maximization strategy is executed with a focus on risk and',\n",
       " 'uncertainty this article presents the consequences that can result from operating risk that is related to purchasers using payment postponement for goods andor services the present article offers a method that uses portfolio management theory to determine the level of accounts receivable in a firm an increase in the level of accounts receivables in a firm increases both net working capital and the costs of holding and managing accounts receivables both of these decrease the value of the firm but a liberal',\n",
       " 'policy in accounts receivable coupled with the portfolio management approach could increase the value efforts to assign ways to manage these risks were also undertaken among them special attention was paid to adapting assumptions from portfolio theory as well as gauging the potential effect on the firm value',\n",
       " 'we provide a new dynamic approach to scenario generation for the purposes of risk management in the banking industry we connect ideas from conventional techniques like historical and monte carlo simulation and we come up with a hybrid method that shares the advantages of standard procedures but eliminates several of their drawbacks instead of considering the static problem of constructing one or ten day ahead distributions for vectors of risk factors we embed the problem into a dynamic framework where any',\n",
       " 'time horizon can be consistently simulated additionally we use standard models from mathematical finance for each risk factor whence bridging the worlds of trading and risk management our approach is based on stochastic differential equations sdes like the hjmequation or the blackscholes equation governing the time evolution of risk factors on an empirical calibration method to the market for the chosen sdes and on an euler scheme or highorder schemes for the numerical evaluation of the respective sdes the',\n",
       " 'empirical calibration procedure presented in this paper can be seen as the sdecounterpart of the so called filtered historical simulation method the behavior of volatility stems in our case out of the assumptions on the underlying sdes furthermore we are able to easily incorporate middlesize and largesize events within our framework always making a precise distinction between the information obtained from the market and the one coming from the necessary apriori intuition of the risk manager results of one',\n",
       " 'concrete implementation are provided',\n",
       " 'we consider market players with tailriskseeking behaviour as exemplified by the sshaped utility introduced by kahneman and tversky we argue that risk measures such as value at risk var and expected shortfall es are ineffective in constraining such players we show that in many standard market models product design aimed at utility maximization is not constrained at all by var or es bounds the maximized utility corresponding to the optimal payoff is the same with or without es constraints by contrast we show',\n",
       " 'that in reasonable markets risk management constraints based on a second more conventional concave utility function can reduce the maximum sshaped utility that can be achieved by the investor even if the constraining utility function is only rather modestly concave it follows that product designs leading to unbounded sshaped utilities will lead to unbounded negative expected constraining utilities when measured with such conventional utility functions to prove these latter results we solve a general problem',\n",
       " 'of optimizing an investor expected utility under risk management constraints where both investor and risk manager have conventional concave utility functions but the investor has limited liability we illustrate our results throughout with the example of the blackscholes option market these results are particularly important given the historical role of var and that es was endorsed by the basel committee in',\n",
       " 'in this contribution we consider the overall risk given as the sum of random subrisks mathbfxj in the context of valueatrisk var based risk calculations if we assume that the undertaking knows the parametric distribution family subrisk mathbfxjmathbfxjthetaj but does not know the true parameter vectors thetaj the undertaking faces parameter uncertainty to assess the appropriateness of methods to model parameter uncertainty for risk capital calculation we consider a criterion introduced in the recent',\n",
       " 'literature according to this criterion we demonstrate that in general appropriateness of a risk capital model for each subrisk does not imply appropriateness of the model on the aggregate level of the overall risk for the case where the overall risk is given by the sum of normally distributed subrisks we prove a theoretical result leading to an appropriate integrated risk capital model taking parameter uncertainty into account based on the theorem we develop a method improving the approximation of the',\n",
       " 'required confidence level simultaneously for both on the level of each subrisk as well as for the overall risk',\n",
       " 'this paper discusses an alternative explanation for the empirical findings contradicting the positive relationship between risk variance and reward expected return we show that these contradicting results might be due to the false definition of riskperception which we correct by introducing expected downside risk edr the edr parameter similar to the expected shortfall or conditional valueatrisk measures the tail risk however fits and better explains the utility perception of investors our results indicate',\n",
       " 'that when using the edr as risk measure both the positive and negative relationship between expected return and risk can be derived under standard conditions eg expected utility theory and positive riskaversion therefore no alternative psychological explanation or additional boundary condition on utility theory is required to explain the phenomenon furthermore we show empirically that it is a more precise linear predictor of expected return than volatility both for individual assets and portfolios',\n",
       " 'under solvency ii the computation of capital requirements is based on value at risk vr vr is a quantilebased risk measure and neglects extreme risks in the tail vr belongs to the family of distortion risk measures a serious deficiency of vr is that firms can hide their total downside risk in corporate networks unless a consolidated solvency balance sheet is required for each economic scenario in this case they can largely reduce their total capital requirements via appropriate transfer agreements within a',\n",
       " 'network structure consisting of sufficiently many entities and thereby circumvent capital regulation we prove several versions of such a result for general distortion risk measures of vrtype explicitly construct suitable allocations of the network portfolio and finally demonstrate how these findings can be extended beyond distortion risk measures we also discuss why consolidation requirements cannot completely eliminate this problem capital regulation should thus be based on coherent or convex risk measures',\n",
       " 'like average value at risk or expectiles',\n",
       " 'the ongoing concern about systemic risk since the outburst of the global financial crisis has highlighted the need for risk measures at the level of sets of interconnected financial components such as portfolios institutions or members of clearing houses the two main issues in systemic risk measurement are the computation of an overall reserve level and its allocation to the different components according to their systemic relevance we develop here a pragmatic approach to systemic risk measurement and',\n",
       " 'allocation based on multivariate shortfall risk measures where acceptable allocations are first computed and then aggregated so as to minimize costs we analyze the sensitivity of the risk allocations to various factors and highlight its relevance as an indicator of systemic risk in particular we study the interplay between the loss function and the dependence structure of the components moreover we address the computational aspects of risk allocation finally we apply this methodology to the allocation of',\n",
       " 'the default fund of a ccp on real data',\n",
       " 'aggregate and systemic risk in complex systems are emergent phenomena depending on two properties the idiosyncratic risks of the elements and the topology of the network of interactions among them while a significant attention has been given to aggregate risk assessment and risk propagation once the above two properties are given less is known about how the risk is distributed in the network and its relations with the topology we study this problem by investigating a large proprietary dataset of payments',\n",
       " 'among m italian firms whose credit risk rating is known we document significant correlations between local topological properties of a node firm and its risk moreover we show the existence of an homophily of risk ie the tendency of firms with similar risk profile to be statistically more connected among themselves this effect is observed when considering both pairs of firms and communities or hierarchies identified in the network we leverage this knowledge to show the predictability of the missing rating of',\n",
       " 'a firm using only the network properties of the associated node',\n",
       " 'the cyber risk insurance market is at a nascent stage of its development even as the magnitude of cyber losses is significant and the rate of cyber risk events is increasing existing cyber risk insurance products as well as academic studies have been focusing on classifying cyber risk events and developing models of these events but little attention has been paid to proposing insurance risk transfer strategies that incentivize mitigation of cyber loss through adjusting the premium of the risk transfer',\n",
       " 'product to address this important gap we develop a bonusmalus model for cyber risk insurance specifically we propose a mathematical model of cyber risk insurance and cybersecurity provisioning supported with an efficient numerical algorithm based on dynamic programming through a numerical experiment we demonstrate how a properly designed cyber risk insurance contract with a bonusmalus system can resolve the issue of moral hazard and benefit the insurer',\n",
       " 'the kind of realized mission inflows the sensitivity to risk among other factors the risk results from decision about liquid assets investment level and liquid assets financing the higher the risk exposure the higher the level of liquid assets if the specific risk exposure is smaller the more aggressive could be the net liquid assets strategy the organization choosing between various solutions in liquid assets needs to decide what level of risk is acceptable for her owners or donors and or capital suppliers',\n",
       " 'the paper shows how in authors opinion decisions about liquid assets management strategy inflow the risk of the organizations and its economical results during realization of main mission comparison of theoretical model with empirical data for over silesian nonprofit organization results suggests that nonprofit organization managing teams choose more risky aggressive liquid assets solutions than forprofit firms',\n",
       " 'the paper proposes a new approach to model risk measurement based on the wasserstein distance between two probability measures it formulates the theoretical motivation resulting from the interpretation of fictitious adversary of robust risk management the proposed approach accounts for equivalent and nonequivalent probability measures and incorporates the economic reality of the fictitious adversary it provides practically feasible results that overcome the restriction of considering only models implying',\n",
       " 'probability measures equivalent to the reference model the wasserstein approach suits for various types of model risk problems ranging from the singleasset hedging risk problem to the multiasset allocation problem the robust capital market line accounting for the correlation risk is not achievable with other nonparametric approaches',\n",
       " 'the t copula is often used in risk management as it allows for modelling tail dependence between risks and it is simple to simulate and calibrate however the use of a standard t copula is often criticized due to its restriction of having a single parameter for the degrees of freedom dof that may limit its capability to model the tail dependence structure in a multivariate case to overcome this problem grouped t copula was proposed recently where risks are grouped a priori in such a way that each group has a',\n",
       " 'standard t copula with its specific dof parameter in this paper we propose the use of a grouped t copula where each group consists of one risk factor only so that a priori grouping is not required the copula characteristics in the bivariate case are studied we explain simulation and calibration procedures including a simulation study on finite sample properties of the maximum likelihood estimators and kendalls tau approximation this new copula can be significantly different from the standard t copula in',\n",
       " 'terms of risk measures such as tail dependence value at risk and expected shortfall keywords grouped t copula tail dependence risk management',\n",
       " 'working in a continuous time setting we extend to the general case of dynamic risk measures continuous from above the characterization of time consistency in terms of cocycle condition of the minimal penalty function we prove also the supermartingale property for general time consistent dynamic risk measures when the time consistent dynamic risk measure continuous from above is normalized and non degenerate we prove under a mild condition that the dynamic risk process of any financial instrument has a',\n",
       " 'cadlag modification this condition is always satisfied in case of continuity from below',\n",
       " 'we use a replica approach to deal with portfolio optimization problems a given risk measure is minimized using empirical estimates of asset values correlations we study the phase transition which happens when the time series is too short with respect to the size of the portfolio we also study the noise sensitivity of portfolio allocation when this transition is approached we consider explicitely the cases where the absolute deviation and the conditional valueatrisk are chosen as a risk measure we show how',\n",
       " 'the replica method can study a wide range of risk measures and deal with various types of time series correlations including realistic ones with volatility clustering',\n",
       " 'the new notion of maturityindependent risk measures is introduced and contrasted with the existing risk measurement concepts it is shown by means of two examples one set on a finite probability space and the other in a diffusion framework that surprisingly some of the widely utilized risk measures cannot be used to build maturityindependent counterparts we construct a large class of maturityindependent risk measures and give representative examples in both continuous and discretetime financial models',\n",
       " 'to quantify an operational risk capital charge under basel ii many banks adopt a loss distribution approach under this approach quantification of the frequency and severity distributions of operational risk involves the banks internal data expert opinions and relevant external data in this paper we suggest a new approach based on a bayesian inference method that allows for a combination of these three sources of information to estimate the parameters of the risk frequency and severity distributions',\n",
       " 'we study the risk assessment of uncertain cash flows in terms of dynamic convex risk measures for processes as introduced in cheridito delbaen and kupper these risk measures take into account not only the amounts but also the timing of a cash flow we discuss their robust representation in terms of suitably penalized probability measures on the optional sigmafield this yields an explicit analysis both of model and discounting ambiguity we focus on supermartingale criteria for different notions of time',\n",
       " 'consistency in particular we show how bubbles may appear in the dynamic penalization and how they cause a breakdown of asymptotic safety of the risk assessment procedure',\n",
       " 'spectral risk measures srms are risk measures that take account of user riskaversion but to date there has been little guidance on the choice of utility function underlying them this paper addresses this issue by examining alternative approaches based on exponential and power utility functions a number of problems are identified with both types of spectral risk measure the general lesson is that users of spectral risk measures must be careful to select utility functions that fit the features of the',\n",
       " 'particular problems they are dealing with and should be especially careful when using power srms',\n",
       " 'we discuss two distinct approaches for distorting risk measures of sums of dependent random variables which preserve the property of coherence the first based on distorted expectations operates on the survival function of the sum the second simultaneously applies the distortion on the survival function of the sum and the dependence structure of risks represented by copulas our goal is to propose risk measures that take into account the fluctuations of losses and possible correlations between risk components',\n",
       " 'we propose a generalization of the classical notion of the vrlambda that takes into account not only the probability of the losses but the balance between such probability and the amount of the loss this is obtained by defining a new class of law invariant risk measures based on an appropriate family of acceptance sets the vrlambda and other known law invariant risk measures turn out to be special cases of our proposal we further prove the dual representation of risk measures on mathcalp mathbbr',\n",
       " 'we demonstrate a limitation of discounted expected utility a standard approach for representing the preference to risk when future cost is discounted specifically we provide an example of the preference of a decision maker that appears to be rational but cannot be represented with any discounted expected utility a straightforward modification to discounted expected utility leads to inconsistent decision making over time we will show that an iterated risk measure can represent the preference that cannot be',\n",
       " 'represented by any discounted expected utility and that the decisions based on the iterated risk measure are consistent over time',\n",
       " 'our goal in this paper is to propose an alternative risk measure which takes into account the fluctuations of losses and possible correlations between random variables this new notion of risk measures that we call copula conditional tail expectation describes the expected amount of risk that can be experienced given that a potential bivariate risk exceeds a bivariate threshold value and provides an important measure for righttail risk an application to real financial data is given',\n",
       " 'we propose to interpret distribution model risk as sensitivity of expected loss to changes in the risk factor distribution and to measure the distribution model risk of a portfolio by the maximum expected loss over a set of plausible distributions defined in terms of some divergence from an estimated distribution the divergence may be relative entropy a bregman distance or an fdivergence we give formulas for the calculation of distribution model risk and explicitly determine the worst case distribution from',\n",
       " 'the set of plausible distributions we also give formulas for the evaluation of divergence preferences describing ambiguity averse decision makers',\n",
       " 'the aim of this paper is to introduce a method for computing the allocated solvency ii capital requirement scr of each risk which the company is exposed to taking in account for the diversification effect among different risks the method suggested is based on the euler principle we show that it has very suitable properties like coherence in the sense of denault and rorac compatibility and practical implications for the companies that use the standard formula further we show how this approach can be used to',\n",
       " 'evaluate the underwriting and reinsurance policies and to define a measure of the companys risk appetite based on the capital at risk return',\n",
       " 'stochastic domains often involve riskaverse decision makers while recent work has focused on how to model risk in markov decision processes using risk measures it has not addressed the problem of solving large riskaverse formulations in this paper we propose and analyze a new method for solving large riskaverse mdps with hybrid continuousdiscrete state spaces and continuous action spaces the proposed method iteratively improves a bound on the value function using a linearity structure of the mdp we',\n",
       " 'demonstrate the utility and properties of the method on a portfolio optimization problem',\n",
       " 'in this paper we introduce a new coherent cumulative risk measure on mathcalrlp the space of cadlag processes having laplace transform this new coherent risk measure turns out to be tractable enough within a class of models where the aggregate claims is driven by a spectrally positive levy process moreover we study the problem of capital allocation in an insurance context and we show that the capital allocation problem for this risk measure has a unique solution determined by the euler allocation method',\n",
       " 'some examples are provided',\n",
       " 'in this paper we consider the problem of optimal reinsurance design when the risk is measured by a distortion risk measure and the premium is given by a distortion risk premium first we show how the optimal reinsurance design for the ceding company the reinsurance company and the social planner can be formulated in the same way second by introducing the marginal indemnification functions we characterize the optimal reinsurance contracts we show that for an optimal policy the associated marginal',\n",
       " 'indemnification function only takes the values zero and one we will see how the roles of the market preferences and premiums and that of the total risk are separated',\n",
       " 'we propose a model for the credit and liquidity risks faced by clearing members of central counterparty clearing houses ccps this model aims to capture the features of gap risk feedback between clearing member default market volatility and margining requirements the different risks faced by various types of market participant and the changes in margining requirements a clearing member faces as the system evolves by considering the entire network of ccps and clearing members we investigate the distribution',\n",
       " 'of losses to default fund contributions and contingent liquidity requirements for each clearing member further we identify wrongway risks between defaults of clearing members and market turbulence',\n",
       " 'this article presents a new model for valuing a credit default swap cds contract that is affected by multiple credit risks of the buyer seller and reference entity we show that default dependency has a significant impact on asset pricing in fact correlated default risk is one of the most pervasive threats in financial markets we also show that a fully collateralized cds is not equivalent to a riskfree one in other words full collateralization cannot eliminate counterparty risk completely in the cds market',\n",
       " 'the paper analyzes risk assessment for cash flows in continuous time using the notion of convex risk measures for processes by combining a decomposition result for optional measures and a dual representation of a convex risk measure for bounded cd processes we show that this framework provides a systematic approach to the both issues of model ambiguity and uncertainty about the time value of money we also establish a link between risk measures for processes and bsdes',\n",
       " 'we study dynamic hedging of counterparty risk for a portfolio of credit derivatives our empirically driven credit model consists of interacting default intensities which ramp up and then decay after the occurrence of credit events using the galtchoukkunitawatanabe decomposition of the counterparty risk price payment stream we recover a closedform representation for the risk minimizing strategy in terms of classical solutions to nonlinear recursive systems of cauchy problems we discuss applications of our',\n",
       " 'framework to the most prominent class of credit derivatives including credit swap and risky bond portfolios as well as firsttodefault claims',\n",
       " 'this article presents a generic model for pricing financial derivatives subject to counterparty credit risk both unilateral and bilateral types of credit risks are considered our study shows that credit risk should be modeled as american style options in most cases which require a backward induction valuation to correct a common mistake in the literature we emphasize that the market value of a defaultable derivative is actually a risky value rather than a riskfree value credit value adjustment cva is also',\n",
       " 'elaborated a practical framework is developed for pricing defaultable derivatives and calculating their cvas at a portfolio level',\n",
       " 'this seemed impossible to use a theoretically adequate but too sophisticated risk measure called nonruin capital whence its widespread including regulatory documents replacement with an inadequate but simple risk measure called valueatrisk conflicting with the idea by albert einstein that everything should be made as simple as possible but not simpler this led to fallacious and even deceitful but generally accepted standards and recommendations arguing from the standpoint of mathematical theory of risk we',\n",
       " 'aim to break this impasse',\n",
       " 'this paper examines the pricing of shortterm and longterm dynamic network risk in the crosssection of stock returns stocks with high sensitivities to dynamic network risk earn lower returns we rationalize our finding with economic theory that allows the stochastic discount factor to load on network risk through the precautionary savings channel a onestandard deviation increase in longterm shortterm network risk loadings associate with a drop in annualized expected returns',\n",
       " 'having a perfect model to compute the optimal policy is often infeasible in reinforcement learning it is important in highstakes domains to quantify and manage risk induced by model uncertainties entropic risk measure is an exponential utilitybased convex risk measure that satisfies many reasonable properties in this paper we propose an entropic risk constrained policy gradient and actorcritic algorithms that are riskaverse to the model uncertainty we demonstrate the usefulness of our algorithms on several',\n",
       " 'problem domains',\n",
       " 'we consider computation of market values of bonus payments in multistate withprofit life insurance the bonus scheme consists of additional benefits bought according to a dividend strategy that depends on the past realization of financial risk the current individual insurance risk the number of additional benefits currently held and socalled portfoliowide means describing the shape of the insurance business we formulate numerical procedures that efficiently combine simulation of financial risk with more',\n",
       " 'analytical methods for the outstanding insurance risk special attention is given to the case where the number of additional benefits bought only depends on the financial risk',\n",
       " 'we provide a framework for detecting relevant insurance companies in a systemic risk perspective among the alternative methodologies for measuring systemic risk we propose a complex network approach where insurers are linked to form a global interconnected system we model the reciprocal influence between insurers calibrating edge weights on the basis of specific risk measures therefore we provide a suitable network indicator the weighted effective resistance centrality able to catch which is the effect of a',\n",
       " 'specific vertex on the network robustness by means of this indicator we assess the prominence of a company in spreading and receiving risk from the others',\n",
       " 'the basic financial purpose of corporation is creation of its value liquidity management should also contribute to realization of this fundamental aim many of the current asset management models that are found in financial management literature assume book profit maximization as the basic financial purpose these book profit based models could be lacking in what relates to another aim like maximization of enterprise value the corporate value creation strategy is executed with a focus on risk and uncertainty',\n",
       " 'firms hold cash for a variety of reasons generally cash balances held in a firm can be called considered precautionary speculative transactional and intentional the first are the result of management anxieties managers fear the negative part of the risk and hold cash to hedge against it second cash balances are held to use chances that are created by the positive part of the risk equation next cash balances are the result of the operating needs of the firm in this article we analyze the relation between',\n",
       " 'these types of cash balances and risk this article presents the discussion about relations between firm net working investment policy and as result operating cash balances and firm value this article also contains propositions for marking levels of precautionary cash balances and speculative cash balances application of these propositions should help managers to make better decisions to maximize the value of a firm',\n",
       " 'the theory of convex risk functions has now been well established as the basis for identifying the families of risk functions that should be used in risk averse optimization problems despite its theoretical appeal the implementation of a convex risk function remains difficult as there is little guidance regarding how a convex risk function should be chosen so that it also well represents ones own risk preferences in this paper we address this issue through the lens of inverse optimization specifically given',\n",
       " 'solution data from some forward riskaverse optimization problems we develop an inverse optimization framework that generates a risk function that renders the solutions optimal for the forward problems the framework incorporates the wellknown properties of convex risk functions namely monotonicity convexity translation invariance and law invariance as the general information about candidate risk functions and also the feedbacks from individuals which include an initial estimate of the risk function and',\n",
       " 'pairwise comparisons among random losses as the more specific information our framework is particularly novel in that unlike classical inverse optimization no parametric assumption is made about the risk function ie it is nonparametric we show how the resulting inverse optimization problems can be reformulated as convex programs and are polynomially solvable if the corresponding forward problems are polynomially solvable we illustrate the imputed risk functions in a portfolio selection problem and',\n",
       " 'demonstrate their practical value using reallife data',\n",
       " 'this paper studies the problem of spectrum shortage in an unmanned aerial vehicle uav network during critical missions such as wildfire monitoring search and rescue and disaster monitoring such applications involve a high demand for highthroughput data transmissions such as realtime video image and voice streaming where the assigned spectrum to the uav network may not be adequate to provide the desired quality of service qos in these scenarios the aerial network can borrow an additional spectrum from the',\n",
       " 'available terrestrial networks in the trade of a relaying service for them we propose a spectrum sharing model in which the uavs are grouped into two classes of relaying uavs that service the spectrum owner and the sensing uavs that perform the disaster relief mission using the obtained spectrum the operation of the uav network is managed by a hierarchical mechanism in which a central controller assigns the tasks of the uavs based on their resources and determine their operation region based on the level of',\n",
       " 'priority of impacted areas and then the uavs autonomously finetune their position using a modelfree reinforcement learning algorithm to maximize the individual throughput and prolong their lifetime we analyze the performance and the convergence for the proposed method analytically and with extensive simulations in different scenarios',\n",
       " 'a risk of small definedbenefit pension schemes is that there are too few members to eliminate idiosyncratic mortality risk that is there are too few members to effectively pool mortality risk this means that when there are few members in the scheme there is an increased risk of the liability value deviating significantly from the expected liability value as compared to a large scheme we quantify this risk through examining the coefficient of variation of a schemes liability value relative to its expected',\n",
       " 'value we examine how the coefficient of variation varies with the number of members and find that even with a few hundred members in the scheme idiosyncratic mortality risk may still be significant using a stochastic mortality model reduces the idiosyncratic mortality risk but at the cost of increasing the overall mortality risk in the scheme next we quantify the amount of the mortality risk concentrated in the executive section of the scheme where the executives receive a benefit that is higher than the',\n",
       " 'nonexecutive benefit we use the euler capital allocation principle to allocate the total standard deviation of the liability value between the executive and nonexecutive sections we find that the proportion of the standard deviation allocated to the executive section is higher than is suggested by an allocation based on the members benefit amounts while the results are sensitive to the choice of mortality model they do suggest that the mortality risk of the scheme should be monitored and managed within the',\n",
       " 'sections of a scheme and not only on a schemewide basis',\n",
       " 'wireless networks are most appealing in terms of deployment over a wide range of applications the key areas are disaster management industrial unit automation and battlefield surveillance the paper presents a study over interoperability of manet mobile adhoc network protocols ie dsdv olsr zrp aodv over wsn wireless sensor network the review here covers all the prevailing protocol solutions for wsn and deployment of manet protocols over them the need of moving to manet protocols lie in situation when we talk',\n",
       " 'about mobile sensory nodes which are a compulsion when we talk about the above mentioned three areas however the deployment may not be limited to these only',\n",
       " 'unmanned aerial vehicles uavs also known as drones are proliferating applications such as surveillance disaster management and drone racing place high requirements on the communication with the drones in terms of throughput reliability and latency the existing wireless technologies notably wifi that are currently used for drone connectivity are limited to short ranges and lowmobility situations new scalable technology is needed to meet future demands on long connectivity ranges support for fastmoving drones',\n",
       " 'and the possibility to simultaneously communicate with entire swarms of drones massive multipleinput and multipleoutput mimo the main technology component of emerging g standards has the potential to meet these requirements',\n",
       " 'predicting unseen weather phenomena is an important issue for disaster management in this paper we suggest a model for a convolutional sequencetosequence autoencoder for predicting undiscovered weather situations from previous satellite images we also propose a symmetric skip connection between encoder and decoder modules to produce more comprehensive image predictions to examine our model performance we conducted experiments for each suggested model to predict future satellite images from historical',\n",
       " 'satellite images a specific combination of skip connection and sequencetosequence autoencoder was able to generate closest prediction from the ground truth image',\n",
       " 'people involved in mass emergencies increasingly publish informationrich contents in online social networks osns thus acting as a distributed and resilient network of human sensors in this work we present hermes a system designed to enrich the information spontaneously disclosed by osn users in the aftermath of disasters hermes leverages a mixed data collection strategy called hybrid crowdsensing and stateoftheart ai techniques evaluated in realworld emergencies hermes proved to increase i the amount of the',\n",
       " 'available damage information ii the density up to x and the variety up to x of the retrieved geographic information iii the geographic coverage up to and granularity',\n",
       " 'identifying regions that have high likelihood for wildfires is a key component of land and forestry management and disaster preparedness we create a data set by aggregating nearly a decade of remotesensing data and historical fire records to predict wildfires this prediction problem is framed as three machine learning tasks results are compared and analyzed for four different deep learning models to estimate wildfire likelihood the results demonstrate that deep learning models can successfully identify',\n",
       " 'areas of high fire likelihood using aggregated data about vegetation weather and topography with an auc of',\n",
       " 'the current world challenges include issues such as infectious disease pandemics environmental health risks food safety and crime prevention through this article a special emphasis is given to one of the main challenges in the healthcare sector during the covid pandemic the cyber risk since the beginning of the covid pandemic the world health organization has detected a dramatic increase in the number of cyberattacks for instance in italy the covid emergency has heavily affected cybersecurity from january',\n",
       " 'to april the total of attacks accidents and violations of privacy to the detriment of companies and individuals has doubled using a systematic and rigorous approach this paper aims to analyze the literature on the cyber risk in the healthcare sector to understand the real knowledge on this topic the findings highlight the poor attention of the scientific community on this topic except in the united states the literature lacks research contributions to support cyber risk management in subject areas such as',\n",
       " 'business management and accounting social science and mathematics this research outlines the need to empirically investigate the cyber risk giving a practical solution to health facilities keywords cyber risk cyberattack cybersecurity computer security covid coronavirusinformation technology risk risk management risk assessment health facilities healthcare sectorsystematic literature review insurance',\n",
       " 'we construct new multivariate copulas on the basis of a generalized infinite partitionofunity approach this approach allows in contrast to finite partitionofunity copulas for taildependence as well as for asymmetry a possibility of fitting such copulas to real data from quantitative risk management is also pointed out',\n",
       " 'we present a constructive and selfcontained approach to data driven general partitionofunity copulas that were recently introduced in the literature in particular we consider bernstein negative binomial and poisson copulas and present a solution to the problem of fitting such copulas to highly asymmetric data',\n",
       " 'in this article we consider a game theoretic approach to the risksensitive benchmarked asset management problem rsbam of davis and lleo citedl in particular we consider a stochastic differential game between two players namely the investor who has a power utility while the second player represents the market which tries to minimize the expected payoff of the investor the market does this by modulating a stochastic benchmark that the investor needs to outperform we obtain an explicit expression for the',\n",
       " 'optimal pair of strategies as for both the players',\n",
       " 'in this work we will develop a new approach to solve the non repayment problem in microfinance due to the problem of asymmetric information this approach is based on modeling and simulation of ordinary differential systems where time remains a primordial component they thus enable microfinance institutions to manage their risk portfolios by a prediction of numbers of solvent and insolvent borrowers ever a period in order to define or redefine its development strategy investment and management in an area',\n",
       " 'where the population is often poor and in need a mechanism of financial inclusion',\n",
       " 'the possibility that experiments at highenergy accelerators could create new forms of matter that would ultimately destroy the earth has been considered several times in the past quarter century one consequence of the earliest of these disaster scenarios was that the authors of a article in physics today who reviewed the experiments that had been carried out at the bevalac at lawrence berkeley laboratory were placed on the fbis unabomber watch list later concerns that experiments at the relativistic heavy',\n",
       " 'ion collider at brookhaven national laboratory might create mini black holes or nuggets of stable strange quark matter resulted in a flurry of articles in the popular press i discuss this history as well as richard a posners provocative analysis and recommendations on how to deal with such scientific risks i conclude that better communication between scientists and nonscientists would serve to assuage unreasonable fears and focus attention on truly serious potential threats to humankind',\n",
       " 'maxstable random fields are very appropriate for the statistical modelling of spatial extremes hence integrals of functions of maxstable random fields over a given region can play a key role in the assessment of the risk of natural disasters meaning that it is relevant to improve our understanding of their probabilistic behaviour for this purpose in this paper we propose a general central limit theorem for functions of stationary maxstable random fields on mathbbrd then we show that appropriate functions of',\n",
       " 'the brownresnick random field with a power variogram and of the smith random field satisfy the central limit theorem another strong motivation for our work lies in the fact that central limit theorems for random fields on mathbbrd have been barely considered in the literature as an application we briefly show the usefulness of our results in a risk assessment context',\n",
       " 'humansupervision in multiagent teams is a critical requirement to ensure that the decisionmakers risk preferences are utilized to assign tasks to robots in stressful complex missions that pose risk to human health and life such as humanitarianassistance and disasterrelief missions human mistakes or delays in tasking robots can adversely affect the mission to assist human decision making in such missions we present an alertgeneration framework capable of detecting various modes of potential failure or',\n",
       " 'performance degradation we demonstrate that our framework based on state machine simulation and formal methods offers probabilistic modeling to estimate the likelihood of unfavorable events we introduce smart simulation that offers a computationallyefficient way of detecting lowprobability situations compared to standard montecarlo simulations moreover for certain class of problems our inferencebased method can provide guarantees on correctly detecting task failures',\n",
       " 'in probabilistic risk management risk is characterized by two quantities the magnitude or severity of the adverse consequences that can potentially result from the given activity or action and by the likelihood of occurrence of the given adverse consequences but a risk seldom exists in isolation chain of consequences must be examined as the outcome of one risk can increase the likelihood of other risks systemic theory must complement classic prm indeed these chains are composed of many different elements',\n",
       " 'all of which may have a critical importance at many different levels furthermore when urban catastrophes are envisioned space and time constraints are key determinants of the workings and dynamics of these chains of catastrophes models must include a correct spatial topology of the studied risk finally literature insists on the importance small events can have on the risk on a greater scale urban risks management models belong to selforganized criticality theory we chose multiagent systems to incorporate',\n",
       " 'this property in our model the behavior of an agent can transform the dynamics of important groups of them',\n",
       " 'the management of operational risk in the banking industry has undergone significant changes over the last decade due to substantial changes in operational risk environment globalization deregulation the use of complex financial products and changes in information technology have resulted in exposure to new risks very different from market and credit risks in response basel committee for banking supervision has developed a regulatory framework referred to as basel ii that introduced operational risk',\n",
       " 'category and corresponding capital requirements over the past five years major banks in most parts of the world have received accreditation under the basel ii advanced measurement approach ama by adopting the loss distribution approach lda despite there being a number of unresolved methodological challenges in its implementation different approaches and methods are still under hot debate in this paper we review methods proposed in the literature for combining different data sources internal data external',\n",
       " 'data and scenario analysis which is one of the regulatory requirement for ama',\n",
       " 'heavy use of spreadsheets by organisations bears many potential risks such as errors ambiguity data loss duplication and fraud in this paper these risks are briefly outlined along with their available mitigation methods such as documentation centralisation auditing and user training however because of the large quantities of spreadsheets used in organisations applying these methods on all spreadsheets is impossible this fact is considered as a deficiency in these methods a gap which is addressed in this',\n",
       " 'paper in this paper a new software tool for managing spreadsheets and identifying the risk levels they include is proposed developed and tested as an addin for microsoft excel application risk calculator can automatically collect and record spreadsheet properties in an inventory database and assign risk scores based on their importance use and complexity consequently auditing processes can be targeted to high risk spreadsheets such a method saves time effort and money',\n",
       " 'we study issues of robustness in the context of quantitative risk management and optimization we develop a general methodology for determining whether a given risk measurement related optimization problem is robust which we call robustness against optimization the new notion is studied for various classes of risk measures and expected utility and loss functions motivated by practical issues from financial regulation special attention is given to the two most widely used risk measures in the industry',\n",
       " 'valueatrisk var and expected shortfall es we establish that for a class of general optimization problems var leads to nonrobust optimizers whereas convex risk measures generally lead to robust ones our results offer extra insight on the ongoing discussion about the comparative advantages of var and es in banking and insurance regulation our notion of robustness is conceptually different from the field of robust optimization to which some interesting links are derived',\n",
       " 'we show that coherent risk measures are ineffective in curbing the behaviour of investors with limited liability or excessive tailrisk seeking behaviour if the market admits statistical arbitrage opportunities which we term rhoarbitrage for a risk measure rho we show how to determine analytically whether such rhoarbitrage portfolios exist in complete markets and in the markowitz model we also consider realistic numerical examples of incomplete markets and determine whether expected shortfall constraints are',\n",
       " 'ineffective in these markets we find that the answer depends heavily upon the probability model selected by the risk manager but that it is certainly possible for expected shortfall constraints to be ineffective in realistic markets since value at risk constraints are weaker than expected shortfall constraints our results can be applied to value at risk by contrast we show that reasonable expected utility constraints are effective in any arbitragefree market',\n",
       " 'measurement and management of credit concentration risk is critical for banks and relevant for microprudential requirements while several methods exist for measuring credit concentration risk within institutions the systemic effect of different institutions exposures to the same counterparties has been less explored so far in this paper we propose a measure of the systemic credit concentration risk that arises because of common exposures between different institutions within a financial system this approach',\n",
       " 'is based on a network model that describes the effect of overlapping portfolios this network metric is applied to synthetic and real world data to illustrate that the effect of common exposures is not fully reflected in single portfolio concentration measures it also allows to quantify several aspects of the interplay between interconnectedness and credit risk using this network measure we formulate an analytical approximation for the additional capital requirement corresponding to the systemic risk arising',\n",
       " 'from credit concentration interconnectedness our methodology also avoids double counting between the granularity adjustment and the common exposure adjustment although approximated this common exposure adjustment is able to capture with only two parameters an aspect of systemic risk that can extend single portfolios view to a systemwide one',\n",
       " 'we review the recently introduced concept of variety of a financial portfolio and we sketch its importance for risk control purposes the empirical behaviour of variety correlation exceedance correlation and asymmetry of the probability density function of daily returns is discussed the results obtained are compared with the ones of a onefactor model showing strengths and limitations of this model',\n",
       " 'recurring international financial crises have adverse socioeconomic effects and demand novel regulatory instruments or strategies for risk management and market stabilization however the complex web of market interactions often impedes rational decisions that would absolutely minimize the risk here we show that for any given expected return investors can overcome this complexity and globally minimize their financial risk in portfolio selection models which is mathematically equivalent to computing the',\n",
       " 'ground state of spin glass models in physics provided the margin requirement remains below a critical empirically measurable value for markets with centrally regulated margin requirements this result suggests a potentially stabilizing intervention strategy',\n",
       " 'we investigate optimal consumption problems for a blackscholes market under uniform restrictions on valueatrisk and expected shortfall for logarithmic utility functions we find the solutions in terms of a dynamic strategy in explicit form which can be compared and interpreted this paper continues our previous work where we solved similar problems for power utility functions',\n",
       " 'we discuss the use of saddlepoint methods in the analysis of portfolios with particular reference to credit portfolios the objective is to proceed from a model of the loss distribution given through probabilities correlations and the like to an analytical approximation of the distribution once this is done we show how to derive the socalled risk contributions which are the derivatives of risk measures such as a given quantile var or expected shortfall to the allocations in the underlying assets these show',\n",
       " 'informally where the risk is coming from and also indicate how to go about optimising the portfolio',\n",
       " 'by adopting the polynomial interpolation method we propose an approach to hedge against the interestrate risk of the defaultfree bonds by measuring the nonparallel movement of the yieldcurve such as the translation the rotation and the twist the empirical analysis shows that our hedging strategies are comparable to traditional durationconvexity strategy or even better when we have more suitable hedging instruments on hand the article shows that this strategy is flexible and robust to cope with the',\n",
       " 'interestrate risk and can help finetune a position as time changes',\n",
       " 'motivated by the aig bailout case in the financial crisis of we consider an insurer who wants to maximize the expected utility of the terminal wealth by selecting optimal investment and risk control strategies the insurers risk process is modelled by a jumpdiffusion process and is negatively correlated with the capital gains in the financial market we obtain explicit solution to optimal strategies for various utility functions',\n",
       " 'credibility theory provides tools to obtain better estimates by combining individual data with sample information we apply the credibility theory to a uniform distribution that is used in testing the reliability of forecasting an interest rate for long term horizons such empirical exercise is asked by regulators crr in validating an internal model method for counterparty credit risk the main results is that risk managers consider more reliable the output of a test with limited sample size when the',\n",
       " 'credibility is applied to define a confidence interval',\n",
       " 'gas models have been recently proposed in timeseries econometrics as valuable tools for signal extraction and prediction this paper details how financial risk managers can use gas models for valueatrisk var prediction using the novel gas package for r details and code snippets for prediction comparison and backtesting with gas models are presented an empirical application considering dow jones index constituents investigates the var forecasting performance of gas models',\n",
       " 'analytical free of time consuming monte carlo simulations framework for credit portfolio systematic risk metrics calculations is presented techniques are described that allow calculation of portfoliolevel systematic risk measures standard deviation var and expected shortfall as well as allocation of risk down to individual transactions the underlying model is the industry standard multifactor mertontype model with arbitrary valuation function at horizon in contrast to the simplistic defaultonly case high',\n",
       " 'accuracy of the proposed analytical technique is demonstrated by benchmarking against monte carlo simulations',\n",
       " 'in this paper we address the problems faced by a group of agents that possess situational awareness but lack a security mechanism by the introduction of a adaptive risk management system the beliefdesireintention bdi architecture lacks a framework that would facilitate an adaptive risk management system that uses the situational awareness of the agents we extend the bdi architecture with the concept of adaptive alertness agents can modify their level of alertness by monitoring the risks faced by them and by',\n",
       " 'their peers alertbdi enables the agents to detect and assess the risks faced by them in an efficient manner thereby increasing operational efficiency and resistance against attacks',\n",
       " 'we contribute to the understanding of how systemic risk arises in a network of creditinterlinked agents motivated by empirical studies we formulate a network model which despite its simplicity depicts the nature of interbank markets better than a homogeneous model the components of a vector ornsteinuhlenbeck process living on the vertices of the network describe the financial robustnesses of the agents for this system we prove a lln for growing network size leading to a propagation of chaos result we state',\n",
       " 'properties which arise from such a structure and examine the effect of inhomogeneity on several risk management issues and the possibility of contagion',\n",
       " 'the dual risk model is a popular model in finance and insurance which is often used to model the wealth process of a venture capital or high tech company optimal dividends have been extensively studied in the literature for the dual risk model it is well known that the value function of this optimal control problem does not yield closedform solutions except in some special cases in this paper we study the asymptotics of the optimal dividends problem when the parameters of the model go to either zero or',\n",
       " 'infinity our results provide insights to the optimal strategies and the optimal values when the parameters are extreme',\n",
       " 'it is well known that quantile regression model minimizes the portfolio extreme risk whenever the attention is placed on the estimation of the response variable left quantiles we show that by considering the entire conditional distribution of the dependent variable it is possible to optimize different risk and performance indicators in particular we introduce a riskadjusted profitability measure useful in evaluating financial portfolios under a pessimistic perspective since the reward contribution is net of',\n",
       " 'the most favorable outcomes moreover as we consider large portfolios we also cope with the dimensionality issue by introducing an l norm penalty on the assets weights',\n",
       " 'we present an exactlysolvable riskminimizing stochastic differential game for flood management in rivers the streamflow dynamics follow stochastic differential equations driven by a levy process an entropic dynamic risk measure is employed to evaluate a flood risk under model uncertainty the problem is solved via a hamiltonjacobibellmanisaacs equation we explicitly derive an optimal flood mitigation policy along with its existence criteria and the worstcase probability measure a backward stochastic',\n",
       " 'differential representation as an alternative formulation is also presented',\n",
       " 'risk is an inherent feature of agricultural production and marketing and accurate measurement of it helps inform more efficient use of resources this paper examines three tail quantilebased risk measures applied to the estimation of extreme agricultural financial risk for corn and soybean production in the us value at risk var expected shortfall es and spectral risk measures srms we use extreme value theory evt to model the tail returns and present results for these three different risk measures using',\n",
       " 'agricultural futures market data we compare the estimated risk measures in terms of their size and precision and find that they are all considerably higher than normal estimates they are also quite uncertain and become more uncertain as the risks involved become more extreme',\n",
       " 'as systemic risk has become a hot topic in the financial markets how to measure allocate and regulate the systemic risk are becoming especially important however the financial markets are becoming more and more complicate which makes the usual study of systemic risk to be restricted in this paper we will study the systemic risk measures on a special space lpcdot where the variable exponent pcdot is no longer a given real number like the space lp but a random variable which reflects the possible volatility',\n",
       " 'of the financial markets finally the dual representation for this new systemic risk measures will be studied our results show that every this new systemic risk measure can be decomposed into a convex certain function and a simplesystemic risk measure which provides a new ideas for dealing with the systemic risk',\n",
       " 'we introduce a statistical model for operational losses based on heavytailed distributions and bipartite graphs which captures the event type and business line structure of operational risk data the model explicitly takes into account the pareto tails of losses and the heterogeneous dependence structures between them we then derive estimators for individual as well as aggregated tail risk measured in terms of valueatrisk and conditionaltailexpectation for very high confidence levels and provide also an',\n",
       " 'asymptotically full capital allocation method estimation methods for such tail risk measures and capital allocations are also proposed and tested on simulated data finally by having access to realworld operational risk losses from the italian banking system we show that even with a small number of observations the proposed estimation methods produce reliable estimates and that quantifying dependence by means of the empirical network has a big impact on estimates at both individual and aggregate level as',\n",
       " 'well as for capital allocations',\n",
       " 'indexbased hedging solutions are used to transfer the longevity risk to the capital markets however mismatches between the liability of the hedger and the hedging instrument cause longevity basis risk therefore an appropriate twopopulation model to measure and assess the longevity basis risk is required in this paper we aim to construct a twopopulation mortality model to provide an effective hedge against the longevity basis risk the reference population is modelled by using the leecarter model with the',\n",
       " 'renewal process and exponential jumps proposed by ozen and csahin and the dynamics of the book population are specified the analysis based on the uk mortality data indicates that the proposed model for the reference population and the common age effect model for the book population provide a better fit compared to the other models considered in the paper different twopopulation models are used to investigate the impact of the sampling risk on the indexbased hedge as well as to analyse the risk reduction',\n",
       " 'regarding hedge effectiveness the results show that the proposed model provides a significant risk reduction when mortality jumps and the sampling risk are taken into account',\n",
       " 'systemic risk refers to the risk that the financial system is susceptible to failures due to the characteristics of the system itself the tremendous cost of systemic risk requires the design and implementation of tools for the efficient macroprudential regulation of financial institutions the current paper proposes a novel approach to measuring systemic risk key to our construction is a rigorous derivation of systemic risk measures from the structure of the underlying system and the objectives of a',\n",
       " 'financial regulator the suggested systemic risk measures express systemic risk in terms of capital endowments of the financial firms their definition requires two ingredients a cash flow or value model that assigns to the capital allocations of the entities in the system a relevant stochastic outcome and an acceptability criterion ie a set of random outcomes that are acceptable to a regulatory authority systemic risk is measured by the set of allocations of additional capital that lead to acceptable',\n",
       " 'outcomes we explain the conceptual framework and the definition of systemic risk measures provide an algorithm for their computation and illustrate their application in numerical case studies many systemic risk measures in the literature can be viewed as the minimal amount of capital that is needed to make the system acceptable after aggregating individual risks hence quantify the costs of a bailout in contrast our approach emphasizes operational systemic risk measures that include both ex post bailout',\n",
       " 'costs as well as ex ante capital requirements and may be used to prevent systemic crises',\n",
       " 'quantifying uncertainties in collective human behavior and decision making is crucial for ensuring public health and safety enabling effective disaster response informing the design of transportation and communication networks and guiding the development of new technologies however modeling and predicting such behavior is notoriously difficult due to the influence of a variety of complex factors such as the availability and uncertainty of information the interaction and influence of social groups and',\n",
       " 'networks the degree of risk or time pressure involved in a situation and differences in individual personalities and preferences here we develop a stochastic model of human decision making to describe the empirical behavior of subjects in a controlled experiment simulating a natural disaster scenario we compare the observed behavior to that of statistically optimal bayesian decision makers quantifying the extent to which human decisions are optimal and identifying the conditions in which suboptimal',\n",
       " 'decisions are made finally we investigate how human evacuation strategies change when decisions are made in groups under a variety of different rules and whether these group strategy adjustments are optimal or beneficial',\n",
       " 'in largescale natural disasters humans are likely to fail when they attempt to reach highrisk sites or act in search and rescue operations robots however outdo their counterparts in surviving the hazards and handling the search and rescue missions due to their multiple and diverse sensing and actuation capabilities the dynamic formation of optimal coalition of these heterogeneous robots for cost efficiency is very challenging and research in the area is gaining more and more attention in this paper we',\n",
       " 'propose a novel heuristic since the population of robots in largescale disaster settings is very large we rely on quantum multiobjective particle swarm optimization qmopso the problem is modeled as a multiobjective optimization problem simulations with different test cases and metrics and comparison with other algorithms such as nsgaii and speaii are carried out the experimental results show that the proposed algorithm outperforms the existing algorithms not only in terms of convergence but also in terms of',\n",
       " 'diversity and processing time',\n",
       " 'this document constitutes the final report of the contractual activity between directa sim and dipartimento di automatica e informatica politecnico di torino on the research topic titled quantificazione del rischio di un portafoglio di strumenti finanziari per trading online su device fissi e mobili',\n",
       " 'systemic risks characterizing the russian overnight interbank market from the network point of view are analyzed',\n",
       " 'implementing largescale information and communication technology it projects carries large risks and easily might disrupt operations waste taxpayers money and create negative publicity because of the high risks it is important that government leaders manage the attendant risks we analysed a sample of public sector it projects the sample included largescale projects on average the actual expenditure was million and the average duration was months our findings showed that the typical project had no cost',\n",
       " 'overruns and took on average longer than initially expected however comparing the risk distribution with the normative model of a thintailed distribution projects actual costs should fall within and of the budget in nearly out of projects the data showed however that a staggering of all projects are outliers with cost overruns tests showed that the risk of outliers is even higher for standard software as well as in certain project types eg data management office management egovernment and management',\n",
       " 'information systems analysis showed also that projects duration adds risk every additional year of project duration increases the average cost risk by percentage points lastly we suggest four solutions that public sector organization can take benchmark your organization to know where you are debias your it project decisionmaking reduce the complexities of your it projects and develop masterbuilders to learn from the best in the field',\n",
       " 'we introduce a new measure of performance of investment strategies the monotone sharpe ratio we study its properties establish a connection with coherent risk measures and obtain an efficient representation for using in applications',\n",
       " 'the successful completion of a software development process depends on the analytical capability and foresightedness of the project manager for the project manager the main intriguing task is to manage the risk factors as they adversely influence the completion deadline one such key risk factor is staff training the risk of this factor can be avoided by prejudging the amount of training required by the staff so a procedure is required to help the project manager make this decision this paper presents a',\n",
       " 'system that uses influence diagrams to implement the risk model to aid decision making the system also considers the cost of conducting the training based on various risk factors such as i lack of experience with project software ii newly appointed staff iii staff not well versed with the required quality standards and iv lack of experience with project environment the system provides estimated requirement details for staff training at the beginning of a software development project',\n",
       " 'this paper describes the rationale curriculum and subject matter of a new msc module being taught on an msc finance and information management course at the university of wales institute in cardiff academic research on spreadsheet risks now has some penetration in academic literature and there is a growing body of knowledge on the subjects of spreadsheet error human factors spreadsheet engineering best practice spreadsheet risk management and various techniques used to mitigate spreadsheet errors this new',\n",
       " 'msc module in end user computing risk management is an attempt to pull all of this research and practitioner experience together to arm the next generation of finance spreadsheet champions with the relevant knowledge techniques and critical perspective on an emerging discipline',\n",
       " 'once upon a time there was a classical financial world in which all the libors were equal standard textbooks taught that simple relations held such that for example a months libor deposit was replicable with a months libor deposits plus a x months forward rate agreement fra and that libor was a good proxy of the risk free rate required as basic building block of noarbitrage pricing theory nowadays in the modern financial world after the credit crunch some libors are more equal than others depending on their',\n",
       " 'rate tenor and classical formulas are history banks are not anymore too big to fail libors are fixed by panels of risky banks and they are risky rates themselves these simple empirical facts carry very important consequences in derivatives trading and risk management such as for example basis risk collateralization and regulatory pressure in favour of central counterparties something that should be carefully considered by anyone managing even a single plain vanilla swap in this qualitative note we review',\n",
       " 'the problem trying to shed some light on this modern animal farm recurring to an analogy with quantum physics the zeeman effect',\n",
       " 'we review and apply quasi monte carlo qmc and global sensitivity analysis gsa techniques to pricing and risk management greeks of representative financial instruments of increasing complexity we compare qmc vs standard monte carlo mc results in great detail using highdimensional sobol low discrepancy sequences different discretization methods and specific analyses of convergence performance speed up stability and error optimization for finite differences greeks we find that our qmc outperforms mc in most',\n",
       " 'cases including the highestdimensional simulations and greeks calculations showing faster and more stable convergence to exact or almost exact results using gsa we are able to fully explain our findings in terms of reduced effective dimension of our qmc simulation allowed in most cases but not always by brownian bridge discretization we conclude that beyond pricing qmc is a very promising technique also for computing risk figures greeks in particular as it allows to reduce the computational effort of',\n",
       " 'highdimensional monte carlo simulations typical of modern risk management',\n",
       " 'modeling policyholders lapse behaviors is important to a life insurer since lapses affect pricing reserving profitability liquidity risk management as well as the solvency of the insurer lapse risk is indeed the most significant life underwriting risk according to european insurance and occupational pensions authoritys quantitative impact study qis in this paper we introduce two advanced machine learning algorithms for lapse modeling then we evaluate the performance of different algorithms by means of',\n",
       " 'classical statistical accuracy and profitability measure moreover we adopt an innovative point of view on the lapse prediction problem that comes from churn management we transform the classification problem into a regression question and then perform optimization which is new for lapse risk management we apply different algorithms to a large realworld insurance dataset our results show that xgboost and svm outperform cart and logistic regression especially in terms of the economic validation metric the',\n",
       " 'optimization after transformation brings out significant and consistent increases in economic gains',\n",
       " 'the quest for diversification has led to an increasing number of complex funds with a high number of strategies and nonlinear payoffs the new generation of alternative risk premia arp funds are an example that has been very popular in recent years for complex funds like these a reverse stress test rst is regarded by the industry and regulators as a better forwardlooking risk measure than a valueatrisk var we present an extended rst erst triptych approach with three variables level of plausibility level of',\n",
       " 'loss and scenario in our approach any two of these variables can be derived by providing the third as the input we advocate and demonstrate that erst is a powerful tool for both simple linear and complex portfolios and for both risk management as well as daytoday portfolio management decisions an updated new version of the levenberg marquardt optimization algorithm is introduced to derive erst in certain complex cases',\n",
       " 'the pcl framework provides a comprehensive climate risk management approach grounded in the assessment of societal values of financial and nonfinancial loss tolerability the framework optimizes response action across three main clusters namely preemptive adaptation p or risk reduction contingent arrangements c and loss acceptance l without a predetermined hierarchy across them the pcl framework aims at including the three clusters of outlay within a single continuum and with the main policy outcome being a',\n",
       " 'balanced portfolio of actions across the three clusters by way of an optimization module such that the aggregate outlay is optimized in the longterm it is proposed that the approach be applied separately for each hazard to which the target community is exposed while it is currently applied to climaterelated risk management the methodology can be repurposed for use in other contexts where societal buyin is central',\n",
       " 'using jeff holmans comments in quantitative finance to illustrate critical errors students should learn to avoid mistaking tails th moment for volatility nd moment missing jensens inequality analyzing the hedging wihout the underlying the necessity of a numeraire in finance',\n",
       " 'this paper discusses financial fraud detection in imbalanced dataset using homogeneous and nonhomogeneous poisson processes the probability of predicting fraud on the financial transaction is derived applying our methodology to the financial dataset shows a better predicting power than a baseline approach especially in the case of higher imbalanced data',\n",
       " 'in this work inspired by the archermouyselmi approach we present two methodologies for scoring the stress test scenarios used by ccps for sizing their default funds these methodologies can be used by risk managers to compare different sets of scenarios and could be particularly useful when evaluating the relevance of adding new scenarios to a preexisting set',\n",
       " 'climate change is one of the greatest challenges facing humanity and we as machine learning experts may wonder how we can help here we describe how machine learning can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate from smart grids to disaster management we identify high impact problems where existing gaps can be filled by machine learning in collaboration with other fields our recommendations encompass exciting research questions as well as',\n",
       " 'promising business opportunities we call on the machine learning community to join the global effort against climate change',\n",
       " 'we numerically study an asset liability management problem linked to the decommissioning of french nuclear power plants we link the risk aversion of practitioners to an optimization problem using different price models we show that the optimal solution is linked to a derisking management strategy similar to a concave strategy and we propose an effective heuristic to simulate the underlying optimal strategy besides we show that the strategy is stable with respect to the main parameters involved in the',\n",
       " 'liability problem',\n",
       " 'we give an explicit algorithm and source code for extracting expected returns for stocks from expected returns for alphas our algorithm altogether bypasses combining alphas with weights into alpha combos simply put we have developed a new method for trading alphas which does not involve combining them this yields substantial cost savings as alpha combos cost hedge funds around of the pl while alphas themselves cost around also the extra layer of alpha combos which our new method avoids adds noise and',\n",
       " 'suboptimality we also arrive at our algorithm independently by explicitly constructing alpha risk models based on position data',\n",
       " 'hedge funds are considered as one of the portfolio management sectors which shows a fastest growing for the past decade an optimal hedge fund management requires an appropriate risk metrics the classic capm theory and its ratio sharpe fail to capture some crucial aspects due to the strong nongaussian character of hedge funds statistics a possible way out to this problem while keeping the capm simplicity is the socalled downside risk analysis one important benefit lies in distinguishing between good and bad',\n",
       " 'returns that is returns greater or lower than investors goal we revisit most popular downside risk indicators and provide new analytical results on them we compute these measures by taking the credit suissetremont investable hedge fund index data and with the gaussian case as a benchmark in this way an unusual transversal lecture of the existing downside risk measures is provided',\n",
       " 'we study the asymptotic behavior of the difference between the values at risk varl and varls for heavy tailed random variables l and s for application in sensitivity analysis of quantitative operational risk management within the framework of the advanced measurement approach of basel ii and iii here l describes the loss amount of the present risk profile and s describes the loss amount caused by an additional loss factor we obtain different types of results according to the relative magnitudes of the',\n",
       " 'thicknesses of the tails of l and s in particular if the tail of s is sufficiently thinner than the tail of l then the difference between prior and posterior risk amounts varls varl is asymptotically equivalent to the expectation expected loss of s',\n",
       " 'we propose a unified framework for equity and credit risk modeling where the default time is a doubly stochastic random time with intensity driven by an underlying affine factor process this approach allows for flexible interactions between the defaultable stock price its stochastic volatility and the default intensity while maintaining full analytical tractability we characterise all riskneutral measures which preserve the affine structure of the model and show that risk management as well as pricing',\n",
       " 'problems can be dealt with efficiently by shifting to suitable survival measures as an example we consider a jumptodefault extension of the heston stochastic volatility model',\n",
       " 'background the sensitivity of requirements engineering re to the context makes it difficult to efficiently control problems therein thus hampering an effective risk management devoted to allow for early corrective or even preventive measures problem there is still little empirical knowledge about contextspecific re phenomena which would be necessary for an effective context sensitive risk management in re goal we propose and validate an evidencebased approach to assess risks in re using crosscompany data',\n",
       " 'about problems causes and effects research method we use survey data from companies and build a probabilistic network that supports the forecast of contextspecific re phenomena we implement this approach using spreadsheets to support a lightweight risk assessment results our results from an initial validation in companies strengthen our confidence that the approach increases the awareness for individual risk factors in re and the feedback further allows for disseminating our approach into practice',\n",
       " 'academic research projects receive hundreds of billions of dollars of government investment each year they complement business research projects by focusing on the generation of new foundational knowledge and addressing societal challenges despite the importance of academic research the management of it is often undisciplined and ad hoc it has been postulated that the inherent uncertainty and complexity of academic research projects make them challenging to manage however based on this studys analysis of',\n",
       " 'input and voting from more than academic research team members in facilitated risk management sessions the most important perceived risks are general as opposed to being research specific overall participants top risks related to funding team instability unreliable partners study participant recruitment and data access many of these risks would require system or organizationlevel responses that are beyond the scope of individual academic research teams',\n",
       " 'the panoramic survey telescope and rapid response system panstarrs is unique among the existing or planned major groundbased optical survey systems as the only distributed aperture system the concept of increasing system etendue by replicating small telescopes and digital cameras presents both management opportunities and challenges the focus in this paper is on management lessons learned from ps and how those have been used to form the management plan for ps the management plan components emphasized here',\n",
       " 'include technical development financial and schedule planning and critical path and risk management finally the status and schedule for ps are presented',\n",
       " 'deployment of emerging technologies and rapid change in industries has created a lot of risk for initiating the new projects many techniques and suggestions have been introduced but still lack the gap from various prospective this paper proposes a reliable project scheduling approach the objectives of project scheduling approach are to focus on critical chain schedule and risk management several risks and reservations exist in projects these critical reservations may not only foil the projects to be',\n",
       " 'finished within time limit and budget but also degrades the quality and operational process in the proposed approach the potential risks of project are critically analyzed to overcome these potential risks fuzzy failure mode and effect analysis fmea is introduced in addition several affects of each risk against each activity are evaluated we use monte carlo simulation that helps to calculate the total time of project our approach helps to control risk mitigation that is determined using event tree analysis',\n",
       " 'and fault tree analysis we also implement distribute critical chain schedule for reliable scheduling that makes the project to be implemented within defined plan and schedule finally adaptive procedure with density apd is deployed to get reasonable feeding buffer time and project buffer time',\n",
       " 'we develop an agentbased simulation of the catastrophe insurance and reinsurance industry and use it to study the problem of risk model homogeneity the model simulates the balance sheets of insurance firms who collect premiums from clients in return for ensuring them against intermittent heavytailed risks firms manage their capital and pay dividends to their investors and use either reinsurance contracts or cat bonds to hedge their tail risk the model generates plausible time series of profits and losses',\n",
       " 'and recovers stylized facts such as the insurance cycle and the emergence of asymmetric long tailed firm size distributions we use the model to investigate the problem of risk model homogeneity under solvency ii insurance companies are required to use only certified risk models this has led to a situation in which only a few firms provide risk models creating a systemic fragility to the errors in these models we demonstrate that using too few models increases the risk of nonpayment and default while',\n",
       " 'lowering profits for the industry as a whole the presence of the reinsurance industry ameliorates the problem but does not remove it our results suggest that it would be valuable for regulators to incentivize model diversity the framework we develop here provides a first step toward a simulation model of the insurance industry for testing policies and strategies for better capital management',\n",
       " 'we present a decision support system for flood early warning and disaster management it includes the models for datadriven meteorological predictions for simulation of atmospheric pressure wind long sea waves and seiches a module for optimization of flood barrier gates operation models for stability assessment of levees and embankments for simulation of city inundation dynamics and citizens evacuation scenarios the novelty of this paper is a coupled distributed simulation of surface and subsurface flows',\n",
       " 'that can predict inundation of lowlying inland zones far from the submerged waterfront areas as observed in st petersburg city during the floods all the models are wrapped as software services in the clavire platform for urgent computing which provides workflow management and resource orchestration',\n",
       " 'emergency response to incidents such as accidents crimes and fires is a major problem faced by communities emergency response management comprises of several stages and subproblems like forecasting resource allocation and dispatch the design of principled approaches to tackle each problem is necessary to create efficient emergency response management erm pipelines over the last six years we have worked with several first responder organizations to design erm pipelines in this paper we highlight some of the',\n",
       " 'challenges that we have identified and lessons that we have learned through our experience in this domain such challenges are particularly relevant for practitioners and researchers and are important considerations even in the design of response strategies to mitigate disasters like floods and earthquakes',\n",
       " 'complexity is an inherent attribute of any project the purpose of defining and documenting complexity is to have an early warning tool allowing a project team to focus on certain areas and aspects of the project in order to prevent and alleviate future risks and issues caused by this complexity the main contribution of this paper is to present a systematic view of complexity in project management by identifying its key attributes and classifying complexity by these attributes a complexity taxonomy based on',\n",
       " 'a survey of the existing complexity literature is developed and discussed including the product project and external environment dimensions we show how complexity types are described through simple real life examples and business cases then we develop a framework tool for applying the notion of complexity as an early warning tool for a project manager in order to timely foresee future risks and problems the paper is intended for researchers in complexity project management information systems technology',\n",
       " 'solutions and business management and also for information specialists project managers program managers financial staff and technology directors',\n",
       " 'in modern society the flow of information has become the lifeblood of commerce and social interaction this movement of data supports most aspects of the united states economy in particular as well as serving as the vehicle upon which governmental agencies react to social conditions in addition it is understood that the continuance of efficient and reliable data communications during times of national or regional disaster remains a priority in the united states the coordination of emergency response and area',\n",
       " 'revitalization rehabilitation efforts between local state and federal emergency response is increasingly necessary as agencies strive to work more seamlessly between the affected organizations additionally international support is often made available to react to such adverse conditions as wildfire suppression scenarios and therefore require the efficient management of workforce and associated logistics support it is through the examination of the issues related to untethered data transmission during',\n",
       " 'infrastructure contingencies that responders may best tailor a unified approach to the rapid recovery after disasters occur',\n",
       " 'internet of things iot is expected to enable a myriad of applications by interconnecting objects such as sensors and robots over the internet iot applications range from healthcare to autonomous vehicles and include disaster management enabling these applications in cloud environments requires the design of appropriate iot infrastructureasaservice iot iaas to ease the provisioning of the iot objects as cloud services this paper discusses a case study on search and rescue iot applications in largescale',\n",
       " 'disaster scenarios it proposes an iot iaas architecture that virtualizes robots iaas for robots and provides them to the upstream applications asaservice node and networklevel robots virtualization are supported the proposed architecture meets a set of identified requirements such as the need for a unified description model for heterogeneous robots publicationdiscovery mechanism and federation with other iaas for robots when needed a validating proof of concept is built and experiments are made to evaluate',\n",
       " 'its performance lessons learned and prospective research directions are discussed',\n",
       " 'during a disaster event images shared on social media helps crisis managers gain situational awareness and assess incurred damages among other response tasks recent advances in computer vision and deep neural networks have enabled the development of models for realtime image classification for a number of tasks including detecting crisis incidents filtering irrelevant images classifying images into specific humanitarian categories and assessing the severity of damage despite several efforts past works',\n",
       " 'mainly suffer from limited resources ie labeled images available to train more robust deep learning models in this study we propose new datasets for disaster type detection and informativeness classification and damage severity assessment moreover we relabel existing publicly available datasets for new tasks we identify exact and nearduplicates to form nonoverlapping data splits and finally consolidate them to create larger datasets in our extensive experiments we benchmark several stateoftheart deep',\n",
       " 'learning models and achieve promising results we release our datasets and models publicly aiming to provide proper baselines as well as to spur further research in the crisis informatics community',\n",
       " 'discussion of ims medallion lecture local rademacher complexities and oracle inequalities in risk minimization by v koltchinskii arxiv',\n",
       " 'discussion of ims medallion lecture local rademacher complexities and oracle inequalities in risk minimization by v koltchinskii arxiv',\n",
       " 'discussion of ims medallion lecture local rademacher complexities and oracle inequalities in risk minimization by v koltchinskii arxiv',\n",
       " 'discussion of ims medallion lecture local rademacher complexities and oracle inequalities in risk minimization by v koltchinskii arxiv',\n",
       " 'discussion of ims medallion lecture local rademacher complexities and oracle inequalities in risk minimization by v koltchinskii arxiv',\n",
       " 'in this paper we will discuss the optimal risk transfer problems when risk measures are generated by gexpectations and we present the relationship between infconvolution of gexpectations and the infconvolution of drivers g',\n",
       " 'we analyze operational risk in terms of a spin glass model several regimes are investigated as a functions of the parameters that characterize the dynamics the system is found to be robust against variations of these parameters we unveil the presence of limit cycles and scrutinize the features of the asymptotic state',\n",
       " 'value at risk var is a risk measure that has been widely implemented by financial institutions this paper measures the correlation among asset price changes implied from var calculation empirical results using us and uk equity indexes show that implied correlation is not constant but tends to be higher for events in the left tails crashes than in the right tails booms',\n",
       " 'in the conditional setting we provide a complete duality between quasiconvex risk measures defined on l modules of the lp type and the appropriate class of dual functions this is based on a general result which extends the usual penotvolle representation for quasiconvex real valued maps',\n",
       " 'we pick up the regime switching model for asset returns introduced by rogers and zhang the calibration involves various markets including implied volatility in order to gain additional predictive power we focus on the calculation of risk measures by fourier methods that have successfully been applied to option pricing and analyze the accuracy of the results',\n",
       " 'we show that some specific market risk measures implied by current international capital regulation the basel accords and the capital adequacy directive of the european union violate the obvious requirement of convexity in some regions in the space of portfolio weights',\n",
       " 'we propose a portfolio approach for operational risk quantification based on a class of analytical models from which we derive new results on the correlation problem in particular we show that uniform correlation is a robust assumption for measuring capital charges in these models',\n",
       " 'in this study we propose a new definition of multivariate conditional valueatrisk mcvar as a set of vectors for discrete probability spaces we explore the properties of the vectorvalued mcvar vmcvar and show the advantages of vmcvar over the existing definitions given for continuous random variables when adapted to the discrete case',\n",
       " 'we are highly vulnerable to either natural or artificial catastrophes and therefore public protection and disaster relief ppdr operators need reliable wireless communications for successful operations especially in critical rescue missions ppdr dedicated or commercial terrestrial networks have always been used which at most times lead to unsuccessful operations this is due to the fact these networks are all infrastructurebased which can be destroyed fail to deliver the required service or the networks are',\n",
       " 'not able to support and sustain the sudden traffic surge longterm evolution lte is earmarked as the future candidate technology for ppdr purpose and so much have been put into it in terms of research perhaps suitable architecture that will meet missioncritical requirements can be developed this can only work if terrestrial networks will always be available unfortunately in worst case scenarios infrastructures might get damaged totally or might be destroyed by subsequent disasters as a result adequate',\n",
       " 'guarantees can only be possible in the hypothesis of very high financial involvement fortunately considering availability coverage ubiquity and reliability satellite technologies have lately proven good so to maximize the high channel performance of terrestrial networks and the availability and reliability of nonterrestrial networks the solution lies in a hybrid system it is on this ground that this work deals with the integration of lte and satellite networks in both infrastructurebased and',\n",
       " 'infrastructureless topologies for ppdr purpose it is aim at providing people trapped in disaster and field operators with a transparent accessibility and guaranteed coverage even when infrastructures are damaged the requirements are defined and the model simulated the network is able to provide network coverage enhanced capacity and promised greater resilience',\n",
       " 'in postdisaster scenarios such as after floods earthquakes and in war zones the cellular communication infrastructure may be destroyed or seriously disrupted in such emergency scenarios it becomes very important for first aid responders to communicate with other rescue teams in order to provide feedback to both the central office and the disaster survivors to address this issue rapidly deployable systems are required to reestablish connectivity and assist users and first responders in the region of incident',\n",
       " 'in this work we describe the design implementation and evaluation of a rapidly deployable system for first response applications in postdisaster situations named rdsp the proposed system helps early rescue responders and victims by sharing their location information to remotely located servers by utilizing a novel routing scheme this novel routing scheme consists of the dynamic id assignment dia algorithm and the minimum maximum neighbor mmn algorithm the dia algorithm is used by relay devices to',\n",
       " 'dynamically select their ids on the basis of all the available ids of networks whereas the mmn algorithm is used by the client and relay devices to dynamically select their next neighbor relays for the transmission of messages the rdsp contains three devices the client device sends the victims location information to the server the relay device relays information between client and server device the server device receives messages from the client device to alert the rescue team we deployed and evaluated our',\n",
       " 'system in the outdoor environment of the university campus the experimental results show that the rdsp system reduces the message delivery delay and improves the message delivery ratio with lower communication overhead',\n",
       " 'during a disaster event two types of information that are especially useful for coordinating relief operations are needs and availabilities of resources eg food water medicines in the affected region information posted on microblogging sites is increasingly being used for assisting postdisaster relief operations in this context two practical challenges are ito identify tweets that inform about resource needs and availabilities termed as needtweets and availabilitytweets respectively and iito automatically',\n",
       " 'match needs with appropriate availabilities while several works have addressed the first problem there has been little work on automatically matching needs with availabilities the few prior works that attempted matching only considered the resources and no attempt has been made to understand other aspects of needsavailabilities that are essential for matching in practice in this work we develop a methodology for understanding five important aspects of needtweets and availabilitytweets including what',\n",
       " 'resource and what quantity is neededavailable the geographical location of the needavailability and who needs is providing the resource understanding these aspects helps us to address the needavailability matching problem considering not only the resources but also other factors such as the geographical proximity between the need and the availability to our knowledge this study is the first attempt to develop methods for understanding the semantics of needtweets and availabilitytweets we also develop a',\n",
       " 'novel methodology for matching needtweets with availabilitytweets considering both resource similarity and geographical proximity experiments on two datasets corresponding to two disaster events demonstrate that our proposed methods perform substantially better matching than those in prior works',\n",
       " 'we have developed a framework for crisis response and management that incorporates the latest technologies in computer vision cv inland flood prediction damage assessment and data visualization the framework uses data collected before during and after the crisis to enable rapid and informed decision making during all phases of disaster response our computervision model analyzes spaceborne and airborne imagery to detect relevant features during and after a natural disaster and creates metadata that is',\n",
       " 'transformed into actionable information through webaccessible mapping tools in particular we have designed an ensemble of models to identify features including water roads buildings and vegetation from the imagery we have investigated techniques to bootstrap and reduce dependency on large data annotation efforts by adding use of open source labels including openstreetmaps and adding complementary data sources including height above nearest drainage hand as a side channel to the networks input to encourage',\n",
       " 'it to learn other features orthogonal to visual characteristics modeling efforts include modification of connected unets for semantic segmentation flood line detection and for damage assessment in particular for the case of damage assessment we added a second encoder to unet so that it could learn preevent and postevent image features simultaneously through this method the network is able to learn the difference between the pre and postdisaster images and therefore more effectively classify the level of',\n",
       " 'damage we have validated our approaches using publicly available data from the national oceanic and atmospheric administration noaas remote sensing division which displays the city and streetlevel details as mosaic tile images as well as data released as part of the xview challenge',\n",
       " 'monitoring dam failures using satellite images provides first responders with efficient management of early interventions it is also equally important to monitor spatial and temporal changes in the inundation area to track the postdisaster recovery on january th the tailings dam of the corrego do feijao iron ore mine located in brumadinho brazil collapsed this disaster caused more than fatalities and missing people leading to damage on the order of multiple billions of dollars this study uses sentinel',\n",
       " 'satellite images to map the inundation area and assess and delineate the land use and land cover impacted by the dam failure the images correspond to data captures from january nd days before and february days after the collapse satellite images of the region were classified for before and aftermath of the disaster implementing a machine learning algorithm in order to have sufficient land cover types to validate the quality and accuracy of the algorithm classes were defined mine forest buildup river',\n",
       " 'agricultural clear water and grassland the developed classification algorithm yielded a high accuracy for the image before the collapse this paper determines land cover impact using two different models by using the trained network in the after image and by creating a second network trained in a subset of points of the after image and then comparing the land cover results of the two trained networks in the first model applying the trained network to the after image the accuracy is still high but lower than',\n",
       " 'using the second model this strategy can be applied at a low cost for monitoring and assessment by using openly available satellite information and in case of dam collapse or with a larger budget higher resolution and faster data can be obtained by flyovers on the area of concern',\n",
       " 'counterparty risk denotes the risk that a party defaults in a bilateral contract this risk not only depends on the two parties involved but also on the risk from various other contracts each of these parties holds in rather informal markets such as the otc overthecounter derivative market institutions only report their aggregated quarterly risk exposure but no details about their counterparties hence little is known about the diversification of counterparty risk in this paper we reconstruct the weighted and',\n",
       " 'timedependent network of counterparty risk in the otc derivatives market of the united states between and to proxy unknown bilateral exposures we first study the cooccurrence patterns of institutions based on their quarterly activity and ranking in the official report the network obtained this way is further analysed by a weighted kcore decomposition to reveal a coreperiphery structure this allows us to compare the activitybased ranking with a topologybased ranking to identify the most important',\n",
       " 'institutions and their mutual dependencies we also analyse correlations in these activities to show strong similarities in the behavior of the core institutions our analysis clearly demonstrates the clustering of counterparty risk in a small set of about a dozen us banks this not only increases the default risk of the central institutions but also the default risk of peripheral institutions which have contracts with the central ones hence all institutions indirectly have to bear part of the counterparty',\n",
       " 'risk of all others which needs to be better reflected in the price of otc derivatives',\n",
       " 'to understand the relationship between news sentiment and company stock price movements and to better understand connectivity among companies we define an algorithm for measuring sentimentbased network risk the algorithm ranks companies in networks of cooccurrences and measures sentimentbased risk by calculating both individual risks and aggregated network risks we extract relative sentiment for companies to get a measure of individual company risk and input it into our risk model together with',\n",
       " 'cooccurrences of companies extracted from news on a quarterly basis we can show that the highest quarterly risk value outputted by our risk model is correlated to a higher chance of stock price decline up to days after a risk measurement our results show that the highest difference in the probability of stock price decline compared to the benchmark containing all risk values for the same period is during the interval from to days after a quarterly measurement the highest average probability of company stock',\n",
       " 'price decline is found at a delay of days after a company has reached its maximum risk value the highest probability differences for a daily decline were calculated to be percentage points',\n",
       " 'resilience against major disasters is the most essential characteristic of future electrical distribution systems eds a multiagentbased rolling optimization method for eds restoration scheduling is proposed in this paper when a blackout occurs considering the risk of losing the centralized authority due to the failure of the common core communication network the agents available after disasters or cyberattacks identify the communicationconnected parts ccps in the eds with distributed communication a',\n",
       " 'multitime interval optimization model is formulated and solved by the agents for the restoration scheduling of a ccp a rolling optimization process for the entire eds restoration is proposed during the schedulingrescheduling in the rolling process the ccps in the eds are reidentified and the restoration schedules for the ccps are updated through decentralized decisionmaking and rolling optimization eds restoration scheduling can automatically start and periodically update itself providing effective',\n",
       " 'solutions for eds restoration scheduling in a blackout event a modified ieee bus eds is utilized to demonstrate the effectiveness of the proposed method',\n",
       " 'as the use of renewable generation has increased electric power systems have become increasingly reliant on natural gasfired power plants as fast ramping sources for meeting fluctuating bulk power demands this dependence has introduced new vulnerabilities to the power grid including disruptions to gas transmission networks from natural and manmade disasters to address the operational challenges arising from these disruptions we consider the task of determining a feasible steadystate operating point for a',\n",
       " 'damaged gas pipeline network while ensuring the maximal delivery of load we formulate the mixedinteger nonconvex maximal load delivery mld problem which proves difficult to solve on largescale networks to address this challenge we present a mixedinteger convex relaxation of the mld problem and use it to determine bounds on the transport capacity of a gas pipeline system to demonstrate the effectiveness of the relaxation the exact and relaxed formulations are compared across a large number of randomized',\n",
       " 'damage scenarios on nine natural gas pipeline network models ranging in size from to junctions a proof of concept application which assumes network damage from a set of synthetically generated earthquakes is also presented to demonstrate the utility of the proposed optimizationbased capacity evaluation in the context of risk assessment for natural disasters for all but the largest network the relaxationbased method is found to be suitable for use in evaluating the impacts of multicontingency network',\n",
       " 'disruptions often converging to the optimal solution of the relaxed formulation in less than ten seconds',\n",
       " 'we study the risk criterion for investments based on the drawdown from the maximal value of the capital in the past depending on investors risk attitude thus his risk exposure we find that the distribution of these drawdowns follows a general power law in particular if the risk exposure is kellyoptimal the exponent of this power law has the borderline value of ie the average drawdown is just about to diverge',\n",
       " 'this paper presents analytical solutions to the problem of how to calculate sensible var valueatrisk and es expected shortfall contributions in the creditrisk methodology via the es contributions es itself can be exactly computed in finitely many steps the methods are illustrated by numerical examples',\n",
       " 'within the framework of maximum entropy principle we show that the finitesize longrange ising model is the adequate model for the description of homogeneous credit portfolios and the computation of credit risk when default correlations between the borrowers are included the exact analysis of the model suggest that when the correlation increases a firstorderlike transition may occur inducing a sudden risk increase such a feature is not reproduced by the standard models used in credit risk modeling',\n",
       " 'in this paper we generalize the parametric deltavar method from portfolios with normally distributed risk factors to portfolios with elliptically distributed ones we treat both the expected shortfall and the valueatrisk of such portfolios special attention is given to the particular case of a multivariate tdistribution',\n",
       " 'estimation of the operational risk capital under the loss distribution approach requires evaluation of aggregate compound loss distributions which is one of the classic problems in risk theory closedform solutions are not available for the distributions typically used in operational risk however with modern computer processing power these distributions can be calculated virtually exactly using numerical methods this paper reviews numerical algorithms that can be successfully used to calculate the aggregate',\n",
       " 'loss distributions in particular monte carlo panjer recursion and fourier transformation methods are presented and compared also several closedform approximations based on moment matching and asymptotic result for heavytailed distributions are reviewed',\n",
       " 'setvalued risk measures on lpd with leq p leq infty for conical market models are defined primal and dual representation results are given the collection of initial endowments which allow to superhedge a multivariate claim are shown to form the values of a setvalued sublinear coherent risk measure scalar risk measures with multiple eligible assets also turn out to be a special case within the setvalued framework',\n",
       " 'multivariate regular variation plays a role assessing tail risk in diverse applications such as finance telecommunications insurance and environmental science the classical theory being based on an asymptotic model sometimes leads to inaccurate and useless estimates of probabilities of joint tail regions this problem can be partly ameliorated by using hidden regular variation resnick mitra and resnick we offer a more flexible definition of hidden regular variation that provides improved risk estimates for a',\n",
       " 'larger class of risk tail regions',\n",
       " 'this paper derives considering a gaussian setting closed form solutions of the statistics that adrian and brunnermeier and acharya et al have suggested as measures of systemic risk to be attached to individual banks the statistics equal the product of statistic specific betacoefficients with the mean corrected value at risk hence the measures of systemic risks are closely related to well known concepts of financial economics another benefit of the analysis is that it is revealed how the concepts are related',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-julian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
