{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Experiment for QA Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', 'src')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3642e3992841dfc4f51d2306d25d7684b1bf083adf1f4943f0feb5b1dcbbe1d\n",
      "docker: Error response from daemon: driver failed programming external connectivity on endpoint heuristic_lewin (166659bc71a9c0d03d04834c2da93cdbee29a8cc66901b790cb47863b3ed1f74): Bind for 0.0.0.0:9200 failed: port is already allocated.\n"
     ]
    }
   ],
   "source": [
    "#import haystack and FARM utils\n",
    "from haystack import Finder\n",
    "from haystack.preprocessor.cleaning import clean_wiki_text\n",
    "from haystack.preprocessor.utils import convert_files_to_dicts, fetch_archive_from_http\n",
    "from haystack.reader.farm import FARMReader\n",
    "from haystack.reader.transformers import TransformersReader\n",
    "from haystack.utils import print_answers\n",
    "\n",
    "#initialize elasticsearch docker image\n",
    "! docker run -d -p 9200:9200 -e \"discovery.type=single-node\" elasticsearch:7.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:36:47 - INFO - elasticsearch -   PUT http://localhost:9200/document [status:200 request:0.284s]\n",
      "10/07/2020 18:36:47 - INFO - elasticsearch -   PUT http://localhost:9200/label [status:200 request:0.163s]\n"
     ]
    }
   ],
   "source": [
    "#initialize document storage\n",
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIMS_ID</th>\n",
       "      <th>project_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1584</td>\n",
       "      <td>This programme will contribute to the protection of the biological diversity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1878</td>\n",
       "      <td>The project contributes to the number of GEF projects supported in the agric...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0 PIMS_ID  \\\n",
       "2    1584   \n",
       "4    1878   \n",
       "\n",
       "0                                                              project_description  \n",
       "2  This programme will contribute to the protection of the biological diversity...  \n",
       "4  The project contributes to the number of GEF projects supported in the agric...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "'''processed log-frames'''\n",
    "with open(os.path.abspath(os.path.join('..', 'data'))+'/logframes_clean.pkl', 'rb') as handle:\n",
    "    data = pickle.load(handle)\n",
    "    \n",
    "'''descriptions from taxonomy'''\n",
    "with open(os.path.abspath(os.path.join('..', 'data'))+'/project_description.pkl', 'rb') as handle:\n",
    "    description = pickle.load(handle)\n",
    "    description = description.rename(columns={\"pims_#\": \"PIMS_ID\"})\n",
    "    \n",
    "description.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = pd.concat([pd.Series(row['PIMS_ID'], row['full_obj_or_outcome'].split(\"',\"), )              \n",
    "                    for _, row in data.iterrows()]).reset_index()\n",
    "\n",
    "splitted = splitted.rename(columns={\"index\": \"text\", 0: \"PIMS_ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "for i, row in splitted.iterrows():\n",
    "    write_dicts = {'text': row.text, 'PIMS_ID': row.PIMS_ID}\n",
    "    dict_list.append(write_dicts)\n",
    "dicts = tuple(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_2 = []\n",
    "for i, row in description.iterrows():\n",
    "    write_dicts = {'text': row.project_description, 'PIMS_ID': row.PIMS_ID}\n",
    "    dict_list_2.append(write_dicts)\n",
    "descriptions = tuple(dict_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:47:49 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.706s]\n",
      "10/07/2020 18:47:50 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.008s]\n"
     ]
    }
   ],
   "source": [
    "document_store.write_documents(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.retriever.sparse import ElasticsearchRetriever\n",
    "retriever = ElasticsearchRetriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:48:30 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "10/07/2020 18:48:30 - INFO - farm.infer -   Could not find `deepset/roberta-base-squad2` locally. Try to download from model hub ...\n",
      "10/07/2020 18:48:34 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "10/07/2020 18:48:40 - WARNING - farm.modeling.prediction_head -   Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"loss_ignore_index\": -1}\n",
      "10/07/2020 18:48:46 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "10/07/2020 18:48:46 - INFO - farm.infer -   Got ya 3 parallel workers to do inference ...\n",
      "10/07/2020 18:48:46 - INFO - farm.infer -    0    0    0 \n",
      "10/07/2020 18:48:46 - INFO - farm.infer -   /w\\  /w\\  /w\\\n",
      "10/07/2020 18:48:46 - INFO - farm.infer -   /'\\  / \\  /'\\\n",
      "10/07/2020 18:48:46 - INFO - farm.infer -       \n",
      "10/07/2020 18:48:46 - INFO - haystack.reader.farm -   Saving reader model to models/roberta-temp\n"
     ]
    }
   ],
   "source": [
    "'''load baseline roberat model from FARM(huggingface also possible):'''\n",
    "\n",
    "'''uncomment if model is not stored on disk'''\n",
    "#reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=False)\n",
    "#reader.save(\"models/roberta-temp\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FARMReader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-065f25764a16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load Roberta reader from disk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFARMReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"models/roberta-temp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# for choosing right pre-trained model:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# https://haystack.deepset.ai/en/docs/readermd#Choosing-the-Right-Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FARMReader' is not defined"
     ]
    }
   ],
   "source": [
    "'''load Roberta reader from disk'''\n",
    "\n",
    "reader = FARMReader(model_name_or_path=\"models/roberta-temp\", use_gpu=False, max_seq_len=500, doc_stride=50)\n",
    "# for choosing right pre-trained model:\n",
    "# https://haystack.deepset.ai/en/docs/readermd#Choosing-the-Right-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put reader and retriever together in pipeline:\n",
    "finder = Finder(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:49:47 - INFO - elasticsearch -   POST http://localhost:9200/document/_search [status:200 request:0.295s]\n",
      "10/07/2020 18:49:47 - INFO - haystack.retriever.sparse -   Got 10 candidates from retriever\n",
      "10/07/2020 18:49:47 - INFO - haystack.finder -   Reader is looking for detailed answer in 17281 chars ...\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.11 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.30 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.93s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.04 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.45 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.91 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:02<00:00,  2.31s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  1.21 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:01<00:00,  1.70s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.24 Batches/s]\n"
     ]
    }
   ],
   "source": [
    "prediction = finder.get_answers(question=\"What system shall be implemented in Serbia?\", top_k_retriever=10, top_k_reader=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'answers': [   {   'answer': 'a monitoring, reporting, and verification '\n",
      "                                 '(MRV) system',\n",
      "                       'context': 'reement. \\n'\n",
      "                                  '\\n'\n",
      "                                  'The project will finalize and launch a '\n",
      "                                  'monitoring, reporting, and verification '\n",
      "                                  '(MRV) system that will provide more '\n",
      "                                  'accurate information and',\n",
      "                       'document_id': 'a3056f62-5c73-4046-a46c-ad4d16c2595e',\n",
      "                       'meta': {'PIMS_ID': 6211},\n",
      "                       'offset_end': 102,\n",
      "                       'offset_end_in_doc': 570,\n",
      "                       'offset_start': 48,\n",
      "                       'offset_start_in_doc': 516,\n",
      "                       'probability': 0.7726760525124913,\n",
      "                       'score': 9.787870407104492},\n",
      "                   {   'answer': 'a uniform national wildlife PA system',\n",
      "                       'context': 'ablishment and management, the project aims '\n",
      "                                  'to establish a uniform national wildlife PA '\n",
      "                                  'system in Peninsular Malaysia and to '\n",
      "                                  'establish a performance-b',\n",
      "                       'document_id': 'cee4152e-af8a-4644-8a22-d1f3f900fcb9',\n",
      "                       'meta': {'PIMS_ID': 3967},\n",
      "                       'offset_end': 94,\n",
      "                       'offset_end_in_doc': 1872,\n",
      "                       'offset_start': 57,\n",
      "                       'offset_start_in_doc': 1835,\n",
      "                       'probability': 0.7623624780920136,\n",
      "                       'score': 9.32540512084961},\n",
      "                   {   'answer': 'municipal Energy Management Systems',\n",
      "                       'context': 'jective is to introduce and support the '\n",
      "                                  'implementation of municipal Energy '\n",
      "                                  'Management Systems (EMS), including Energy '\n",
      "                                  'Management Information Systems (',\n",
      "                       'document_id': 'f0ccbdbd-9219-4a93-92db-80b82f5f7a30',\n",
      "                       'meta': {'PIMS_ID': 4588},\n",
      "                       'offset_end': 93,\n",
      "                       'offset_end_in_doc': 107,\n",
      "                       'offset_start': 58,\n",
      "                       'offset_start_in_doc': 72,\n",
      "                       'probability': 0.7236274268999738,\n",
      "                       'score': 7.700214385986328},\n",
      "                   {   'answer': 'a Full-Size Project (FSP) along the coastal '\n",
      "                                 'zone, in six different pilot sites',\n",
      "                       'context': ' Countries Fund (LDCF) to implement a '\n",
      "                                  'Full-Size Project (FSP) along the coastal '\n",
      "                                  'zone, in six different pilot sites (Conakry '\n",
      "                                  'Dee, Lakka, Hamilton, Tomb',\n",
      "                       'document_id': 'b7744907-337a-4cd3-98da-501115e9f6dc',\n",
      "                       'meta': {'PIMS_ID': 5178},\n",
      "                       'offset_end': 114,\n",
      "                       'offset_end_in_doc': 1213,\n",
      "                       'offset_start': 36,\n",
      "                       'offset_start_in_doc': 1135,\n",
      "                       'probability': 0.637876222440903,\n",
      "                       'score': 4.529265403747559},\n",
      "                   {   'answer': 'The project’s approach',\n",
      "                       'context': 'roaches to address the climate risk facing '\n",
      "                                  'coastal communities. The project’s approach '\n",
      "                                  'to be adopted will deliver three '\n",
      "                                  'complimentary outcomes to addr',\n",
      "                       'document_id': 'b7744907-337a-4cd3-98da-501115e9f6dc',\n",
      "                       'meta': {'PIMS_ID': 5178},\n",
      "                       'offset_end': 86,\n",
      "                       'offset_end_in_doc': 2615,\n",
      "                       'offset_start': 64,\n",
      "                       'offset_start_in_doc': 2593,\n",
      "                       'probability': 0.5935355109898552,\n",
      "                       'score': 3.028803825378418}],\n",
      "    'no_ans_gap': 6.785511016845703,\n",
      "    'question': 'What system shall be implemented in Serbia?'}\n"
     ]
    }
   ],
   "source": [
    "print_answers(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Dense Passage Retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:50:24 - INFO - filelock -   Lock 6070406640 acquired on /Users/jonas/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c49719784c4b22a9641e921d86d8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:50:25 - INFO - filelock -   Lock 6070406640 released on /Users/jonas/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:50:26 - INFO - filelock -   Lock 6057116864 acquired on /Users/jonas/.cache/torch/transformers/4b05580c0bfb2b640a50c1c6ae3fe9bca923871a29e0182927c086905d6c4c47.7652e92693c670fb8dfd7ec1f9191e3f82673742ff6a86cde9133a4ea6002ced.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edc6089d0d84b5098b79656bafb4644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=493.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:50:27 - INFO - filelock -   Lock 6057116864 released on /Users/jonas/.cache/torch/transformers/4b05580c0bfb2b640a50c1c6ae3fe9bca923871a29e0182927c086905d6c4c47.7652e92693c670fb8dfd7ec1f9191e3f82673742ff6a86cde9133a4ea6002ced.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:50:27 - INFO - filelock -   Lock 6057589776 acquired on /Users/jonas/.cache/torch/transformers/8fdd0d2838c23f921379f2b0322aecf406cbdaa97ffecc544e3a1d49a7c302bd.6f90756c59007364d7842118056ad653f39f4d340fbe20bcc04037d2a45cb0f7.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8d17f652034ef682c3d99c0c4ba74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=437986065.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:53:10 - INFO - filelock -   Lock 6057589776 released on /Users/jonas/.cache/torch/transformers/8fdd0d2838c23f921379f2b0322aecf406cbdaa97ffecc544e3a1d49a7c302bd.6f90756c59007364d7842118056ad653f39f4d340fbe20bcc04037d2a45cb0f7.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DPRQuestionEncoder were not initialized from the model checkpoint at facebook/dpr-question_encoder-single-nq-base and are newly initialized: ['question_encoder.bert_model.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "10/07/2020 18:53:16 - INFO - filelock -   Lock 5006083408 acquired on /Users/jonas/.cache/torch/transformers/f6388f32b32eac5dad8f0f9c7009ce69e967c1b65ebae62f805fced8022ea991.9500f04f28d7c0ca5f9c265db7ba5030897a2d752451412827f7dec185b1ee36.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42060a238bb94e8ba024c7edf3a35a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=492.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:53:17 - INFO - filelock -   Lock 5006083408 released on /Users/jonas/.cache/torch/transformers/f6388f32b32eac5dad8f0f9c7009ce69e967c1b65ebae62f805fced8022ea991.9500f04f28d7c0ca5f9c265db7ba5030897a2d752451412827f7dec185b1ee36.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:53:17 - INFO - filelock -   Lock 5006083072 acquired on /Users/jonas/.cache/torch/transformers/d1c705617c02da7a616f4b5a8cb445a7f78e84bc4f9e26378c89901d97e16d78.232fed629becb590e5b2ac6c6124f9d1561ef7a1d17ad0394232dd46a0835002.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c394f19e3544b893bafef0eaeda116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=437983985.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/07/2020 18:56:02 - INFO - filelock -   Lock 5006083072 released on /Users/jonas/.cache/torch/transformers/d1c705617c02da7a616f4b5a8cb445a7f78e84bc4f9e26378c89901d97e16d78.232fed629becb590e5b2ac6c6124f9d1561ef7a1d17ad0394232dd46a0835002.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DPRContextEncoder were not initialized from the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base and are newly initialized: ['ctx_encoder.bert_model.embeddings.position_ids']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Dense Passage Retriever:\n",
    "\n",
    "    Utilizes BERT to embed both the document and the query to compute a more contextual similarity score for ranking.\n",
    "    \n",
    "    Embedding of documents is computationally very expensive and is probably unfeasible without proper GPU support.\n",
    "    \n",
    "'''\n",
    "\n",
    "from haystack.retriever.dense import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(document_store=document_store,\n",
    "                                  query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "                                  passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "                                  use_gpu=True,\n",
    "                                  embed_title=True,\n",
    "                                  max_seq_len=256,\n",
    "                                  batch_size=16,\n",
    "                                  remove_sep_tok_from_untitled_passages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1444.4657039711192\n",
      "sliding window or pre-processing has to enabled for proper results\n"
     ]
    }
   ],
   "source": [
    "#check for average length to see if max_seq_length of BERT model is sufficient:\n",
    "mean_len = description.project_description.str.len().mean()\n",
    "print(mean_len)\n",
    "if mean_len > 512:\n",
    "    print('sliding window or pre-processing has to enabled for proper results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/03/2020 11:57:29 - INFO - elasticsearch -   POST http://localhost:9200/document/_search?scroll=5m&size=1000 [status:200 request:0.525s]\n",
      "10/03/2020 11:57:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.137s]\n",
      "10/03/2020 11:57:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.121s]\n",
      "10/03/2020 11:57:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.084s]\n",
      "10/03/2020 11:57:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.113s]\n",
      "10/03/2020 11:57:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.104s]\n",
      "10/03/2020 11:57:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.091s]\n",
      "10/03/2020 11:57:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.079s]\n",
      "10/03/2020 11:57:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.086s]\n",
      "10/03/2020 11:57:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.068s]\n",
      "10/03/2020 11:57:30 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.070s]\n",
      "10/03/2020 11:57:31 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.078s]\n",
      "10/03/2020 11:57:31 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.068s]\n",
      "10/03/2020 11:57:32 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.074s]\n",
      "10/03/2020 11:57:32 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.080s]\n",
      "10/03/2020 11:57:32 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.081s]\n",
      "10/03/2020 11:57:32 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.072s]\n",
      "10/03/2020 11:57:32 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.066s]\n",
      "10/03/2020 11:57:32 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.081s]\n",
      "10/03/2020 11:57:32 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.079s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.071s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.063s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.061s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.081s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.080s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.067s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.083s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.082s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.059s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.064s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.061s]\n",
      "10/03/2020 11:57:33 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.052s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.070s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.062s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.067s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.060s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.061s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.092s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.088s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.076s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.080s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.107s]\n",
      "10/03/2020 11:57:34 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.072s]\n",
      "10/03/2020 11:57:35 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.080s]\n",
      "10/03/2020 11:57:35 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.074s]\n",
      "10/03/2020 11:57:35 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.083s]\n",
      "10/03/2020 11:57:35 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.095s]\n",
      "10/03/2020 11:57:35 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.091s]\n",
      "10/03/2020 11:57:35 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.075s]\n",
      "10/03/2020 11:57:35 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.056s]\n",
      "10/03/2020 11:57:35 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.076s]\n",
      "10/03/2020 11:57:35 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.067s]\n",
      "10/03/2020 11:57:35 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.063s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.059s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.083s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.097s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.075s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.061s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.055s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.067s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.078s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.082s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.056s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.050s]\n",
      "10/03/2020 11:57:36 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.076s]\n",
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.076s]\n",
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.071s]\n",
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.058s]\n",
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.055s]\n",
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.062s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.072s]\n",
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.074s]\n",
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.067s]\n",
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.069s]\n",
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.073s]\n",
      "10/03/2020 11:57:37 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.073s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.066s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.084s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.063s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.059s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.066s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.070s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.097s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.070s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.071s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.058s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.071s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.062s]\n",
      "10/03/2020 11:57:38 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.060s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.079s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.078s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.075s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.064s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.062s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.056s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.064s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.066s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.087s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.061s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.065s]\n",
      "10/03/2020 11:57:39 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.087s]\n",
      "10/03/2020 11:57:40 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.081s]\n",
      "10/03/2020 11:57:40 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.110s]\n",
      "10/03/2020 11:57:40 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.080s]\n",
      "10/03/2020 11:57:40 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.070s]\n",
      "10/03/2020 11:57:40 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.078s]\n",
      "10/03/2020 11:57:40 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.092s]\n",
      "10/03/2020 11:57:40 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.067s]\n",
      "10/03/2020 11:57:40 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.059s]\n",
      "10/03/2020 11:57:40 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.070s]\n",
      "10/03/2020 11:57:40 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.060s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.051s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.046s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.059s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.072s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.055s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.046s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.050s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.067s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.059s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.056s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.057s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.056s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.080s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.072s]\n",
      "10/03/2020 11:57:41 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.066s]\n",
      "10/03/2020 11:57:42 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.081s]\n",
      "10/03/2020 11:57:42 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.105s]\n",
      "10/03/2020 11:57:42 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.111s]\n",
      "10/03/2020 11:57:42 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.079s]\n",
      "10/03/2020 11:57:42 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.058s]\n",
      "10/03/2020 11:57:42 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.078s]\n",
      "10/03/2020 11:57:42 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.088s]\n",
      "10/03/2020 11:57:42 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.090s]\n",
      "10/03/2020 11:57:42 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.086s]\n",
      "10/03/2020 11:57:42 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.057s]\n",
      "10/03/2020 11:57:43 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.084s]\n",
      "10/03/2020 11:57:43 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.083s]\n",
      "10/03/2020 11:57:43 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.077s]\n",
      "10/03/2020 11:57:43 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.065s]\n",
      "10/03/2020 11:57:43 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.062s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/03/2020 11:57:43 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.072s]\n",
      "10/03/2020 11:57:43 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.082s]\n",
      "10/03/2020 11:57:43 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.075s]\n",
      "10/03/2020 11:57:43 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.082s]\n",
      "10/03/2020 11:57:43 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.066s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.067s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.060s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.056s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.055s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.060s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.059s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.051s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.043s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.047s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.063s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.058s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.054s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.055s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.072s]\n",
      "10/03/2020 11:57:44 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.056s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.060s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.046s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.050s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.059s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.060s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.049s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.047s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.061s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.057s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.055s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.044s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.040s]\n",
      "10/03/2020 11:57:45 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.047s]\n",
      "10/03/2020 11:57:46 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.047s]\n",
      "10/03/2020 11:57:46 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.057s]\n",
      "10/03/2020 11:57:46 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.042s]\n",
      "10/03/2020 11:57:46 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.055s]\n",
      "10/03/2020 11:57:46 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.059s]\n",
      "10/03/2020 11:57:46 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.053s]\n",
      "10/03/2020 11:57:46 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.057s]\n",
      "10/03/2020 11:57:46 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.029s]\n",
      "10/03/2020 11:57:46 - INFO - elasticsearch -   POST http://localhost:9200/_search/scroll [status:200 request:0.013s]\n",
      "10/03/2020 11:57:46 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.017s]\n",
      "10/03/2020 11:57:46 - INFO - haystack.document_store.elasticsearch -   Updating embeddings for 181640 docs ...\n",
      "/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1764: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "../torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple)\n",
      "10/03/2020 11:58:21 - INFO - haystack.retriever.dense -   Embedded 80 / 181640 texts\n",
      "10/03/2020 11:58:55 - INFO - haystack.retriever.dense -   Embedded 160 / 181640 texts\n",
      "10/03/2020 11:59:28 - INFO - haystack.retriever.dense -   Embedded 240 / 181640 texts\n",
      "10/03/2020 12:00:02 - INFO - haystack.retriever.dense -   Embedded 320 / 181640 texts\n",
      "10/03/2020 12:00:35 - INFO - haystack.retriever.dense -   Embedded 400 / 181640 texts\n",
      "10/03/2020 12:01:08 - INFO - haystack.retriever.dense -   Embedded 480 / 181640 texts\n",
      "10/03/2020 12:01:41 - INFO - haystack.retriever.dense -   Embedded 560 / 181640 texts\n",
      "10/03/2020 12:02:14 - INFO - haystack.retriever.dense -   Embedded 640 / 181640 texts\n",
      "10/03/2020 12:02:56 - INFO - haystack.retriever.dense -   Embedded 720 / 181640 texts\n",
      "10/03/2020 12:03:37 - INFO - haystack.retriever.dense -   Embedded 800 / 181640 texts\n",
      "10/03/2020 12:04:18 - INFO - haystack.retriever.dense -   Embedded 880 / 181640 texts\n",
      "10/03/2020 12:04:58 - INFO - haystack.retriever.dense -   Embedded 960 / 181640 texts\n",
      "10/03/2020 12:05:33 - INFO - haystack.retriever.dense -   Embedded 1040 / 181640 texts\n",
      "10/03/2020 12:06:12 - INFO - haystack.retriever.dense -   Embedded 1120 / 181640 texts\n",
      "10/03/2020 12:06:50 - INFO - haystack.retriever.dense -   Embedded 1200 / 181640 texts\n",
      "10/03/2020 12:07:27 - INFO - haystack.retriever.dense -   Embedded 1280 / 181640 texts\n",
      "10/03/2020 12:08:04 - INFO - haystack.retriever.dense -   Embedded 1360 / 181640 texts\n",
      "10/03/2020 12:08:44 - INFO - haystack.retriever.dense -   Embedded 1440 / 181640 texts\n",
      "10/03/2020 12:09:21 - INFO - haystack.retriever.dense -   Embedded 1520 / 181640 texts\n",
      "10/03/2020 12:09:59 - INFO - haystack.retriever.dense -   Embedded 1600 / 181640 texts\n",
      "10/03/2020 12:10:50 - INFO - haystack.retriever.dense -   Embedded 1680 / 181640 texts\n",
      "10/03/2020 12:11:31 - INFO - haystack.retriever.dense -   Embedded 1760 / 181640 texts\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-986995a6977e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#update embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdocument_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/haystack/document_store/elasticsearch.py\u001b[0m in \u001b[0;36mupdate_embeddings\u001b[0;34m(self, retriever, index)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mdocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Updating embeddings for {len(docs)} docs ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_passages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/haystack/retriever/dense.py\u001b[0m in \u001b[0;36membed_passages\u001b[0;34m(self, docs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"name\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         result = self._generate_batch_predictions(texts=texts, titles=titles,\n\u001b[0m\u001b[1;32m    123\u001b[0m                                                   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpassage_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                                                   \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpassage_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/haystack/retriever/dense.py\u001b[0m in \u001b[0;36m_generate_batch_predictions\u001b[0;34m(self, texts, model, tokenizer, titles, batch_size)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx_ids_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx_attn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx_seg_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m                 \u001b[0;31m# TODO revert back to when updating transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0;31m# out = out.pooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/transformers/modeling_dpr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         outputs = self.ctx_encoder(\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/transformers/modeling_dpr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     ) -> Union[BaseModelOutputWithPooling, Tuple[Tensor, ...]]:\n\u001b[0;32m--> 166\u001b[0;31m         outputs = self.bert_model(\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         )\n\u001b[0;32m--> 827\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    482\u001b[0m                 )\n\u001b[1;32m    483\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    485\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add cross attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1597\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/haystack/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#update embeddings - do not compile without GPU support. \n",
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = Finder(reader, retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = finder.get_answers(question=\"What is the MRV system supporting in Serbia?\", top_k_retriever=10, top_k_reader=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
