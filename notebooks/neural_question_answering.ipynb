{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\", use_fast=False)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\", return_dict=False)\n",
    "\n",
    "#longformer\n",
    "#tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-large-4096-finetuned-triviaqa\", use_fast=False)\n",
    "#model = LongformerForQuestionAnswering.from_pretrained(\"allenai/longformer-large-4096-finetuned-triviaqa\", return_dict=False)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "bi_encoder = SentenceTransformer('nq-distilbert-base-v1')\n",
    "\n",
    "from inspect import getsourcefile\n",
    "import os.path as path, sys\n",
    "current_dir = path.dirname(path.abspath(getsourcefile(lambda:0)))\n",
    "sys.path.insert(0, current_dir[:current_dir.rfind(path.sep)])\n",
    "import src.clean_dataset as clean\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data:\n",
    "df = pd.read_csv('../data/processed/taxonomy_final.csv')\n",
    "\n",
    "corpus_embeddings = pickle.load(open(\"../data/processed/splitted_corpus_embeddings.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped, splitted = clean.split_at_length(df, 'all_text_clean', 512)\n",
    "passages = splitted.text.tolist()\n",
    "passage_id = splitted.PIMS_ID.tolist()\n",
    "#corpus_embeddings = bi_encoder.encode(passages, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(corpus_embeddings, open(\"../data/processed/splitted_corpus_embeddings.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = clean.split_at_length(df, 'all_text', 1000)\n",
    "passages_long = splitted.text.tolist()\n",
    "print(len(passages_long))\n",
    "#corpus_embeddings_long = bi_encoder.encode(passages_long, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to mitigate floods?\n"
     ]
    }
   ],
   "source": [
    "query = input()\n",
    "\n",
    "top_k = 5  # Number of passages we want to retrieve with the bi-encoder\n",
    "start_time = time.time()\n",
    "question_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "hits = util.semantic_search(question_embedding, corpus_embeddings, top_k=top_k)\n",
    "hits = hits[0]  # Get the hits for the first query\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input question: how to mitigate floods?\n",
      "Results (after 0.906 seconds):\n",
      "\t0.501\tcoastline with climate resilient shoreline and flood protection measures introduced including vegetation planting along the coast and riparian streams and beach replenishment by the end of the programme at least inhabitants in villages have their water supply and associated infrastructure improved to manage climateinduced impacts on water supply the target villages lack robust water supply system to withstand climateinduced impacts in water supply n of population and communities accessing improved water\n",
      "\t0.443\timplementing water adaptive productive practices\n",
      "\t0.438\tenabling climate vulnerable people to plan for and adapt to the impacts of climate change knowledge will be generated and used to formulate comprehensive communitybased adaptation plans ecological and physical infrastructure measures for water management will be adopted to regulate baseflow and reduce risk of floods while mitigating against droughts in addition climate smart agriculture and safe postharvest management technologies and practices will lead to enhanced production reduction in grain loss and\n",
      "\t0.432\tchange and variabilityinduced stress by the completion of the programme climate resilient shoreline and flood protection measures are introduced in at least km coastline and riparian streams including vegetation planting in at least km coast and km of riparian streams and beach replenishment techniques applied in at least sites and km coastline there are only a few villages where shoreline adaptation measures have been introduced through the pacc and cbdampic projects but only in a pilot fashion km of\n",
      "\t0.401\tthe subregion in line with the drin mou implementation process the main objective of the project is to assist the eligible riparian countries in the implementation of an integrated climateresilient river basin flood risk management approach in order to improve their existing capacity to manage flood risk at regional national and local levels and to enhance resilience of vulnerable communities in the drin river basin to climateinduced floods\n",
      "\n",
      "\n",
      "========\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.50050205, 0.44299835, 0.43815923, 0.43215483, 0.40131235]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output of top-k hits\n",
    "print(\"Input question:\", query)\n",
    "print(\"Results (after {:.3f} seconds):\".format(end_time - start_time))\n",
    "matches = []\n",
    "ids = []\n",
    "scores =  []\n",
    "for hit in hits:\n",
    "    print(\"\\t{:.3f}\\t{}\".format(hit['score'], passages[hit['corpus_id']]))\n",
    "    matches.append(passages[hit['corpus_id']])\n",
    "    ids.append(passage_id[hit['corpus_id']])\n",
    "    scores.append(hit['score'])\n",
    "    \n",
    "print(\"\\n\\n========\\n\")\n",
    "#d = {'PIMS_ID':ids,'context':matches}\n",
    "#df = pd.DataFrame(d)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: how to mitigate floods?\n",
      "Answer: vegetation planting along the coast and riparian streams and beach replenishment\n",
      "\n",
      "Question: how to mitigate floods?\n",
      "Answer: implementing water adaptive productive practices\n",
      "\n",
      "Question: how to mitigate floods?\n",
      "Answer: ecological and physical infrastructure measures for water management\n",
      "\n",
      "Question: how to mitigate floods?\n",
      "Answer: vegetation planting\n",
      "\n",
      "Question: how to mitigate floods?\n",
      "Answer: climateresilient river basin flood risk management approach\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for match in matches:\n",
    "    inputs = tokenizer.encode_plus(query, match, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    answer_start_scores, answer_end_scores = model(**inputs)\n",
    "\n",
    "    answer_start = torch.argmax(answer_start_scores)  # Get the most likely beginning of answer with the argmax of the score\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "\n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "    print(f\"Question: {query}\")\n",
    "    print(f\"Answer: {answer}\\n\")\n",
    "    answers.append(answer)\n",
    "    \n",
    "#df = df.assign(answer=answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(\n",
    "    {'PIMS_ID': ids,\n",
    "     'answer': answers,\n",
    "     'context': matches,\n",
    "     \"scores\": scores\n",
    "    })\n",
    "df_results.set_index('PIMS_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIMS_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>vegetation planting along the coast and ripari...</td>\n",
       "      <td>coastline with climate resilient shoreline and...</td>\n",
       "      <td>0.500502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>implementing water adaptive productive practices</td>\n",
       "      <td>implementing water adaptive productive practices</td>\n",
       "      <td>0.442998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>ecological and physical infrastructure measure...</td>\n",
       "      <td>enabling climate vulnerable people to plan for...</td>\n",
       "      <td>0.438159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>vegetation planting</td>\n",
       "      <td>change and variabilityinduced stress by the co...</td>\n",
       "      <td>0.432155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>climateresilient river basin flood risk manage...</td>\n",
       "      <td>the subregion in line with the drin mou implem...</td>\n",
       "      <td>0.401312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    answer  \\\n",
       "PIMS_ID                                                      \n",
       "4667     vegetation planting along the coast and ripari...   \n",
       "5757      implementing water adaptive productive practices   \n",
       "4508     ecological and physical infrastructure measure...   \n",
       "4667                                   vegetation planting   \n",
       "6215     climateresilient river basin flood risk manage...   \n",
       "\n",
       "                                                   context    scores  \n",
       "PIMS_ID                                                               \n",
       "4667     coastline with climate resilient shoreline and...  0.500502  \n",
       "5757      implementing water adaptive productive practices  0.442998  \n",
       "4508     enabling climate vulnerable people to plan for...  0.438159  \n",
       "4667     change and variabilityinduced stress by the co...  0.432155  \n",
       "6215     the subregion in line with the drin mou implem...  0.401312  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
